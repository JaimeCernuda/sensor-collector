{
  "best_global_step": 3477,
  "best_metric": 0.010830165818333626,
  "best_model_checkpoint": "/content/sensor-collector/tick2/notebooks/output/03/granite_ttm_ft/combined/E1_univariate/combined/checkpoints/checkpoint-3477",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3477,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014380212827149842,
      "grad_norm": 0.0003186966641806066,
      "learning_rate": 0.0009997181478285878,
      "loss": 0.0035,
      "step": 50
    },
    {
      "epoch": 0.028760425654299683,
      "grad_norm": 8.496068767271936e-05,
      "learning_rate": 0.000999430543572045,
      "loss": 0.0043,
      "step": 100
    },
    {
      "epoch": 0.04314063848144953,
      "grad_norm": 0.018853986635804176,
      "learning_rate": 0.0009991429393155019,
      "loss": 0.0013,
      "step": 150
    },
    {
      "epoch": 0.057520851308599366,
      "grad_norm": 0.00011813791206805035,
      "learning_rate": 0.000998855335058959,
      "loss": 0.002,
      "step": 200
    },
    {
      "epoch": 0.0719010641357492,
      "grad_norm": 0.0002906447625719011,
      "learning_rate": 0.0009985677308024159,
      "loss": 0.0029,
      "step": 250
    },
    {
      "epoch": 0.08628127696289906,
      "grad_norm": 0.00015147628437262028,
      "learning_rate": 0.0009982801265458728,
      "loss": 0.0022,
      "step": 300
    },
    {
      "epoch": 0.1006614897900489,
      "grad_norm": 0.00045435785432346165,
      "learning_rate": 0.00099799252228933,
      "loss": 0.0027,
      "step": 350
    },
    {
      "epoch": 0.11504170261719873,
      "grad_norm": 9.785349539015442e-05,
      "learning_rate": 0.000997704918032787,
      "loss": 0.0048,
      "step": 400
    },
    {
      "epoch": 0.12942191544434858,
      "grad_norm": 8.56787373777479e-05,
      "learning_rate": 0.000997417313776244,
      "loss": 0.0011,
      "step": 450
    },
    {
      "epoch": 0.1438021282714984,
      "grad_norm": 0.00019031406554859132,
      "learning_rate": 0.000997129709519701,
      "loss": 0.0022,
      "step": 500
    },
    {
      "epoch": 0.15818234109864826,
      "grad_norm": 0.0006073990953154862,
      "learning_rate": 0.000996842105263158,
      "loss": 0.0043,
      "step": 550
    },
    {
      "epoch": 0.1725625539257981,
      "grad_norm": 0.491588294506073,
      "learning_rate": 0.0009965545010066149,
      "loss": 0.0041,
      "step": 600
    },
    {
      "epoch": 0.18694276675294794,
      "grad_norm": 0.23955023288726807,
      "learning_rate": 0.000996266896750072,
      "loss": 0.0035,
      "step": 650
    },
    {
      "epoch": 0.2013229795800978,
      "grad_norm": 0.00016311103536281735,
      "learning_rate": 0.0009959792924935289,
      "loss": 0.0034,
      "step": 700
    },
    {
      "epoch": 0.21570319240724764,
      "grad_norm": 0.00018003390869125724,
      "learning_rate": 0.000995691688236986,
      "loss": 0.0033,
      "step": 750
    },
    {
      "epoch": 0.23008340523439746,
      "grad_norm": 7.76387969381176e-05,
      "learning_rate": 0.000995404083980443,
      "loss": 0.0031,
      "step": 800
    },
    {
      "epoch": 0.24446361806154732,
      "grad_norm": 0.03055521473288536,
      "learning_rate": 0.0009951164797239,
      "loss": 0.0021,
      "step": 850
    },
    {
      "epoch": 0.25884383088869717,
      "grad_norm": 9.796665835892782e-05,
      "learning_rate": 0.000994828875467357,
      "loss": 0.0035,
      "step": 900
    },
    {
      "epoch": 0.273224043715847,
      "grad_norm": 8.502024866174906e-05,
      "learning_rate": 0.000994541271210814,
      "loss": 0.0052,
      "step": 950
    },
    {
      "epoch": 0.2876042565429968,
      "grad_norm": 0.0001302387099713087,
      "learning_rate": 0.000994253666954271,
      "loss": 0.0044,
      "step": 1000
    },
    {
      "epoch": 0.30198446937014667,
      "grad_norm": 0.00027956432313658297,
      "learning_rate": 0.0009939660626977279,
      "loss": 0.0019,
      "step": 1050
    },
    {
      "epoch": 0.3163646821972965,
      "grad_norm": 0.0001578053634148091,
      "learning_rate": 0.000993678458441185,
      "loss": 0.0055,
      "step": 1100
    },
    {
      "epoch": 0.3307448950244464,
      "grad_norm": 4.652739880839363e-05,
      "learning_rate": 0.0009933908541846419,
      "loss": 0.0025,
      "step": 1150
    },
    {
      "epoch": 0.3451251078515962,
      "grad_norm": 0.030566180124878883,
      "learning_rate": 0.000993103249928099,
      "loss": 0.006,
      "step": 1200
    },
    {
      "epoch": 0.359505320678746,
      "grad_norm": 0.0009328351588919759,
      "learning_rate": 0.000992815645671556,
      "loss": 0.0031,
      "step": 1250
    },
    {
      "epoch": 0.3738855335058959,
      "grad_norm": 0.00011242264736210927,
      "learning_rate": 0.000992528041415013,
      "loss": 0.0041,
      "step": 1300
    },
    {
      "epoch": 0.3882657463330457,
      "grad_norm": 0.013999449089169502,
      "learning_rate": 0.00099224043715847,
      "loss": 0.002,
      "step": 1350
    },
    {
      "epoch": 0.4026459591601956,
      "grad_norm": 2.5329296477138996e-05,
      "learning_rate": 0.000991952832901927,
      "loss": 0.0025,
      "step": 1400
    },
    {
      "epoch": 0.41702617198734543,
      "grad_norm": 0.0019485765369608998,
      "learning_rate": 0.000991665228645384,
      "loss": 0.0065,
      "step": 1450
    },
    {
      "epoch": 0.4314063848144953,
      "grad_norm": 0.002738920273259282,
      "learning_rate": 0.0009913776243888409,
      "loss": 0.0011,
      "step": 1500
    },
    {
      "epoch": 0.4457865976416451,
      "grad_norm": 9.323636186309159e-05,
      "learning_rate": 0.000991090020132298,
      "loss": 0.0044,
      "step": 1550
    },
    {
      "epoch": 0.46016681046879493,
      "grad_norm": 0.04902638867497444,
      "learning_rate": 0.000990802415875755,
      "loss": 0.0024,
      "step": 1600
    },
    {
      "epoch": 0.4745470232959448,
      "grad_norm": 4.9621656216913834e-05,
      "learning_rate": 0.000990514811619212,
      "loss": 0.0028,
      "step": 1650
    },
    {
      "epoch": 0.48892723612309463,
      "grad_norm": 0.00013219829997979105,
      "learning_rate": 0.0009902272073626691,
      "loss": 0.0014,
      "step": 1700
    },
    {
      "epoch": 0.5033074489502445,
      "grad_norm": 0.0001450946438126266,
      "learning_rate": 0.000989939603106126,
      "loss": 0.005,
      "step": 1750
    },
    {
      "epoch": 0.5176876617773943,
      "grad_norm": 0.00027434469666332006,
      "learning_rate": 0.000989651998849583,
      "loss": 0.002,
      "step": 1800
    },
    {
      "epoch": 0.5320678746045442,
      "grad_norm": 0.01429727952927351,
      "learning_rate": 0.00098936439459304,
      "loss": 0.004,
      "step": 1850
    },
    {
      "epoch": 0.546448087431694,
      "grad_norm": 0.0012258576462045312,
      "learning_rate": 0.000989076790336497,
      "loss": 0.0029,
      "step": 1900
    },
    {
      "epoch": 0.5608283002588438,
      "grad_norm": 9.040602890308946e-05,
      "learning_rate": 0.000988789186079954,
      "loss": 0.002,
      "step": 1950
    },
    {
      "epoch": 0.5752085130859936,
      "grad_norm": 7.579108205391094e-05,
      "learning_rate": 0.000988501581823411,
      "loss": 0.0045,
      "step": 2000
    },
    {
      "epoch": 0.5895887259131435,
      "grad_norm": 0.00015592384443152696,
      "learning_rate": 0.000988213977566868,
      "loss": 0.0034,
      "step": 2050
    },
    {
      "epoch": 0.6039689387402933,
      "grad_norm": 0.09252319484949112,
      "learning_rate": 0.000987926373310325,
      "loss": 0.0025,
      "step": 2100
    },
    {
      "epoch": 0.6183491515674432,
      "grad_norm": 0.0008911374607123435,
      "learning_rate": 0.0009876387690537821,
      "loss": 0.0046,
      "step": 2150
    },
    {
      "epoch": 0.632729364394593,
      "grad_norm": 0.045828722417354584,
      "learning_rate": 0.000987351164797239,
      "loss": 0.0027,
      "step": 2200
    },
    {
      "epoch": 0.6471095772217429,
      "grad_norm": 0.015718568116426468,
      "learning_rate": 0.000987063560540696,
      "loss": 0.0056,
      "step": 2250
    },
    {
      "epoch": 0.6614897900488927,
      "grad_norm": 0.001757508609443903,
      "learning_rate": 0.000986775956284153,
      "loss": 0.0045,
      "step": 2300
    },
    {
      "epoch": 0.6758700028760426,
      "grad_norm": 0.06499754637479782,
      "learning_rate": 0.00098648835202761,
      "loss": 0.0056,
      "step": 2350
    },
    {
      "epoch": 0.6902502157031924,
      "grad_norm": 0.010831454768776894,
      "learning_rate": 0.000986200747771067,
      "loss": 0.0034,
      "step": 2400
    },
    {
      "epoch": 0.7046304285303423,
      "grad_norm": 0.0008580798166804016,
      "learning_rate": 0.000985913143514524,
      "loss": 0.0053,
      "step": 2450
    },
    {
      "epoch": 0.719010641357492,
      "grad_norm": 0.20390531420707703,
      "learning_rate": 0.000985625539257981,
      "loss": 0.0055,
      "step": 2500
    },
    {
      "epoch": 0.7333908541846419,
      "grad_norm": 0.31008774042129517,
      "learning_rate": 0.000985337935001438,
      "loss": 0.0045,
      "step": 2550
    },
    {
      "epoch": 0.7477710670117917,
      "grad_norm": 0.0015250963624566793,
      "learning_rate": 0.0009850503307448951,
      "loss": 0.0044,
      "step": 2600
    },
    {
      "epoch": 0.7621512798389416,
      "grad_norm": 0.036892373114824295,
      "learning_rate": 0.000984762726488352,
      "loss": 0.0028,
      "step": 2650
    },
    {
      "epoch": 0.7765314926660914,
      "grad_norm": 0.027619337663054466,
      "learning_rate": 0.000984475122231809,
      "loss": 0.005,
      "step": 2700
    },
    {
      "epoch": 0.7909117054932413,
      "grad_norm": 0.015643524006009102,
      "learning_rate": 0.000984187517975266,
      "loss": 0.0029,
      "step": 2750
    },
    {
      "epoch": 0.8052919183203912,
      "grad_norm": 0.02461586706340313,
      "learning_rate": 0.000983899913718723,
      "loss": 0.0014,
      "step": 2800
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.0001312369859078899,
      "learning_rate": 0.00098361230946218,
      "loss": 0.0018,
      "step": 2850
    },
    {
      "epoch": 0.8340523439746909,
      "grad_norm": 0.00019515998428687453,
      "learning_rate": 0.0009833247052056372,
      "loss": 0.0055,
      "step": 2900
    },
    {
      "epoch": 0.8484325568018407,
      "grad_norm": 0.0001728737261146307,
      "learning_rate": 0.0009830371009490941,
      "loss": 0.0018,
      "step": 2950
    },
    {
      "epoch": 0.8628127696289906,
      "grad_norm": 0.029373114928603172,
      "learning_rate": 0.000982749496692551,
      "loss": 0.0031,
      "step": 3000
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.011371239088475704,
      "learning_rate": 0.0009824618924360081,
      "loss": 0.0015,
      "step": 3050
    },
    {
      "epoch": 0.8915731952832902,
      "grad_norm": 0.00011121736315544695,
      "learning_rate": 0.000982174288179465,
      "loss": 0.0021,
      "step": 3100
    },
    {
      "epoch": 0.90595340811044,
      "grad_norm": 0.000344975822372362,
      "learning_rate": 0.0009818866839229222,
      "loss": 0.0016,
      "step": 3150
    },
    {
      "epoch": 0.9203336209375899,
      "grad_norm": 0.008896121755242348,
      "learning_rate": 0.000981599079666379,
      "loss": 0.0034,
      "step": 3200
    },
    {
      "epoch": 0.9347138337647397,
      "grad_norm": 8.189910295186564e-05,
      "learning_rate": 0.0009813114754098362,
      "loss": 0.0029,
      "step": 3250
    },
    {
      "epoch": 0.9490940465918896,
      "grad_norm": 0.012416377663612366,
      "learning_rate": 0.000981023871153293,
      "loss": 0.0025,
      "step": 3300
    },
    {
      "epoch": 0.9634742594190394,
      "grad_norm": 7.160891982493922e-05,
      "learning_rate": 0.0009807362668967502,
      "loss": 0.0007,
      "step": 3350
    },
    {
      "epoch": 0.9778544722461893,
      "grad_norm": 0.0005443195695988834,
      "learning_rate": 0.0009804486626402071,
      "loss": 0.005,
      "step": 3400
    },
    {
      "epoch": 0.9922346850733391,
      "grad_norm": 0.16644389927387238,
      "learning_rate": 0.000980161058383664,
      "loss": 0.0034,
      "step": 3450
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.010830165818333626,
      "eval_runtime": 12.7137,
      "eval_samples_per_second": 3753.366,
      "eval_steps_per_second": 58.677,
      "step": 3477
    }
  ],
  "logging_steps": 50,
  "max_steps": 173850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 550462092902400.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
