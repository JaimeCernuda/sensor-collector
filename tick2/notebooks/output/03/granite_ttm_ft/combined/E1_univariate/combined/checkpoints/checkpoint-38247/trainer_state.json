{
  "best_global_step": 3477,
  "best_metric": 0.010830165818333626,
  "best_model_checkpoint": "/content/sensor-collector/tick2/notebooks/output/03/granite_ttm_ft/combined/E1_univariate/combined/checkpoints/checkpoint-3477",
  "epoch": 11.0,
  "eval_steps": 500,
  "global_step": 38247,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014380212827149842,
      "grad_norm": 0.0003186966641806066,
      "learning_rate": 0.0009997181478285878,
      "loss": 0.0035,
      "step": 50
    },
    {
      "epoch": 0.028760425654299683,
      "grad_norm": 8.496068767271936e-05,
      "learning_rate": 0.000999430543572045,
      "loss": 0.0043,
      "step": 100
    },
    {
      "epoch": 0.04314063848144953,
      "grad_norm": 0.018853986635804176,
      "learning_rate": 0.0009991429393155019,
      "loss": 0.0013,
      "step": 150
    },
    {
      "epoch": 0.057520851308599366,
      "grad_norm": 0.00011813791206805035,
      "learning_rate": 0.000998855335058959,
      "loss": 0.002,
      "step": 200
    },
    {
      "epoch": 0.0719010641357492,
      "grad_norm": 0.0002906447625719011,
      "learning_rate": 0.0009985677308024159,
      "loss": 0.0029,
      "step": 250
    },
    {
      "epoch": 0.08628127696289906,
      "grad_norm": 0.00015147628437262028,
      "learning_rate": 0.0009982801265458728,
      "loss": 0.0022,
      "step": 300
    },
    {
      "epoch": 0.1006614897900489,
      "grad_norm": 0.00045435785432346165,
      "learning_rate": 0.00099799252228933,
      "loss": 0.0027,
      "step": 350
    },
    {
      "epoch": 0.11504170261719873,
      "grad_norm": 9.785349539015442e-05,
      "learning_rate": 0.000997704918032787,
      "loss": 0.0048,
      "step": 400
    },
    {
      "epoch": 0.12942191544434858,
      "grad_norm": 8.56787373777479e-05,
      "learning_rate": 0.000997417313776244,
      "loss": 0.0011,
      "step": 450
    },
    {
      "epoch": 0.1438021282714984,
      "grad_norm": 0.00019031406554859132,
      "learning_rate": 0.000997129709519701,
      "loss": 0.0022,
      "step": 500
    },
    {
      "epoch": 0.15818234109864826,
      "grad_norm": 0.0006073990953154862,
      "learning_rate": 0.000996842105263158,
      "loss": 0.0043,
      "step": 550
    },
    {
      "epoch": 0.1725625539257981,
      "grad_norm": 0.491588294506073,
      "learning_rate": 0.0009965545010066149,
      "loss": 0.0041,
      "step": 600
    },
    {
      "epoch": 0.18694276675294794,
      "grad_norm": 0.23955023288726807,
      "learning_rate": 0.000996266896750072,
      "loss": 0.0035,
      "step": 650
    },
    {
      "epoch": 0.2013229795800978,
      "grad_norm": 0.00016311103536281735,
      "learning_rate": 0.0009959792924935289,
      "loss": 0.0034,
      "step": 700
    },
    {
      "epoch": 0.21570319240724764,
      "grad_norm": 0.00018003390869125724,
      "learning_rate": 0.000995691688236986,
      "loss": 0.0033,
      "step": 750
    },
    {
      "epoch": 0.23008340523439746,
      "grad_norm": 7.76387969381176e-05,
      "learning_rate": 0.000995404083980443,
      "loss": 0.0031,
      "step": 800
    },
    {
      "epoch": 0.24446361806154732,
      "grad_norm": 0.03055521473288536,
      "learning_rate": 0.0009951164797239,
      "loss": 0.0021,
      "step": 850
    },
    {
      "epoch": 0.25884383088869717,
      "grad_norm": 9.796665835892782e-05,
      "learning_rate": 0.000994828875467357,
      "loss": 0.0035,
      "step": 900
    },
    {
      "epoch": 0.273224043715847,
      "grad_norm": 8.502024866174906e-05,
      "learning_rate": 0.000994541271210814,
      "loss": 0.0052,
      "step": 950
    },
    {
      "epoch": 0.2876042565429968,
      "grad_norm": 0.0001302387099713087,
      "learning_rate": 0.000994253666954271,
      "loss": 0.0044,
      "step": 1000
    },
    {
      "epoch": 0.30198446937014667,
      "grad_norm": 0.00027956432313658297,
      "learning_rate": 0.0009939660626977279,
      "loss": 0.0019,
      "step": 1050
    },
    {
      "epoch": 0.3163646821972965,
      "grad_norm": 0.0001578053634148091,
      "learning_rate": 0.000993678458441185,
      "loss": 0.0055,
      "step": 1100
    },
    {
      "epoch": 0.3307448950244464,
      "grad_norm": 4.652739880839363e-05,
      "learning_rate": 0.0009933908541846419,
      "loss": 0.0025,
      "step": 1150
    },
    {
      "epoch": 0.3451251078515962,
      "grad_norm": 0.030566180124878883,
      "learning_rate": 0.000993103249928099,
      "loss": 0.006,
      "step": 1200
    },
    {
      "epoch": 0.359505320678746,
      "grad_norm": 0.0009328351588919759,
      "learning_rate": 0.000992815645671556,
      "loss": 0.0031,
      "step": 1250
    },
    {
      "epoch": 0.3738855335058959,
      "grad_norm": 0.00011242264736210927,
      "learning_rate": 0.000992528041415013,
      "loss": 0.0041,
      "step": 1300
    },
    {
      "epoch": 0.3882657463330457,
      "grad_norm": 0.013999449089169502,
      "learning_rate": 0.00099224043715847,
      "loss": 0.002,
      "step": 1350
    },
    {
      "epoch": 0.4026459591601956,
      "grad_norm": 2.5329296477138996e-05,
      "learning_rate": 0.000991952832901927,
      "loss": 0.0025,
      "step": 1400
    },
    {
      "epoch": 0.41702617198734543,
      "grad_norm": 0.0019485765369608998,
      "learning_rate": 0.000991665228645384,
      "loss": 0.0065,
      "step": 1450
    },
    {
      "epoch": 0.4314063848144953,
      "grad_norm": 0.002738920273259282,
      "learning_rate": 0.0009913776243888409,
      "loss": 0.0011,
      "step": 1500
    },
    {
      "epoch": 0.4457865976416451,
      "grad_norm": 9.323636186309159e-05,
      "learning_rate": 0.000991090020132298,
      "loss": 0.0044,
      "step": 1550
    },
    {
      "epoch": 0.46016681046879493,
      "grad_norm": 0.04902638867497444,
      "learning_rate": 0.000990802415875755,
      "loss": 0.0024,
      "step": 1600
    },
    {
      "epoch": 0.4745470232959448,
      "grad_norm": 4.9621656216913834e-05,
      "learning_rate": 0.000990514811619212,
      "loss": 0.0028,
      "step": 1650
    },
    {
      "epoch": 0.48892723612309463,
      "grad_norm": 0.00013219829997979105,
      "learning_rate": 0.0009902272073626691,
      "loss": 0.0014,
      "step": 1700
    },
    {
      "epoch": 0.5033074489502445,
      "grad_norm": 0.0001450946438126266,
      "learning_rate": 0.000989939603106126,
      "loss": 0.005,
      "step": 1750
    },
    {
      "epoch": 0.5176876617773943,
      "grad_norm": 0.00027434469666332006,
      "learning_rate": 0.000989651998849583,
      "loss": 0.002,
      "step": 1800
    },
    {
      "epoch": 0.5320678746045442,
      "grad_norm": 0.01429727952927351,
      "learning_rate": 0.00098936439459304,
      "loss": 0.004,
      "step": 1850
    },
    {
      "epoch": 0.546448087431694,
      "grad_norm": 0.0012258576462045312,
      "learning_rate": 0.000989076790336497,
      "loss": 0.0029,
      "step": 1900
    },
    {
      "epoch": 0.5608283002588438,
      "grad_norm": 9.040602890308946e-05,
      "learning_rate": 0.000988789186079954,
      "loss": 0.002,
      "step": 1950
    },
    {
      "epoch": 0.5752085130859936,
      "grad_norm": 7.579108205391094e-05,
      "learning_rate": 0.000988501581823411,
      "loss": 0.0045,
      "step": 2000
    },
    {
      "epoch": 0.5895887259131435,
      "grad_norm": 0.00015592384443152696,
      "learning_rate": 0.000988213977566868,
      "loss": 0.0034,
      "step": 2050
    },
    {
      "epoch": 0.6039689387402933,
      "grad_norm": 0.09252319484949112,
      "learning_rate": 0.000987926373310325,
      "loss": 0.0025,
      "step": 2100
    },
    {
      "epoch": 0.6183491515674432,
      "grad_norm": 0.0008911374607123435,
      "learning_rate": 0.0009876387690537821,
      "loss": 0.0046,
      "step": 2150
    },
    {
      "epoch": 0.632729364394593,
      "grad_norm": 0.045828722417354584,
      "learning_rate": 0.000987351164797239,
      "loss": 0.0027,
      "step": 2200
    },
    {
      "epoch": 0.6471095772217429,
      "grad_norm": 0.015718568116426468,
      "learning_rate": 0.000987063560540696,
      "loss": 0.0056,
      "step": 2250
    },
    {
      "epoch": 0.6614897900488927,
      "grad_norm": 0.001757508609443903,
      "learning_rate": 0.000986775956284153,
      "loss": 0.0045,
      "step": 2300
    },
    {
      "epoch": 0.6758700028760426,
      "grad_norm": 0.06499754637479782,
      "learning_rate": 0.00098648835202761,
      "loss": 0.0056,
      "step": 2350
    },
    {
      "epoch": 0.6902502157031924,
      "grad_norm": 0.010831454768776894,
      "learning_rate": 0.000986200747771067,
      "loss": 0.0034,
      "step": 2400
    },
    {
      "epoch": 0.7046304285303423,
      "grad_norm": 0.0008580798166804016,
      "learning_rate": 0.000985913143514524,
      "loss": 0.0053,
      "step": 2450
    },
    {
      "epoch": 0.719010641357492,
      "grad_norm": 0.20390531420707703,
      "learning_rate": 0.000985625539257981,
      "loss": 0.0055,
      "step": 2500
    },
    {
      "epoch": 0.7333908541846419,
      "grad_norm": 0.31008774042129517,
      "learning_rate": 0.000985337935001438,
      "loss": 0.0045,
      "step": 2550
    },
    {
      "epoch": 0.7477710670117917,
      "grad_norm": 0.0015250963624566793,
      "learning_rate": 0.0009850503307448951,
      "loss": 0.0044,
      "step": 2600
    },
    {
      "epoch": 0.7621512798389416,
      "grad_norm": 0.036892373114824295,
      "learning_rate": 0.000984762726488352,
      "loss": 0.0028,
      "step": 2650
    },
    {
      "epoch": 0.7765314926660914,
      "grad_norm": 0.027619337663054466,
      "learning_rate": 0.000984475122231809,
      "loss": 0.005,
      "step": 2700
    },
    {
      "epoch": 0.7909117054932413,
      "grad_norm": 0.015643524006009102,
      "learning_rate": 0.000984187517975266,
      "loss": 0.0029,
      "step": 2750
    },
    {
      "epoch": 0.8052919183203912,
      "grad_norm": 0.02461586706340313,
      "learning_rate": 0.000983899913718723,
      "loss": 0.0014,
      "step": 2800
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.0001312369859078899,
      "learning_rate": 0.00098361230946218,
      "loss": 0.0018,
      "step": 2850
    },
    {
      "epoch": 0.8340523439746909,
      "grad_norm": 0.00019515998428687453,
      "learning_rate": 0.0009833247052056372,
      "loss": 0.0055,
      "step": 2900
    },
    {
      "epoch": 0.8484325568018407,
      "grad_norm": 0.0001728737261146307,
      "learning_rate": 0.0009830371009490941,
      "loss": 0.0018,
      "step": 2950
    },
    {
      "epoch": 0.8628127696289906,
      "grad_norm": 0.029373114928603172,
      "learning_rate": 0.000982749496692551,
      "loss": 0.0031,
      "step": 3000
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.011371239088475704,
      "learning_rate": 0.0009824618924360081,
      "loss": 0.0015,
      "step": 3050
    },
    {
      "epoch": 0.8915731952832902,
      "grad_norm": 0.00011121736315544695,
      "learning_rate": 0.000982174288179465,
      "loss": 0.0021,
      "step": 3100
    },
    {
      "epoch": 0.90595340811044,
      "grad_norm": 0.000344975822372362,
      "learning_rate": 0.0009818866839229222,
      "loss": 0.0016,
      "step": 3150
    },
    {
      "epoch": 0.9203336209375899,
      "grad_norm": 0.008896121755242348,
      "learning_rate": 0.000981599079666379,
      "loss": 0.0034,
      "step": 3200
    },
    {
      "epoch": 0.9347138337647397,
      "grad_norm": 8.189910295186564e-05,
      "learning_rate": 0.0009813114754098362,
      "loss": 0.0029,
      "step": 3250
    },
    {
      "epoch": 0.9490940465918896,
      "grad_norm": 0.012416377663612366,
      "learning_rate": 0.000981023871153293,
      "loss": 0.0025,
      "step": 3300
    },
    {
      "epoch": 0.9634742594190394,
      "grad_norm": 7.160891982493922e-05,
      "learning_rate": 0.0009807362668967502,
      "loss": 0.0007,
      "step": 3350
    },
    {
      "epoch": 0.9778544722461893,
      "grad_norm": 0.0005443195695988834,
      "learning_rate": 0.0009804486626402071,
      "loss": 0.005,
      "step": 3400
    },
    {
      "epoch": 0.9922346850733391,
      "grad_norm": 0.16644389927387238,
      "learning_rate": 0.000980161058383664,
      "loss": 0.0034,
      "step": 3450
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.010830165818333626,
      "eval_runtime": 11.6141,
      "eval_samples_per_second": 4108.722,
      "eval_steps_per_second": 64.232,
      "step": 3477
    },
    {
      "epoch": 1.006614897900489,
      "grad_norm": 0.009754961356520653,
      "learning_rate": 0.0009798734541271211,
      "loss": 0.0037,
      "step": 3500
    },
    {
      "epoch": 1.0209951107276387,
      "grad_norm": 0.03139939159154892,
      "learning_rate": 0.000979585849870578,
      "loss": 0.0027,
      "step": 3550
    },
    {
      "epoch": 1.0353753235547887,
      "grad_norm": 0.008272615261375904,
      "learning_rate": 0.0009792982456140352,
      "loss": 0.007,
      "step": 3600
    },
    {
      "epoch": 1.0497555363819384,
      "grad_norm": 9.965107165044174e-05,
      "learning_rate": 0.000979010641357492,
      "loss": 0.0027,
      "step": 3650
    },
    {
      "epoch": 1.0641357492090884,
      "grad_norm": 0.023541774600744247,
      "learning_rate": 0.0009787230371009492,
      "loss": 0.0022,
      "step": 3700
    },
    {
      "epoch": 1.0785159620362381,
      "grad_norm": 0.0004937864141538739,
      "learning_rate": 0.000978435432844406,
      "loss": 0.004,
      "step": 3750
    },
    {
      "epoch": 1.092896174863388,
      "grad_norm": 8.657912258058786e-05,
      "learning_rate": 0.0009781478285878632,
      "loss": 0.0049,
      "step": 3800
    },
    {
      "epoch": 1.1072763876905378,
      "grad_norm": 0.00014439408550970256,
      "learning_rate": 0.0009778602243313201,
      "loss": 0.0016,
      "step": 3850
    },
    {
      "epoch": 1.1216566005176876,
      "grad_norm": 0.012785891070961952,
      "learning_rate": 0.000977572620074777,
      "loss": 0.0037,
      "step": 3900
    },
    {
      "epoch": 1.1360368133448375,
      "grad_norm": 0.0019597914069890976,
      "learning_rate": 0.0009772850158182341,
      "loss": 0.0032,
      "step": 3950
    },
    {
      "epoch": 1.1504170261719873,
      "grad_norm": 0.0001585566787980497,
      "learning_rate": 0.000976997411561691,
      "loss": 0.0044,
      "step": 4000
    },
    {
      "epoch": 1.1647972389991372,
      "grad_norm": 3.556038063834421e-05,
      "learning_rate": 0.0009767098073051482,
      "loss": 0.0027,
      "step": 4050
    },
    {
      "epoch": 1.179177451826287,
      "grad_norm": 0.007725118659436703,
      "learning_rate": 0.0009764222030486052,
      "loss": 0.0012,
      "step": 4100
    },
    {
      "epoch": 1.193557664653437,
      "grad_norm": 3.865658072754741e-05,
      "learning_rate": 0.0009761345987920621,
      "loss": 0.0016,
      "step": 4150
    },
    {
      "epoch": 1.2079378774805867,
      "grad_norm": 0.013407135382294655,
      "learning_rate": 0.0009758469945355192,
      "loss": 0.0017,
      "step": 4200
    },
    {
      "epoch": 1.2223180903077366,
      "grad_norm": 6.33817253401503e-05,
      "learning_rate": 0.0009755593902789761,
      "loss": 0.003,
      "step": 4250
    },
    {
      "epoch": 1.2366983031348864,
      "grad_norm": 0.006412843242287636,
      "learning_rate": 0.0009752717860224331,
      "loss": 0.0036,
      "step": 4300
    },
    {
      "epoch": 1.2510785159620363,
      "grad_norm": 0.1075318306684494,
      "learning_rate": 0.0009749841817658902,
      "loss": 0.0013,
      "step": 4350
    },
    {
      "epoch": 1.265458728789186,
      "grad_norm": 0.019192812964320183,
      "learning_rate": 0.0009746965775093471,
      "loss": 0.0026,
      "step": 4400
    },
    {
      "epoch": 1.2798389416163358,
      "grad_norm": 0.006074817851185799,
      "learning_rate": 0.0009744089732528042,
      "loss": 0.0048,
      "step": 4450
    },
    {
      "epoch": 1.2942191544434858,
      "grad_norm": 0.028370512649416924,
      "learning_rate": 0.0009741213689962612,
      "loss": 0.0043,
      "step": 4500
    },
    {
      "epoch": 1.3085993672706355,
      "grad_norm": 7.091367297107354e-05,
      "learning_rate": 0.0009738337647397182,
      "loss": 0.0037,
      "step": 4550
    },
    {
      "epoch": 1.3229795800977855,
      "grad_norm": 0.002319993916898966,
      "learning_rate": 0.0009735461604831751,
      "loss": 0.0056,
      "step": 4600
    },
    {
      "epoch": 1.3373597929249352,
      "grad_norm": 0.13990935683250427,
      "learning_rate": 0.0009732585562266322,
      "loss": 0.0023,
      "step": 4650
    },
    {
      "epoch": 1.3517400057520852,
      "grad_norm": 0.004705186001956463,
      "learning_rate": 0.0009729709519700892,
      "loss": 0.0015,
      "step": 4700
    },
    {
      "epoch": 1.366120218579235,
      "grad_norm": 0.0036986463237553835,
      "learning_rate": 0.0009726833477135461,
      "loss": 0.0029,
      "step": 4750
    },
    {
      "epoch": 1.380500431406385,
      "grad_norm": 0.01458203699439764,
      "learning_rate": 0.0009723957434570032,
      "loss": 0.0031,
      "step": 4800
    },
    {
      "epoch": 1.3948806442335346,
      "grad_norm": 0.04298722371459007,
      "learning_rate": 0.0009721081392004601,
      "loss": 0.0053,
      "step": 4850
    },
    {
      "epoch": 1.4092608570606844,
      "grad_norm": 5.943630458205007e-05,
      "learning_rate": 0.0009718205349439172,
      "loss": 0.0044,
      "step": 4900
    },
    {
      "epoch": 1.4236410698878343,
      "grad_norm": 0.0036376933567225933,
      "learning_rate": 0.0009715329306873742,
      "loss": 0.0039,
      "step": 4950
    },
    {
      "epoch": 1.4380212827149843,
      "grad_norm": 0.019978607073426247,
      "learning_rate": 0.0009712453264308312,
      "loss": 0.0013,
      "step": 5000
    },
    {
      "epoch": 1.452401495542134,
      "grad_norm": 0.0002413079491816461,
      "learning_rate": 0.0009709577221742882,
      "loss": 0.0018,
      "step": 5050
    },
    {
      "epoch": 1.4667817083692838,
      "grad_norm": 0.0003795045777224004,
      "learning_rate": 0.0009706701179177452,
      "loss": 0.0041,
      "step": 5100
    },
    {
      "epoch": 1.4811619211964338,
      "grad_norm": 0.00034887896617874503,
      "learning_rate": 0.0009703825136612022,
      "loss": 0.001,
      "step": 5150
    },
    {
      "epoch": 1.4955421340235835,
      "grad_norm": 0.0004104595282115042,
      "learning_rate": 0.0009700949094046591,
      "loss": 0.0034,
      "step": 5200
    },
    {
      "epoch": 1.5099223468507335,
      "grad_norm": 5.1681552577065304e-05,
      "learning_rate": 0.0009698073051481162,
      "loss": 0.0024,
      "step": 5250
    },
    {
      "epoch": 1.5243025596778832,
      "grad_norm": 0.0003440764849074185,
      "learning_rate": 0.0009695197008915733,
      "loss": 0.0029,
      "step": 5300
    },
    {
      "epoch": 1.538682772505033,
      "grad_norm": 0.0005658677546307445,
      "learning_rate": 0.0009692320966350302,
      "loss": 0.001,
      "step": 5350
    },
    {
      "epoch": 1.553062985332183,
      "grad_norm": 6.828064215369523e-05,
      "learning_rate": 0.0009689444923784873,
      "loss": 0.0029,
      "step": 5400
    },
    {
      "epoch": 1.5674431981593329,
      "grad_norm": 0.013597770594060421,
      "learning_rate": 0.0009686568881219442,
      "loss": 0.0025,
      "step": 5450
    },
    {
      "epoch": 1.5818234109864826,
      "grad_norm": 0.0003568984102457762,
      "learning_rate": 0.0009683692838654012,
      "loss": 0.0047,
      "step": 5500
    },
    {
      "epoch": 1.5962036238136323,
      "grad_norm": 0.00015433099179062992,
      "learning_rate": 0.0009680816796088582,
      "loss": 0.0036,
      "step": 5550
    },
    {
      "epoch": 1.6105838366407823,
      "grad_norm": 0.009810705669224262,
      "learning_rate": 0.0009677940753523152,
      "loss": 0.0047,
      "step": 5600
    },
    {
      "epoch": 1.6249640494679323,
      "grad_norm": 8.066683949436992e-05,
      "learning_rate": 0.0009675064710957722,
      "loss": 0.0016,
      "step": 5650
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 0.0492708720266819,
      "learning_rate": 0.0009672188668392292,
      "loss": 0.0035,
      "step": 5700
    },
    {
      "epoch": 1.6537244751222318,
      "grad_norm": 0.0001323063625022769,
      "learning_rate": 0.0009669312625826863,
      "loss": 0.0035,
      "step": 5750
    },
    {
      "epoch": 1.6681046879493815,
      "grad_norm": 0.011773107573390007,
      "learning_rate": 0.0009666436583261432,
      "loss": 0.0014,
      "step": 5800
    },
    {
      "epoch": 1.6824849007765315,
      "grad_norm": 0.0003079260641243309,
      "learning_rate": 0.0009663560540696003,
      "loss": 0.0033,
      "step": 5850
    },
    {
      "epoch": 1.6968651136036814,
      "grad_norm": 0.02149929478764534,
      "learning_rate": 0.0009660684498130573,
      "loss": 0.0016,
      "step": 5900
    },
    {
      "epoch": 1.7112453264308312,
      "grad_norm": 0.00030603562481701374,
      "learning_rate": 0.0009657808455565142,
      "loss": 0.0011,
      "step": 5950
    },
    {
      "epoch": 1.725625539257981,
      "grad_norm": 0.0013101417571306229,
      "learning_rate": 0.0009654932412999713,
      "loss": 0.0039,
      "step": 6000
    },
    {
      "epoch": 1.7400057520851309,
      "grad_norm": 0.00011521608394104987,
      "learning_rate": 0.0009652056370434282,
      "loss": 0.0016,
      "step": 6050
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 6.444870086852461e-05,
      "learning_rate": 0.0009649180327868852,
      "loss": 0.0053,
      "step": 6100
    },
    {
      "epoch": 1.7687661777394306,
      "grad_norm": 0.00044376589357852936,
      "learning_rate": 0.0009646304285303422,
      "loss": 0.0025,
      "step": 6150
    },
    {
      "epoch": 1.7831463905665803,
      "grad_norm": 0.00033688644180074334,
      "learning_rate": 0.0009643428242737993,
      "loss": 0.0018,
      "step": 6200
    },
    {
      "epoch": 1.7975266033937303,
      "grad_norm": 0.09610094130039215,
      "learning_rate": 0.0009640552200172563,
      "loss": 0.0035,
      "step": 6250
    },
    {
      "epoch": 1.8119068162208802,
      "grad_norm": 0.0006489279330708086,
      "learning_rate": 0.0009637676157607133,
      "loss": 0.0032,
      "step": 6300
    },
    {
      "epoch": 1.82628702904803,
      "grad_norm": 5.8993755374103785e-05,
      "learning_rate": 0.0009634800115041703,
      "loss": 0.0022,
      "step": 6350
    },
    {
      "epoch": 1.8406672418751797,
      "grad_norm": 0.03404868766665459,
      "learning_rate": 0.0009631924072476272,
      "loss": 0.0039,
      "step": 6400
    },
    {
      "epoch": 1.8550474547023295,
      "grad_norm": 0.015702996402978897,
      "learning_rate": 0.0009629048029910843,
      "loss": 0.0034,
      "step": 6450
    },
    {
      "epoch": 1.8694276675294794,
      "grad_norm": 0.0705474391579628,
      "learning_rate": 0.0009626171987345413,
      "loss": 0.0013,
      "step": 6500
    },
    {
      "epoch": 1.8838078803566294,
      "grad_norm": 0.006491455715149641,
      "learning_rate": 0.0009623295944779982,
      "loss": 0.0005,
      "step": 6550
    },
    {
      "epoch": 1.8981880931837791,
      "grad_norm": 0.00020299822790548205,
      "learning_rate": 0.0009620419902214554,
      "loss": 0.0011,
      "step": 6600
    },
    {
      "epoch": 1.9125683060109289,
      "grad_norm": 0.011748632416129112,
      "learning_rate": 0.0009617543859649123,
      "loss": 0.0043,
      "step": 6650
    },
    {
      "epoch": 1.9269485188380788,
      "grad_norm": 0.002633544383570552,
      "learning_rate": 0.0009614667817083693,
      "loss": 0.0051,
      "step": 6700
    },
    {
      "epoch": 1.9413287316652288,
      "grad_norm": 0.09657678008079529,
      "learning_rate": 0.0009611791774518263,
      "loss": 0.0033,
      "step": 6750
    },
    {
      "epoch": 1.9557089444923785,
      "grad_norm": 0.0006544971838593483,
      "learning_rate": 0.0009608915731952833,
      "loss": 0.0071,
      "step": 6800
    },
    {
      "epoch": 1.9700891573195283,
      "grad_norm": 0.004904814995825291,
      "learning_rate": 0.0009606039689387403,
      "loss": 0.0049,
      "step": 6850
    },
    {
      "epoch": 1.984469370146678,
      "grad_norm": 0.00127464160323143,
      "learning_rate": 0.0009603163646821973,
      "loss": 0.0046,
      "step": 6900
    },
    {
      "epoch": 1.998849582973828,
      "grad_norm": 0.01621692068874836,
      "learning_rate": 0.0009600287604256543,
      "loss": 0.005,
      "step": 6950
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.016112234443426132,
      "eval_runtime": 11.8145,
      "eval_samples_per_second": 4039.03,
      "eval_steps_per_second": 63.143,
      "step": 6954
    },
    {
      "epoch": 2.013229795800978,
      "grad_norm": 0.09192188829183578,
      "learning_rate": 0.0009597411561691112,
      "loss": 0.0043,
      "step": 7000
    },
    {
      "epoch": 2.0276100086281277,
      "grad_norm": 0.030776482075452805,
      "learning_rate": 0.0009594535519125684,
      "loss": 0.003,
      "step": 7050
    },
    {
      "epoch": 2.0419902214552774,
      "grad_norm": 7.73219799157232e-05,
      "learning_rate": 0.0009591659476560254,
      "loss": 0.0029,
      "step": 7100
    },
    {
      "epoch": 2.056370434282427,
      "grad_norm": 0.17571724951267242,
      "learning_rate": 0.0009588783433994823,
      "loss": 0.0018,
      "step": 7150
    },
    {
      "epoch": 2.0707506471095773,
      "grad_norm": 0.0007065823883749545,
      "learning_rate": 0.0009585907391429394,
      "loss": 0.0034,
      "step": 7200
    },
    {
      "epoch": 2.085130859936727,
      "grad_norm": 0.03400164097547531,
      "learning_rate": 0.0009583031348863963,
      "loss": 0.0015,
      "step": 7250
    },
    {
      "epoch": 2.099511072763877,
      "grad_norm": 4.87729994347319e-05,
      "learning_rate": 0.0009580155306298533,
      "loss": 0.0017,
      "step": 7300
    },
    {
      "epoch": 2.1138912855910266,
      "grad_norm": 0.00010461999045219272,
      "learning_rate": 0.0009577279263733103,
      "loss": 0.0045,
      "step": 7350
    },
    {
      "epoch": 2.1282714984181768,
      "grad_norm": 0.025911932811141014,
      "learning_rate": 0.0009574403221167673,
      "loss": 0.0055,
      "step": 7400
    },
    {
      "epoch": 2.1426517112453265,
      "grad_norm": 0.13917988538742065,
      "learning_rate": 0.0009571527178602243,
      "loss": 0.0039,
      "step": 7450
    },
    {
      "epoch": 2.1570319240724762,
      "grad_norm": 0.00045692126150242984,
      "learning_rate": 0.0009568651136036814,
      "loss": 0.0046,
      "step": 7500
    },
    {
      "epoch": 2.171412136899626,
      "grad_norm": 0.00012742338003590703,
      "learning_rate": 0.0009565775093471384,
      "loss": 0.0024,
      "step": 7550
    },
    {
      "epoch": 2.185792349726776,
      "grad_norm": 0.029087373986840248,
      "learning_rate": 0.0009562899050905953,
      "loss": 0.003,
      "step": 7600
    },
    {
      "epoch": 2.200172562553926,
      "grad_norm": 0.0052584814839065075,
      "learning_rate": 0.0009560023008340524,
      "loss": 0.0028,
      "step": 7650
    },
    {
      "epoch": 2.2145527753810756,
      "grad_norm": 0.04718500375747681,
      "learning_rate": 0.0009557146965775093,
      "loss": 0.0019,
      "step": 7700
    },
    {
      "epoch": 2.2289329882082254,
      "grad_norm": 0.025497425347566605,
      "learning_rate": 0.0009554270923209663,
      "loss": 0.0037,
      "step": 7750
    },
    {
      "epoch": 2.243313201035375,
      "grad_norm": 0.0014463945990428329,
      "learning_rate": 0.0009551394880644234,
      "loss": 0.0037,
      "step": 7800
    },
    {
      "epoch": 2.2576934138625253,
      "grad_norm": 0.01315535418689251,
      "learning_rate": 0.0009548518838078803,
      "loss": 0.0022,
      "step": 7850
    },
    {
      "epoch": 2.272073626689675,
      "grad_norm": 0.00022545584943145514,
      "learning_rate": 0.0009545642795513374,
      "loss": 0.0021,
      "step": 7900
    },
    {
      "epoch": 2.286453839516825,
      "grad_norm": 0.040678080171346664,
      "learning_rate": 0.0009542766752947944,
      "loss": 0.0032,
      "step": 7950
    },
    {
      "epoch": 2.3008340523439745,
      "grad_norm": 0.0003118684107903391,
      "learning_rate": 0.0009539890710382514,
      "loss": 0.0033,
      "step": 8000
    },
    {
      "epoch": 2.3152142651711247,
      "grad_norm": 0.014740400947630405,
      "learning_rate": 0.0009537014667817084,
      "loss": 0.0032,
      "step": 8050
    },
    {
      "epoch": 2.3295944779982745,
      "grad_norm": 6.236427725525573e-05,
      "learning_rate": 0.0009534138625251654,
      "loss": 0.0021,
      "step": 8100
    },
    {
      "epoch": 2.343974690825424,
      "grad_norm": 0.0003365646698512137,
      "learning_rate": 0.0009531262582686224,
      "loss": 0.0054,
      "step": 8150
    },
    {
      "epoch": 2.358354903652574,
      "grad_norm": 0.07410228252410889,
      "learning_rate": 0.0009528386540120793,
      "loss": 0.0019,
      "step": 8200
    },
    {
      "epoch": 2.372735116479724,
      "grad_norm": 0.0006886492483317852,
      "learning_rate": 0.0009525510497555364,
      "loss": 0.0023,
      "step": 8250
    },
    {
      "epoch": 2.387115329306874,
      "grad_norm": 0.0006598626496270299,
      "learning_rate": 0.0009522634454989933,
      "loss": 0.0026,
      "step": 8300
    },
    {
      "epoch": 2.4014955421340236,
      "grad_norm": 0.0013055297313258052,
      "learning_rate": 0.0009519758412424504,
      "loss": 0.0017,
      "step": 8350
    },
    {
      "epoch": 2.4158757549611733,
      "grad_norm": 0.0008383662207052112,
      "learning_rate": 0.0009516882369859075,
      "loss": 0.0017,
      "step": 8400
    },
    {
      "epoch": 2.430255967788323,
      "grad_norm": 0.00038502682582475245,
      "learning_rate": 0.0009514006327293644,
      "loss": 0.003,
      "step": 8450
    },
    {
      "epoch": 2.4446361806154733,
      "grad_norm": 8.337804320035502e-05,
      "learning_rate": 0.0009511130284728214,
      "loss": 0.0022,
      "step": 8500
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.17095889151096344,
      "learning_rate": 0.0009508254242162784,
      "loss": 0.001,
      "step": 8550
    },
    {
      "epoch": 2.4733966062697728,
      "grad_norm": 0.02485545165836811,
      "learning_rate": 0.0009505378199597354,
      "loss": 0.0012,
      "step": 8600
    },
    {
      "epoch": 2.4877768190969225,
      "grad_norm": 0.006579098291695118,
      "learning_rate": 0.0009502502157031924,
      "loss": 0.0052,
      "step": 8650
    },
    {
      "epoch": 2.5021570319240727,
      "grad_norm": 0.00220467709004879,
      "learning_rate": 0.0009499626114466494,
      "loss": 0.0025,
      "step": 8700
    },
    {
      "epoch": 2.5165372447512224,
      "grad_norm": 0.005649572238326073,
      "learning_rate": 0.0009496750071901065,
      "loss": 0.0039,
      "step": 8750
    },
    {
      "epoch": 2.530917457578372,
      "grad_norm": 0.05722532048821449,
      "learning_rate": 0.0009493874029335634,
      "loss": 0.0014,
      "step": 8800
    },
    {
      "epoch": 2.545297670405522,
      "grad_norm": 0.014648392796516418,
      "learning_rate": 0.0009490997986770205,
      "loss": 0.0014,
      "step": 8850
    },
    {
      "epoch": 2.5596778832326716,
      "grad_norm": 0.01570693962275982,
      "learning_rate": 0.0009488121944204774,
      "loss": 0.0038,
      "step": 8900
    },
    {
      "epoch": 2.574058096059822,
      "grad_norm": 0.00010018291504820809,
      "learning_rate": 0.0009485245901639344,
      "loss": 0.0028,
      "step": 8950
    },
    {
      "epoch": 2.5884383088869716,
      "grad_norm": 8.562261064071208e-05,
      "learning_rate": 0.0009482369859073915,
      "loss": 0.0025,
      "step": 9000
    },
    {
      "epoch": 2.6028185217141213,
      "grad_norm": 0.00020693179976660758,
      "learning_rate": 0.0009479493816508484,
      "loss": 0.0025,
      "step": 9050
    },
    {
      "epoch": 2.617198734541271,
      "grad_norm": 0.0002717121096793562,
      "learning_rate": 0.0009476617773943054,
      "loss": 0.0057,
      "step": 9100
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.0011447793804109097,
      "learning_rate": 0.0009473741731377624,
      "loss": 0.0035,
      "step": 9150
    },
    {
      "epoch": 2.645959160195571,
      "grad_norm": 0.015742221847176552,
      "learning_rate": 0.0009470865688812195,
      "loss": 0.0031,
      "step": 9200
    },
    {
      "epoch": 2.6603393730227207,
      "grad_norm": 0.00022382664610631764,
      "learning_rate": 0.0009467989646246765,
      "loss": 0.0009,
      "step": 9250
    },
    {
      "epoch": 2.6747195858498705,
      "grad_norm": 0.000334268988808617,
      "learning_rate": 0.0009465113603681335,
      "loss": 0.0043,
      "step": 9300
    },
    {
      "epoch": 2.68909979867702,
      "grad_norm": 0.00019330681243445724,
      "learning_rate": 0.0009462237561115905,
      "loss": 0.0014,
      "step": 9350
    },
    {
      "epoch": 2.7034800115041704,
      "grad_norm": 0.0006579176988452673,
      "learning_rate": 0.0009459361518550474,
      "loss": 0.0072,
      "step": 9400
    },
    {
      "epoch": 2.71786022433132,
      "grad_norm": 0.0008410006994381547,
      "learning_rate": 0.0009456485475985045,
      "loss": 0.0015,
      "step": 9450
    },
    {
      "epoch": 2.73224043715847,
      "grad_norm": 0.0013648975873365998,
      "learning_rate": 0.0009453609433419614,
      "loss": 0.003,
      "step": 9500
    },
    {
      "epoch": 2.74662064998562,
      "grad_norm": 8.790647552814335e-05,
      "learning_rate": 0.0009450733390854184,
      "loss": 0.002,
      "step": 9550
    },
    {
      "epoch": 2.76100086281277,
      "grad_norm": 0.02293272688984871,
      "learning_rate": 0.0009447857348288756,
      "loss": 0.0057,
      "step": 9600
    },
    {
      "epoch": 2.7753810756399195,
      "grad_norm": 0.00352213392034173,
      "learning_rate": 0.0009444981305723325,
      "loss": 0.0037,
      "step": 9650
    },
    {
      "epoch": 2.7897612884670693,
      "grad_norm": 0.000510665588080883,
      "learning_rate": 0.0009442105263157895,
      "loss": 0.004,
      "step": 9700
    },
    {
      "epoch": 2.804141501294219,
      "grad_norm": 0.00037732490454800427,
      "learning_rate": 0.0009439229220592465,
      "loss": 0.0034,
      "step": 9750
    },
    {
      "epoch": 2.8185217141213688,
      "grad_norm": 0.09515118598937988,
      "learning_rate": 0.0009436353178027035,
      "loss": 0.0056,
      "step": 9800
    },
    {
      "epoch": 2.832901926948519,
      "grad_norm": 0.4724595248699188,
      "learning_rate": 0.0009433477135461605,
      "loss": 0.0012,
      "step": 9850
    },
    {
      "epoch": 2.8472821397756687,
      "grad_norm": 0.0005549254710786045,
      "learning_rate": 0.0009430601092896175,
      "loss": 0.0049,
      "step": 9900
    },
    {
      "epoch": 2.8616623526028184,
      "grad_norm": 7.560486119473353e-05,
      "learning_rate": 0.0009427725050330745,
      "loss": 0.0027,
      "step": 9950
    },
    {
      "epoch": 2.8760425654299686,
      "grad_norm": 0.0002122340229107067,
      "learning_rate": 0.0009424849007765314,
      "loss": 0.0044,
      "step": 10000
    },
    {
      "epoch": 2.8904227782571184,
      "grad_norm": 0.00028444838244467974,
      "learning_rate": 0.0009421972965199886,
      "loss": 0.0044,
      "step": 10050
    },
    {
      "epoch": 2.904802991084268,
      "grad_norm": 0.0715881884098053,
      "learning_rate": 0.0009419096922634455,
      "loss": 0.0027,
      "step": 10100
    },
    {
      "epoch": 2.919183203911418,
      "grad_norm": 0.004729419481009245,
      "learning_rate": 0.0009416220880069025,
      "loss": 0.0008,
      "step": 10150
    },
    {
      "epoch": 2.9335634167385676,
      "grad_norm": 3.429011849220842e-05,
      "learning_rate": 0.0009413344837503596,
      "loss": 0.0029,
      "step": 10200
    },
    {
      "epoch": 2.9479436295657173,
      "grad_norm": 0.03343036025762558,
      "learning_rate": 0.0009410468794938165,
      "loss": 0.0058,
      "step": 10250
    },
    {
      "epoch": 2.9623238423928675,
      "grad_norm": 0.007687288802117109,
      "learning_rate": 0.0009407592752372735,
      "loss": 0.0045,
      "step": 10300
    },
    {
      "epoch": 2.9767040552200172,
      "grad_norm": 0.0031680131796747446,
      "learning_rate": 0.0009404716709807305,
      "loss": 0.0022,
      "step": 10350
    },
    {
      "epoch": 2.991084268047167,
      "grad_norm": 0.05161469802260399,
      "learning_rate": 0.0009401840667241875,
      "loss": 0.0016,
      "step": 10400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.011963270604610443,
      "eval_runtime": 11.6679,
      "eval_samples_per_second": 4089.766,
      "eval_steps_per_second": 63.936,
      "step": 10431
    },
    {
      "epoch": 3.0054644808743167,
      "grad_norm": 0.0008694123825989664,
      "learning_rate": 0.0009398964624676444,
      "loss": 0.0049,
      "step": 10450
    },
    {
      "epoch": 3.019844693701467,
      "grad_norm": 0.00043227989226579666,
      "learning_rate": 0.0009396088582111016,
      "loss": 0.003,
      "step": 10500
    },
    {
      "epoch": 3.0342249065286166,
      "grad_norm": 0.00031415646662935615,
      "learning_rate": 0.0009393212539545586,
      "loss": 0.0031,
      "step": 10550
    },
    {
      "epoch": 3.0486051193557664,
      "grad_norm": 0.0011669520754367113,
      "learning_rate": 0.0009390336496980155,
      "loss": 0.0044,
      "step": 10600
    },
    {
      "epoch": 3.062985332182916,
      "grad_norm": 0.00019655619689729065,
      "learning_rate": 0.0009387460454414726,
      "loss": 0.0046,
      "step": 10650
    },
    {
      "epoch": 3.0773655450100663,
      "grad_norm": 0.016835173591971397,
      "learning_rate": 0.0009384584411849295,
      "loss": 0.0019,
      "step": 10700
    },
    {
      "epoch": 3.091745757837216,
      "grad_norm": 0.0031478244345635176,
      "learning_rate": 0.0009381708369283865,
      "loss": 0.0037,
      "step": 10750
    },
    {
      "epoch": 3.106125970664366,
      "grad_norm": 3.212361116311513e-05,
      "learning_rate": 0.0009378832326718436,
      "loss": 0.0022,
      "step": 10800
    },
    {
      "epoch": 3.1205061834915155,
      "grad_norm": 0.0006213514716364443,
      "learning_rate": 0.0009375956284153005,
      "loss": 0.0032,
      "step": 10850
    },
    {
      "epoch": 3.1348863963186657,
      "grad_norm": 0.00017949374159798026,
      "learning_rate": 0.0009373080241587575,
      "loss": 0.0006,
      "step": 10900
    },
    {
      "epoch": 3.1492666091458155,
      "grad_norm": 0.00047790491953492165,
      "learning_rate": 0.0009370204199022146,
      "loss": 0.0042,
      "step": 10950
    },
    {
      "epoch": 3.163646821972965,
      "grad_norm": 3.637260306277312e-05,
      "learning_rate": 0.0009367328156456716,
      "loss": 0.0037,
      "step": 11000
    },
    {
      "epoch": 3.178027034800115,
      "grad_norm": 0.00012680699001066387,
      "learning_rate": 0.0009364452113891285,
      "loss": 0.0029,
      "step": 11050
    },
    {
      "epoch": 3.1924072476272647,
      "grad_norm": 0.0005966297467239201,
      "learning_rate": 0.0009361576071325856,
      "loss": 0.0014,
      "step": 11100
    },
    {
      "epoch": 3.206787460454415,
      "grad_norm": 0.014253111556172371,
      "learning_rate": 0.0009358700028760426,
      "loss": 0.0064,
      "step": 11150
    },
    {
      "epoch": 3.2211676732815646,
      "grad_norm": 0.013751904480159283,
      "learning_rate": 0.0009355823986194995,
      "loss": 0.0039,
      "step": 11200
    },
    {
      "epoch": 3.2355478861087144,
      "grad_norm": 0.0016971369041129947,
      "learning_rate": 0.0009352947943629566,
      "loss": 0.0007,
      "step": 11250
    },
    {
      "epoch": 3.249928098935864,
      "grad_norm": 0.013169731013476849,
      "learning_rate": 0.0009350071901064135,
      "loss": 0.0033,
      "step": 11300
    },
    {
      "epoch": 3.2643083117630143,
      "grad_norm": 3.430875949561596e-05,
      "learning_rate": 0.0009347195858498705,
      "loss": 0.0024,
      "step": 11350
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 0.009585145860910416,
      "learning_rate": 0.0009344319815933277,
      "loss": 0.0015,
      "step": 11400
    },
    {
      "epoch": 3.2930687374173138,
      "grad_norm": 0.05778784304857254,
      "learning_rate": 0.0009341443773367846,
      "loss": 0.0025,
      "step": 11450
    },
    {
      "epoch": 3.3074489502444635,
      "grad_norm": 0.08357667177915573,
      "learning_rate": 0.0009338567730802416,
      "loss": 0.0024,
      "step": 11500
    },
    {
      "epoch": 3.3218291630716132,
      "grad_norm": 0.0006315691280178726,
      "learning_rate": 0.0009335691688236986,
      "loss": 0.002,
      "step": 11550
    },
    {
      "epoch": 3.3362093758987634,
      "grad_norm": 0.0005474197096191347,
      "learning_rate": 0.0009332815645671556,
      "loss": 0.0011,
      "step": 11600
    },
    {
      "epoch": 3.350589588725913,
      "grad_norm": 9.476417471887544e-05,
      "learning_rate": 0.0009329939603106125,
      "loss": 0.0026,
      "step": 11650
    },
    {
      "epoch": 3.364969801553063,
      "grad_norm": 0.0005110162892378867,
      "learning_rate": 0.0009327063560540696,
      "loss": 0.0009,
      "step": 11700
    },
    {
      "epoch": 3.3793500143802127,
      "grad_norm": 0.01417919248342514,
      "learning_rate": 0.0009324187517975266,
      "loss": 0.0037,
      "step": 11750
    },
    {
      "epoch": 3.393730227207363,
      "grad_norm": 0.0031034292187541723,
      "learning_rate": 0.0009321311475409836,
      "loss": 0.0047,
      "step": 11800
    },
    {
      "epoch": 3.4081104400345126,
      "grad_norm": 0.0037769272457808256,
      "learning_rate": 0.0009318435432844407,
      "loss": 0.0035,
      "step": 11850
    },
    {
      "epoch": 3.4224906528616623,
      "grad_norm": 0.029744252562522888,
      "learning_rate": 0.0009315559390278976,
      "loss": 0.0068,
      "step": 11900
    },
    {
      "epoch": 3.436870865688812,
      "grad_norm": 0.00023365857487078756,
      "learning_rate": 0.0009312683347713546,
      "loss": 0.0125,
      "step": 11950
    },
    {
      "epoch": 3.451251078515962,
      "grad_norm": 0.010501772165298462,
      "learning_rate": 0.0009309807305148117,
      "loss": 0.003,
      "step": 12000
    },
    {
      "epoch": 3.465631291343112,
      "grad_norm": 0.0007438980392180383,
      "learning_rate": 0.0009306931262582686,
      "loss": 0.0019,
      "step": 12050
    },
    {
      "epoch": 3.4800115041702617,
      "grad_norm": 0.10052170604467392,
      "learning_rate": 0.0009304055220017257,
      "loss": 0.0035,
      "step": 12100
    },
    {
      "epoch": 3.4943917169974115,
      "grad_norm": 0.0006441482109948993,
      "learning_rate": 0.0009301179177451826,
      "loss": 0.0043,
      "step": 12150
    },
    {
      "epoch": 3.5087719298245617,
      "grad_norm": 0.0004940174985677004,
      "learning_rate": 0.0009298303134886396,
      "loss": 0.0046,
      "step": 12200
    },
    {
      "epoch": 3.5231521426517114,
      "grad_norm": 0.1325211375951767,
      "learning_rate": 0.0009295427092320966,
      "loss": 0.0055,
      "step": 12250
    },
    {
      "epoch": 3.537532355478861,
      "grad_norm": 0.00014360429486259818,
      "learning_rate": 0.0009292551049755537,
      "loss": 0.0024,
      "step": 12300
    },
    {
      "epoch": 3.551912568306011,
      "grad_norm": 0.00028062681667506695,
      "learning_rate": 0.0009289675007190107,
      "loss": 0.0026,
      "step": 12350
    },
    {
      "epoch": 3.5662927811331606,
      "grad_norm": 0.0013183553237468004,
      "learning_rate": 0.0009286798964624676,
      "loss": 0.0049,
      "step": 12400
    },
    {
      "epoch": 3.5806729939603104,
      "grad_norm": 0.06826287508010864,
      "learning_rate": 0.0009283922922059247,
      "loss": 0.0038,
      "step": 12450
    },
    {
      "epoch": 3.5950532067874605,
      "grad_norm": 0.0006957303266972303,
      "learning_rate": 0.0009281046879493816,
      "loss": 0.0048,
      "step": 12500
    },
    {
      "epoch": 3.6094334196146103,
      "grad_norm": 0.00011014387564500794,
      "learning_rate": 0.0009278170836928387,
      "loss": 0.0043,
      "step": 12550
    },
    {
      "epoch": 3.62381363244176,
      "grad_norm": 0.10102663934230804,
      "learning_rate": 0.0009275294794362957,
      "loss": 0.0023,
      "step": 12600
    },
    {
      "epoch": 3.63819384526891,
      "grad_norm": 9.103192860493436e-05,
      "learning_rate": 0.0009272418751797527,
      "loss": 0.0027,
      "step": 12650
    },
    {
      "epoch": 3.65257405809606,
      "grad_norm": 0.00023744706413708627,
      "learning_rate": 0.0009269542709232098,
      "loss": 0.0038,
      "step": 12700
    },
    {
      "epoch": 3.6669542709232097,
      "grad_norm": 6.188070256030187e-05,
      "learning_rate": 0.0009266666666666667,
      "loss": 0.0033,
      "step": 12750
    },
    {
      "epoch": 3.6813344837503594,
      "grad_norm": 0.06600938737392426,
      "learning_rate": 0.0009263790624101237,
      "loss": 0.0055,
      "step": 12800
    },
    {
      "epoch": 3.695714696577509,
      "grad_norm": 0.060541097074747086,
      "learning_rate": 0.0009260914581535806,
      "loss": 0.0035,
      "step": 12850
    },
    {
      "epoch": 3.710094909404659,
      "grad_norm": 0.05300794914364815,
      "learning_rate": 0.0009258038538970377,
      "loss": 0.0034,
      "step": 12900
    },
    {
      "epoch": 3.724475122231809,
      "grad_norm": 0.0012041769223287702,
      "learning_rate": 0.0009255162496404947,
      "loss": 0.0009,
      "step": 12950
    },
    {
      "epoch": 3.738855335058959,
      "grad_norm": 0.013065731152892113,
      "learning_rate": 0.0009252286453839517,
      "loss": 0.0047,
      "step": 13000
    },
    {
      "epoch": 3.7532355478861086,
      "grad_norm": 0.003848481923341751,
      "learning_rate": 0.0009249410411274087,
      "loss": 0.0075,
      "step": 13050
    },
    {
      "epoch": 3.7676157607132588,
      "grad_norm": 6.562617636518553e-05,
      "learning_rate": 0.0009246534368708657,
      "loss": 0.0016,
      "step": 13100
    },
    {
      "epoch": 3.7819959735404085,
      "grad_norm": 0.00033417955273762345,
      "learning_rate": 0.0009243658326143228,
      "loss": 0.0067,
      "step": 13150
    },
    {
      "epoch": 3.7963761863675582,
      "grad_norm": 6.663114618277177e-05,
      "learning_rate": 0.0009240782283577797,
      "loss": 0.0039,
      "step": 13200
    },
    {
      "epoch": 3.810756399194708,
      "grad_norm": 4.1464103560429066e-05,
      "learning_rate": 0.0009237906241012367,
      "loss": 0.0034,
      "step": 13250
    },
    {
      "epoch": 3.8251366120218577,
      "grad_norm": 0.013676839880645275,
      "learning_rate": 0.0009235030198446938,
      "loss": 0.0007,
      "step": 13300
    },
    {
      "epoch": 3.839516824849008,
      "grad_norm": 0.0007276547257788479,
      "learning_rate": 0.0009232154155881507,
      "loss": 0.003,
      "step": 13350
    },
    {
      "epoch": 3.8538970376761577,
      "grad_norm": 0.018529260531067848,
      "learning_rate": 0.0009229278113316077,
      "loss": 0.0006,
      "step": 13400
    },
    {
      "epoch": 3.8682772505033074,
      "grad_norm": 0.010774587281048298,
      "learning_rate": 0.0009226402070750647,
      "loss": 0.0024,
      "step": 13450
    },
    {
      "epoch": 3.882657463330457,
      "grad_norm": 3.088300582021475e-05,
      "learning_rate": 0.0009223526028185218,
      "loss": 0.0063,
      "step": 13500
    },
    {
      "epoch": 3.8970376761576073,
      "grad_norm": 6.53043098282069e-05,
      "learning_rate": 0.0009220649985619788,
      "loss": 0.004,
      "step": 13550
    },
    {
      "epoch": 3.911417888984757,
      "grad_norm": 4.700461067841388e-05,
      "learning_rate": 0.0009217773943054358,
      "loss": 0.002,
      "step": 13600
    },
    {
      "epoch": 3.925798101811907,
      "grad_norm": 0.0003478385042399168,
      "learning_rate": 0.0009214897900488928,
      "loss": 0.0026,
      "step": 13650
    },
    {
      "epoch": 3.9401783146390565,
      "grad_norm": 6.562468479387462e-05,
      "learning_rate": 0.0009212021857923497,
      "loss": 0.0048,
      "step": 13700
    },
    {
      "epoch": 3.9545585274662063,
      "grad_norm": 0.07920802384614944,
      "learning_rate": 0.0009209145815358068,
      "loss": 0.0038,
      "step": 13750
    },
    {
      "epoch": 3.9689387402933565,
      "grad_norm": 0.00043637133785523474,
      "learning_rate": 0.0009206269772792637,
      "loss": 0.0017,
      "step": 13800
    },
    {
      "epoch": 3.983318953120506,
      "grad_norm": 0.030993575230240822,
      "learning_rate": 0.0009203393730227207,
      "loss": 0.0045,
      "step": 13850
    },
    {
      "epoch": 3.997699165947656,
      "grad_norm": 0.00013050275447312742,
      "learning_rate": 0.0009200517687661779,
      "loss": 0.0022,
      "step": 13900
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.011886055581271648,
      "eval_runtime": 11.7774,
      "eval_samples_per_second": 4051.76,
      "eval_steps_per_second": 63.342,
      "step": 13908
    },
    {
      "epoch": 4.012079378774806,
      "grad_norm": 0.062104232609272,
      "learning_rate": 0.0009197641645096348,
      "loss": 0.0029,
      "step": 13950
    },
    {
      "epoch": 4.026459591601956,
      "grad_norm": 0.0009343079291284084,
      "learning_rate": 0.0009194765602530918,
      "loss": 0.0065,
      "step": 14000
    },
    {
      "epoch": 4.040839804429106,
      "grad_norm": 0.0013076291652396321,
      "learning_rate": 0.0009191889559965488,
      "loss": 0.0045,
      "step": 14050
    },
    {
      "epoch": 4.055220017256255,
      "grad_norm": 0.002224151510745287,
      "learning_rate": 0.0009189013517400058,
      "loss": 0.0036,
      "step": 14100
    },
    {
      "epoch": 4.069600230083405,
      "grad_norm": 0.0002160759031539783,
      "learning_rate": 0.0009186137474834628,
      "loss": 0.0048,
      "step": 14150
    },
    {
      "epoch": 4.083980442910555,
      "grad_norm": 0.09693235903978348,
      "learning_rate": 0.0009183261432269198,
      "loss": 0.0032,
      "step": 14200
    },
    {
      "epoch": 4.098360655737705,
      "grad_norm": 0.0006509955273941159,
      "learning_rate": 0.0009180385389703768,
      "loss": 0.0012,
      "step": 14250
    },
    {
      "epoch": 4.112740868564854,
      "grad_norm": 0.00019548778072930872,
      "learning_rate": 0.0009177509347138337,
      "loss": 0.0042,
      "step": 14300
    },
    {
      "epoch": 4.127121081392005,
      "grad_norm": 0.01417627278715372,
      "learning_rate": 0.0009174633304572909,
      "loss": 0.0057,
      "step": 14350
    },
    {
      "epoch": 4.141501294219155,
      "grad_norm": 6.567312084371224e-05,
      "learning_rate": 0.0009171757262007478,
      "loss": 0.0025,
      "step": 14400
    },
    {
      "epoch": 4.155881507046304,
      "grad_norm": 0.0004805542412213981,
      "learning_rate": 0.0009168881219442048,
      "loss": 0.0024,
      "step": 14450
    },
    {
      "epoch": 4.170261719873454,
      "grad_norm": 0.0001877431495813653,
      "learning_rate": 0.0009166005176876619,
      "loss": 0.0018,
      "step": 14500
    },
    {
      "epoch": 4.184641932700604,
      "grad_norm": 0.012195011600852013,
      "learning_rate": 0.0009163129134311188,
      "loss": 0.0023,
      "step": 14550
    },
    {
      "epoch": 4.199022145527754,
      "grad_norm": 0.0006377810495905578,
      "learning_rate": 0.0009160253091745758,
      "loss": 0.0018,
      "step": 14600
    },
    {
      "epoch": 4.213402358354903,
      "grad_norm": 0.0005777584738098085,
      "learning_rate": 0.0009157377049180328,
      "loss": 0.0023,
      "step": 14650
    },
    {
      "epoch": 4.227782571182053,
      "grad_norm": 0.0029439318459481,
      "learning_rate": 0.0009154501006614898,
      "loss": 0.0027,
      "step": 14700
    },
    {
      "epoch": 4.242162784009203,
      "grad_norm": 0.035443760454654694,
      "learning_rate": 0.0009151624964049468,
      "loss": 0.0024,
      "step": 14750
    },
    {
      "epoch": 4.2565429968363535,
      "grad_norm": 0.00027303441311232746,
      "learning_rate": 0.0009148748921484039,
      "loss": 0.0032,
      "step": 14800
    },
    {
      "epoch": 4.270923209663503,
      "grad_norm": 0.010180388577282429,
      "learning_rate": 0.0009145872878918609,
      "loss": 0.0012,
      "step": 14850
    },
    {
      "epoch": 4.285303422490653,
      "grad_norm": 0.004844251554459333,
      "learning_rate": 0.0009142996836353178,
      "loss": 0.004,
      "step": 14900
    },
    {
      "epoch": 4.299683635317803,
      "grad_norm": 0.00032625600579194725,
      "learning_rate": 0.0009140120793787749,
      "loss": 0.0014,
      "step": 14950
    },
    {
      "epoch": 4.3140638481449525,
      "grad_norm": 0.0003096098662354052,
      "learning_rate": 0.0009137244751222318,
      "loss": 0.0018,
      "step": 15000
    },
    {
      "epoch": 4.328444060972102,
      "grad_norm": 0.000607251946348697,
      "learning_rate": 0.0009134368708656888,
      "loss": 0.0021,
      "step": 15050
    },
    {
      "epoch": 4.342824273799252,
      "grad_norm": 7.876236486481503e-05,
      "learning_rate": 0.0009131492666091459,
      "loss": 0.0056,
      "step": 15100
    },
    {
      "epoch": 4.357204486626402,
      "grad_norm": 0.00014069081225898117,
      "learning_rate": 0.0009128616623526028,
      "loss": 0.004,
      "step": 15150
    },
    {
      "epoch": 4.371584699453552,
      "grad_norm": 0.0028331780340522528,
      "learning_rate": 0.0009125740580960598,
      "loss": 0.0025,
      "step": 15200
    },
    {
      "epoch": 4.385964912280702,
      "grad_norm": 0.010911201126873493,
      "learning_rate": 0.0009122864538395169,
      "loss": 0.0033,
      "step": 15250
    },
    {
      "epoch": 4.400345125107852,
      "grad_norm": 0.0007157918880693614,
      "learning_rate": 0.0009119988495829739,
      "loss": 0.0022,
      "step": 15300
    },
    {
      "epoch": 4.4147253379350015,
      "grad_norm": 0.0001384925562888384,
      "learning_rate": 0.0009117112453264309,
      "loss": 0.0044,
      "step": 15350
    },
    {
      "epoch": 4.429105550762151,
      "grad_norm": 0.0024929679930210114,
      "learning_rate": 0.0009114236410698879,
      "loss": 0.0091,
      "step": 15400
    },
    {
      "epoch": 4.443485763589301,
      "grad_norm": 0.0020001432858407497,
      "learning_rate": 0.0009111360368133449,
      "loss": 0.0035,
      "step": 15450
    },
    {
      "epoch": 4.457865976416451,
      "grad_norm": 0.0429084338247776,
      "learning_rate": 0.0009108484325568018,
      "loss": 0.0075,
      "step": 15500
    },
    {
      "epoch": 4.4722461892436005,
      "grad_norm": 0.0004537580825854093,
      "learning_rate": 0.0009105608283002589,
      "loss": 0.0019,
      "step": 15550
    },
    {
      "epoch": 4.48662640207075,
      "grad_norm": 0.0040077343583106995,
      "learning_rate": 0.0009102732240437158,
      "loss": 0.0035,
      "step": 15600
    },
    {
      "epoch": 4.5010066148979,
      "grad_norm": 0.0002132353838533163,
      "learning_rate": 0.0009099856197871728,
      "loss": 0.0024,
      "step": 15650
    },
    {
      "epoch": 4.515386827725051,
      "grad_norm": 0.00010756754636531696,
      "learning_rate": 0.00090969801553063,
      "loss": 0.0011,
      "step": 15700
    },
    {
      "epoch": 4.5297670405522,
      "grad_norm": 0.005436384119093418,
      "learning_rate": 0.0009094104112740869,
      "loss": 0.0048,
      "step": 15750
    },
    {
      "epoch": 4.54414725337935,
      "grad_norm": 0.0061654988676309586,
      "learning_rate": 0.0009091228070175439,
      "loss": 0.0013,
      "step": 15800
    },
    {
      "epoch": 4.5585274662065,
      "grad_norm": 3.5750690585700795e-05,
      "learning_rate": 0.0009088352027610009,
      "loss": 0.002,
      "step": 15850
    },
    {
      "epoch": 4.57290767903365,
      "grad_norm": 0.1668982058763504,
      "learning_rate": 0.0009085475985044579,
      "loss": 0.0035,
      "step": 15900
    },
    {
      "epoch": 4.587287891860799,
      "grad_norm": 0.002619981998577714,
      "learning_rate": 0.0009082599942479148,
      "loss": 0.0036,
      "step": 15950
    },
    {
      "epoch": 4.601668104687949,
      "grad_norm": 0.0002516169915907085,
      "learning_rate": 0.0009079723899913719,
      "loss": 0.004,
      "step": 16000
    },
    {
      "epoch": 4.6160483175151,
      "grad_norm": 7.418479071930051e-05,
      "learning_rate": 0.0009076847857348289,
      "loss": 0.0022,
      "step": 16050
    },
    {
      "epoch": 4.630428530342249,
      "grad_norm": 0.000305930181639269,
      "learning_rate": 0.0009073971814782858,
      "loss": 0.004,
      "step": 16100
    },
    {
      "epoch": 4.644808743169399,
      "grad_norm": 0.00011771924619097263,
      "learning_rate": 0.000907109577221743,
      "loss": 0.0024,
      "step": 16150
    },
    {
      "epoch": 4.659188955996549,
      "grad_norm": 0.01978961005806923,
      "learning_rate": 0.0009068219729651999,
      "loss": 0.0015,
      "step": 16200
    },
    {
      "epoch": 4.673569168823699,
      "grad_norm": 5.1305418310221285e-05,
      "learning_rate": 0.0009065343687086569,
      "loss": 0.0013,
      "step": 16250
    },
    {
      "epoch": 4.687949381650848,
      "grad_norm": 0.005109836813062429,
      "learning_rate": 0.000906246764452114,
      "loss": 0.0025,
      "step": 16300
    },
    {
      "epoch": 4.702329594477998,
      "grad_norm": 0.00011081876436946914,
      "learning_rate": 0.0009059591601955709,
      "loss": 0.0008,
      "step": 16350
    },
    {
      "epoch": 4.716709807305148,
      "grad_norm": 0.0051290113478899,
      "learning_rate": 0.0009056715559390279,
      "loss": 0.0019,
      "step": 16400
    },
    {
      "epoch": 4.731090020132298,
      "grad_norm": 8.41869623400271e-05,
      "learning_rate": 0.0009053839516824849,
      "loss": 0.0027,
      "step": 16450
    },
    {
      "epoch": 4.745470232959448,
      "grad_norm": 0.0006726598949171603,
      "learning_rate": 0.000905096347425942,
      "loss": 0.0008,
      "step": 16500
    },
    {
      "epoch": 4.759850445786598,
      "grad_norm": 0.023530784994363785,
      "learning_rate": 0.0009048087431693989,
      "loss": 0.004,
      "step": 16550
    },
    {
      "epoch": 4.774230658613748,
      "grad_norm": 0.0008290460100397468,
      "learning_rate": 0.000904521138912856,
      "loss": 0.0051,
      "step": 16600
    },
    {
      "epoch": 4.7886108714408975,
      "grad_norm": 0.13225828111171722,
      "learning_rate": 0.000904233534656313,
      "loss": 0.0011,
      "step": 16650
    },
    {
      "epoch": 4.802991084268047,
      "grad_norm": 7.034468580968678e-05,
      "learning_rate": 0.0009039459303997699,
      "loss": 0.0026,
      "step": 16700
    },
    {
      "epoch": 4.817371297095197,
      "grad_norm": 0.00017279900202993304,
      "learning_rate": 0.000903658326143227,
      "loss": 0.0022,
      "step": 16750
    },
    {
      "epoch": 4.831751509922347,
      "grad_norm": 0.13803192973136902,
      "learning_rate": 0.0009033707218866839,
      "loss": 0.001,
      "step": 16800
    },
    {
      "epoch": 4.846131722749496,
      "grad_norm": 5.0820781325455755e-05,
      "learning_rate": 0.0009030831176301409,
      "loss": 0.0021,
      "step": 16850
    },
    {
      "epoch": 4.860511935576646,
      "grad_norm": 0.005150551442056894,
      "learning_rate": 0.000902795513373598,
      "loss": 0.0045,
      "step": 16900
    },
    {
      "epoch": 4.874892148403797,
      "grad_norm": 0.022537315264344215,
      "learning_rate": 0.000902507909117055,
      "loss": 0.0036,
      "step": 16950
    },
    {
      "epoch": 4.8892723612309466,
      "grad_norm": 0.1693728268146515,
      "learning_rate": 0.000902220304860512,
      "loss": 0.0022,
      "step": 17000
    },
    {
      "epoch": 4.903652574058096,
      "grad_norm": 0.0006193550652824342,
      "learning_rate": 0.000901932700603969,
      "loss": 0.003,
      "step": 17050
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 0.00048148955102078617,
      "learning_rate": 0.000901645096347426,
      "loss": 0.0023,
      "step": 17100
    },
    {
      "epoch": 4.932412999712396,
      "grad_norm": 5.692067134077661e-05,
      "learning_rate": 0.0009013574920908829,
      "loss": 0.0015,
      "step": 17150
    },
    {
      "epoch": 4.9467932125395455,
      "grad_norm": 0.0005915379151701927,
      "learning_rate": 0.00090106988783434,
      "loss": 0.0033,
      "step": 17200
    },
    {
      "epoch": 4.961173425366695,
      "grad_norm": 3.9815229683881626e-05,
      "learning_rate": 0.000900782283577797,
      "loss": 0.0027,
      "step": 17250
    },
    {
      "epoch": 4.975553638193845,
      "grad_norm": 0.07943026721477509,
      "learning_rate": 0.0009004946793212539,
      "loss": 0.0025,
      "step": 17300
    },
    {
      "epoch": 4.989933851020995,
      "grad_norm": 0.00011191215162398294,
      "learning_rate": 0.000900207075064711,
      "loss": 0.003,
      "step": 17350
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.011322653852403164,
      "eval_runtime": 11.7074,
      "eval_samples_per_second": 4075.971,
      "eval_steps_per_second": 63.72,
      "step": 17385
    },
    {
      "epoch": 5.004314063848145,
      "grad_norm": 0.00018064945470541716,
      "learning_rate": 0.000899919470808168,
      "loss": 0.0019,
      "step": 17400
    },
    {
      "epoch": 5.018694276675295,
      "grad_norm": 0.013532841578125954,
      "learning_rate": 0.000899631866551625,
      "loss": 0.0034,
      "step": 17450
    },
    {
      "epoch": 5.033074489502445,
      "grad_norm": 8.702546620042995e-05,
      "learning_rate": 0.0008993442622950821,
      "loss": 0.0023,
      "step": 17500
    },
    {
      "epoch": 5.047454702329595,
      "grad_norm": 0.00014805421233177185,
      "learning_rate": 0.000899056658038539,
      "loss": 0.0039,
      "step": 17550
    },
    {
      "epoch": 5.061834915156744,
      "grad_norm": 0.009231806732714176,
      "learning_rate": 0.000898769053781996,
      "loss": 0.0024,
      "step": 17600
    },
    {
      "epoch": 5.076215127983894,
      "grad_norm": 0.05028232932090759,
      "learning_rate": 0.000898481449525453,
      "loss": 0.0018,
      "step": 17650
    },
    {
      "epoch": 5.090595340811044,
      "grad_norm": 0.001051620114594698,
      "learning_rate": 0.00089819384526891,
      "loss": 0.0025,
      "step": 17700
    },
    {
      "epoch": 5.1049755536381936,
      "grad_norm": 0.00010522131196921691,
      "learning_rate": 0.0008979062410123669,
      "loss": 0.0004,
      "step": 17750
    },
    {
      "epoch": 5.119355766465343,
      "grad_norm": 0.032438598573207855,
      "learning_rate": 0.000897618636755824,
      "loss": 0.0016,
      "step": 17800
    },
    {
      "epoch": 5.133735979292494,
      "grad_norm": 0.00020553143986035138,
      "learning_rate": 0.0008973310324992811,
      "loss": 0.0018,
      "step": 17850
    },
    {
      "epoch": 5.148116192119644,
      "grad_norm": 0.0005877873627468944,
      "learning_rate": 0.000897043428242738,
      "loss": 0.0031,
      "step": 17900
    },
    {
      "epoch": 5.162496404946793,
      "grad_norm": 0.0001635044754948467,
      "learning_rate": 0.0008967558239861951,
      "loss": 0.0039,
      "step": 17950
    },
    {
      "epoch": 5.176876617773943,
      "grad_norm": 0.027662629261612892,
      "learning_rate": 0.000896468219729652,
      "loss": 0.0024,
      "step": 18000
    },
    {
      "epoch": 5.191256830601093,
      "grad_norm": 0.0010668050963431597,
      "learning_rate": 0.000896180615473109,
      "loss": 0.0045,
      "step": 18050
    },
    {
      "epoch": 5.205637043428243,
      "grad_norm": 0.00012393404904287308,
      "learning_rate": 0.0008958930112165661,
      "loss": 0.0041,
      "step": 18100
    },
    {
      "epoch": 5.220017256255392,
      "grad_norm": 0.0745813250541687,
      "learning_rate": 0.000895605406960023,
      "loss": 0.0009,
      "step": 18150
    },
    {
      "epoch": 5.234397469082542,
      "grad_norm": 3.832527363556437e-05,
      "learning_rate": 0.00089531780270348,
      "loss": 0.0042,
      "step": 18200
    },
    {
      "epoch": 5.248777681909692,
      "grad_norm": 0.023148080334067345,
      "learning_rate": 0.000895030198446937,
      "loss": 0.003,
      "step": 18250
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.027207080274820328,
      "learning_rate": 0.0008947425941903941,
      "loss": 0.0033,
      "step": 18300
    },
    {
      "epoch": 5.277538107563992,
      "grad_norm": 0.012301946990191936,
      "learning_rate": 0.000894454989933851,
      "loss": 0.003,
      "step": 18350
    },
    {
      "epoch": 5.291918320391142,
      "grad_norm": 0.022884558886289597,
      "learning_rate": 0.0008941673856773081,
      "loss": 0.0037,
      "step": 18400
    },
    {
      "epoch": 5.306298533218292,
      "grad_norm": 0.0006628651171922684,
      "learning_rate": 0.0008938797814207651,
      "loss": 0.0038,
      "step": 18450
    },
    {
      "epoch": 5.320678746045441,
      "grad_norm": 0.008367856964468956,
      "learning_rate": 0.000893592177164222,
      "loss": 0.0016,
      "step": 18500
    },
    {
      "epoch": 5.335058958872591,
      "grad_norm": 0.00011657760478556156,
      "learning_rate": 0.0008933045729076791,
      "loss": 0.0038,
      "step": 18550
    },
    {
      "epoch": 5.349439171699741,
      "grad_norm": 0.0011005194392055273,
      "learning_rate": 0.000893016968651136,
      "loss": 0.0019,
      "step": 18600
    },
    {
      "epoch": 5.363819384526891,
      "grad_norm": 0.09332232177257538,
      "learning_rate": 0.000892729364394593,
      "loss": 0.0029,
      "step": 18650
    },
    {
      "epoch": 5.37819959735404,
      "grad_norm": 0.0002502012939658016,
      "learning_rate": 0.0008924417601380501,
      "loss": 0.004,
      "step": 18700
    },
    {
      "epoch": 5.392579810181191,
      "grad_norm": 0.0007398215238936245,
      "learning_rate": 0.0008921541558815071,
      "loss": 0.0031,
      "step": 18750
    },
    {
      "epoch": 5.406960023008341,
      "grad_norm": 6.25636093900539e-05,
      "learning_rate": 0.0008918665516249641,
      "loss": 0.0046,
      "step": 18800
    },
    {
      "epoch": 5.4213402358354905,
      "grad_norm": 0.0005497823585756123,
      "learning_rate": 0.0008915789473684211,
      "loss": 0.0038,
      "step": 18850
    },
    {
      "epoch": 5.43572044866264,
      "grad_norm": 0.013600122183561325,
      "learning_rate": 0.0008912913431118781,
      "loss": 0.0048,
      "step": 18900
    },
    {
      "epoch": 5.45010066148979,
      "grad_norm": 0.020704761147499084,
      "learning_rate": 0.000891003738855335,
      "loss": 0.002,
      "step": 18950
    },
    {
      "epoch": 5.46448087431694,
      "grad_norm": 0.0001493335876148194,
      "learning_rate": 0.0008907161345987921,
      "loss": 0.0013,
      "step": 19000
    },
    {
      "epoch": 5.4788610871440895,
      "grad_norm": 0.00038660498103126884,
      "learning_rate": 0.0008904285303422491,
      "loss": 0.0022,
      "step": 19050
    },
    {
      "epoch": 5.493241299971239,
      "grad_norm": 0.0002511718194000423,
      "learning_rate": 0.000890140926085706,
      "loss": 0.0028,
      "step": 19100
    },
    {
      "epoch": 5.507621512798389,
      "grad_norm": 0.034800466150045395,
      "learning_rate": 0.0008898533218291632,
      "loss": 0.0023,
      "step": 19150
    },
    {
      "epoch": 5.52200172562554,
      "grad_norm": 0.0018515378469601274,
      "learning_rate": 0.0008895657175726201,
      "loss": 0.0033,
      "step": 19200
    },
    {
      "epoch": 5.536381938452689,
      "grad_norm": 8.329696720466018e-05,
      "learning_rate": 0.0008892781133160771,
      "loss": 0.0048,
      "step": 19250
    },
    {
      "epoch": 5.550762151279839,
      "grad_norm": 4.556825660984032e-05,
      "learning_rate": 0.0008889905090595341,
      "loss": 0.0019,
      "step": 19300
    },
    {
      "epoch": 5.565142364106989,
      "grad_norm": 0.00042418460361659527,
      "learning_rate": 0.0008887029048029911,
      "loss": 0.0036,
      "step": 19350
    },
    {
      "epoch": 5.5795225769341386,
      "grad_norm": 0.016315298154950142,
      "learning_rate": 0.0008884153005464481,
      "loss": 0.0013,
      "step": 19400
    },
    {
      "epoch": 5.593902789761288,
      "grad_norm": 0.10098733007907867,
      "learning_rate": 0.0008881276962899051,
      "loss": 0.0053,
      "step": 19450
    },
    {
      "epoch": 5.608283002588438,
      "grad_norm": 0.0003686498384922743,
      "learning_rate": 0.0008878400920333621,
      "loss": 0.0028,
      "step": 19500
    },
    {
      "epoch": 5.622663215415588,
      "grad_norm": 0.00249965931288898,
      "learning_rate": 0.000887552487776819,
      "loss": 0.0031,
      "step": 19550
    },
    {
      "epoch": 5.6370434282427375,
      "grad_norm": 0.035588592290878296,
      "learning_rate": 0.0008872648835202762,
      "loss": 0.0023,
      "step": 19600
    },
    {
      "epoch": 5.651423641069888,
      "grad_norm": 7.90184349170886e-05,
      "learning_rate": 0.0008869772792637332,
      "loss": 0.0027,
      "step": 19650
    },
    {
      "epoch": 5.665803853897038,
      "grad_norm": 9.942658653017133e-05,
      "learning_rate": 0.0008866896750071901,
      "loss": 0.0025,
      "step": 19700
    },
    {
      "epoch": 5.680184066724188,
      "grad_norm": 0.00032259614090435207,
      "learning_rate": 0.0008864020707506472,
      "loss": 0.003,
      "step": 19750
    },
    {
      "epoch": 5.694564279551337,
      "grad_norm": 0.001273602363653481,
      "learning_rate": 0.0008861144664941041,
      "loss": 0.0011,
      "step": 19800
    },
    {
      "epoch": 5.708944492378487,
      "grad_norm": 0.00034371973015367985,
      "learning_rate": 0.0008858268622375611,
      "loss": 0.0074,
      "step": 19850
    },
    {
      "epoch": 5.723324705205637,
      "grad_norm": 0.00010669492621673271,
      "learning_rate": 0.0008855392579810181,
      "loss": 0.0029,
      "step": 19900
    },
    {
      "epoch": 5.737704918032787,
      "grad_norm": 0.1627991944551468,
      "learning_rate": 0.0008852516537244751,
      "loss": 0.0017,
      "step": 19950
    },
    {
      "epoch": 5.752085130859937,
      "grad_norm": 0.021310588344931602,
      "learning_rate": 0.0008849640494679322,
      "loss": 0.0025,
      "step": 20000
    },
    {
      "epoch": 5.766465343687086,
      "grad_norm": 0.0032867849804461002,
      "learning_rate": 0.0008846764452113892,
      "loss": 0.0041,
      "step": 20050
    },
    {
      "epoch": 5.780845556514237,
      "grad_norm": 0.00021009915508329868,
      "learning_rate": 0.0008843888409548462,
      "loss": 0.005,
      "step": 20100
    },
    {
      "epoch": 5.7952257693413864,
      "grad_norm": 0.0001517289929324761,
      "learning_rate": 0.0008841012366983031,
      "loss": 0.0027,
      "step": 20150
    },
    {
      "epoch": 5.809605982168536,
      "grad_norm": 0.11055448651313782,
      "learning_rate": 0.0008838136324417602,
      "loss": 0.0031,
      "step": 20200
    },
    {
      "epoch": 5.823986194995686,
      "grad_norm": 0.07587644457817078,
      "learning_rate": 0.0008835260281852172,
      "loss": 0.0026,
      "step": 20250
    },
    {
      "epoch": 5.838366407822836,
      "grad_norm": 0.0028824149630963802,
      "learning_rate": 0.0008832384239286741,
      "loss": 0.0042,
      "step": 20300
    },
    {
      "epoch": 5.852746620649985,
      "grad_norm": 7.138666842365637e-05,
      "learning_rate": 0.0008829508196721312,
      "loss": 0.0033,
      "step": 20350
    },
    {
      "epoch": 5.867126833477135,
      "grad_norm": 8.110239286907017e-05,
      "learning_rate": 0.0008826632154155881,
      "loss": 0.0025,
      "step": 20400
    },
    {
      "epoch": 5.881507046304286,
      "grad_norm": 0.03779067471623421,
      "learning_rate": 0.0008823756111590452,
      "loss": 0.0054,
      "step": 20450
    },
    {
      "epoch": 5.8958872591314355,
      "grad_norm": 1.0847464799880981,
      "learning_rate": 0.0008820880069025022,
      "loss": 0.0037,
      "step": 20500
    },
    {
      "epoch": 5.910267471958585,
      "grad_norm": 0.032860707491636276,
      "learning_rate": 0.0008818004026459592,
      "loss": 0.0095,
      "step": 20550
    },
    {
      "epoch": 5.924647684785735,
      "grad_norm": 0.0014324943767860532,
      "learning_rate": 0.0008815127983894162,
      "loss": 0.0024,
      "step": 20600
    },
    {
      "epoch": 5.939027897612885,
      "grad_norm": 8.66501359269023e-05,
      "learning_rate": 0.0008812251941328732,
      "loss": 0.0041,
      "step": 20650
    },
    {
      "epoch": 5.9534081104400345,
      "grad_norm": 0.00019411466200836003,
      "learning_rate": 0.0008809375898763302,
      "loss": 0.0062,
      "step": 20700
    },
    {
      "epoch": 5.967788323267184,
      "grad_norm": 0.00015924561012070626,
      "learning_rate": 0.0008806499856197871,
      "loss": 0.0019,
      "step": 20750
    },
    {
      "epoch": 5.982168536094334,
      "grad_norm": 0.0002859524392988533,
      "learning_rate": 0.0008803623813632442,
      "loss": 0.0064,
      "step": 20800
    },
    {
      "epoch": 5.996548748921484,
      "grad_norm": 0.05562826991081238,
      "learning_rate": 0.0008800747771067013,
      "loss": 0.004,
      "step": 20850
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.021813899278640747,
      "eval_runtime": 11.7333,
      "eval_samples_per_second": 4066.98,
      "eval_steps_per_second": 63.58,
      "step": 20862
    },
    {
      "epoch": 6.0109289617486334,
      "grad_norm": 9.232684533344582e-05,
      "learning_rate": 0.0008797871728501582,
      "loss": 0.0038,
      "step": 20900
    },
    {
      "epoch": 6.025309174575784,
      "grad_norm": 0.00032325321808457375,
      "learning_rate": 0.0008794995685936153,
      "loss": 0.0057,
      "step": 20950
    },
    {
      "epoch": 6.039689387402934,
      "grad_norm": 0.009983638301491737,
      "learning_rate": 0.0008792119643370722,
      "loss": 0.0037,
      "step": 21000
    },
    {
      "epoch": 6.054069600230084,
      "grad_norm": 0.015610871836543083,
      "learning_rate": 0.0008789243600805292,
      "loss": 0.004,
      "step": 21050
    },
    {
      "epoch": 6.068449813057233,
      "grad_norm": 0.011596824042499065,
      "learning_rate": 0.0008786367558239862,
      "loss": 0.0021,
      "step": 21100
    },
    {
      "epoch": 6.082830025884383,
      "grad_norm": 0.0656718909740448,
      "learning_rate": 0.0008783491515674432,
      "loss": 0.0042,
      "step": 21150
    },
    {
      "epoch": 6.097210238711533,
      "grad_norm": 0.0020397917833179235,
      "learning_rate": 0.0008780615473109002,
      "loss": 0.0017,
      "step": 21200
    },
    {
      "epoch": 6.1115904515386825,
      "grad_norm": 0.0001444085210096091,
      "learning_rate": 0.0008777739430543572,
      "loss": 0.0038,
      "step": 21250
    },
    {
      "epoch": 6.125970664365832,
      "grad_norm": 0.0008680665050633252,
      "learning_rate": 0.0008774863387978143,
      "loss": 0.0026,
      "step": 21300
    },
    {
      "epoch": 6.140350877192983,
      "grad_norm": 3.606531390687451e-05,
      "learning_rate": 0.0008771987345412712,
      "loss": 0.0032,
      "step": 21350
    },
    {
      "epoch": 6.154731090020133,
      "grad_norm": 0.00933937355875969,
      "learning_rate": 0.0008769111302847283,
      "loss": 0.0024,
      "step": 21400
    },
    {
      "epoch": 6.169111302847282,
      "grad_norm": 0.0012163615319877863,
      "learning_rate": 0.0008766235260281852,
      "loss": 0.001,
      "step": 21450
    },
    {
      "epoch": 6.183491515674432,
      "grad_norm": 0.022771023213863373,
      "learning_rate": 0.0008763359217716422,
      "loss": 0.0034,
      "step": 21500
    },
    {
      "epoch": 6.197871728501582,
      "grad_norm": 0.12475702166557312,
      "learning_rate": 0.0008760483175150993,
      "loss": 0.0048,
      "step": 21550
    },
    {
      "epoch": 6.212251941328732,
      "grad_norm": 8.511911437381059e-05,
      "learning_rate": 0.0008757607132585562,
      "loss": 0.0009,
      "step": 21600
    },
    {
      "epoch": 6.226632154155881,
      "grad_norm": 0.00262631312943995,
      "learning_rate": 0.0008754731090020132,
      "loss": 0.0034,
      "step": 21650
    },
    {
      "epoch": 6.241012366983031,
      "grad_norm": 0.09215450286865234,
      "learning_rate": 0.0008751855047454703,
      "loss": 0.0021,
      "step": 21700
    },
    {
      "epoch": 6.255392579810181,
      "grad_norm": 0.031068764626979828,
      "learning_rate": 0.0008748979004889273,
      "loss": 0.003,
      "step": 21750
    },
    {
      "epoch": 6.2697727926373314,
      "grad_norm": 0.05340484902262688,
      "learning_rate": 0.0008746102962323843,
      "loss": 0.0092,
      "step": 21800
    },
    {
      "epoch": 6.284153005464481,
      "grad_norm": 0.002121497178450227,
      "learning_rate": 0.0008743226919758413,
      "loss": 0.0037,
      "step": 21850
    },
    {
      "epoch": 6.298533218291631,
      "grad_norm": 0.05655548349022865,
      "learning_rate": 0.0008740350877192983,
      "loss": 0.0032,
      "step": 21900
    },
    {
      "epoch": 6.312913431118781,
      "grad_norm": 0.02336028590798378,
      "learning_rate": 0.0008737474834627552,
      "loss": 0.0052,
      "step": 21950
    },
    {
      "epoch": 6.32729364394593,
      "grad_norm": 0.00023904840054456145,
      "learning_rate": 0.0008734598792062123,
      "loss": 0.0016,
      "step": 22000
    },
    {
      "epoch": 6.34167385677308,
      "grad_norm": 0.0002543607261031866,
      "learning_rate": 0.0008731722749496692,
      "loss": 0.0047,
      "step": 22050
    },
    {
      "epoch": 6.35605406960023,
      "grad_norm": 0.0016310731880366802,
      "learning_rate": 0.0008728846706931262,
      "loss": 0.0039,
      "step": 22100
    },
    {
      "epoch": 6.37043428242738,
      "grad_norm": 0.00016800772573333234,
      "learning_rate": 0.0008725970664365834,
      "loss": 0.0051,
      "step": 22150
    },
    {
      "epoch": 6.384814495254529,
      "grad_norm": 0.01260270457714796,
      "learning_rate": 0.0008723094621800403,
      "loss": 0.0029,
      "step": 22200
    },
    {
      "epoch": 6.39919470808168,
      "grad_norm": 0.0001636819652048871,
      "learning_rate": 0.0008720218579234973,
      "loss": 0.0027,
      "step": 22250
    },
    {
      "epoch": 6.41357492090883,
      "grad_norm": 0.1588294506072998,
      "learning_rate": 0.0008717342536669543,
      "loss": 0.0047,
      "step": 22300
    },
    {
      "epoch": 6.4279551337359795,
      "grad_norm": 8.230565435951576e-05,
      "learning_rate": 0.0008714466494104113,
      "loss": 0.0012,
      "step": 22350
    },
    {
      "epoch": 6.442335346563129,
      "grad_norm": 0.00010819028102559969,
      "learning_rate": 0.0008711590451538683,
      "loss": 0.0027,
      "step": 22400
    },
    {
      "epoch": 6.456715559390279,
      "grad_norm": 0.0006420105928555131,
      "learning_rate": 0.0008708714408973253,
      "loss": 0.0039,
      "step": 22450
    },
    {
      "epoch": 6.471095772217429,
      "grad_norm": 0.04703281447291374,
      "learning_rate": 0.0008705838366407823,
      "loss": 0.0019,
      "step": 22500
    },
    {
      "epoch": 6.4854759850445785,
      "grad_norm": 0.020824139937758446,
      "learning_rate": 0.0008702962323842392,
      "loss": 0.0032,
      "step": 22550
    },
    {
      "epoch": 6.499856197871728,
      "grad_norm": 0.051831603050231934,
      "learning_rate": 0.0008700086281276964,
      "loss": 0.0019,
      "step": 22600
    },
    {
      "epoch": 6.514236410698878,
      "grad_norm": 0.0029641890432685614,
      "learning_rate": 0.0008697210238711533,
      "loss": 0.0025,
      "step": 22650
    },
    {
      "epoch": 6.528616623526029,
      "grad_norm": 0.0012766177533194423,
      "learning_rate": 0.0008694334196146103,
      "loss": 0.0045,
      "step": 22700
    },
    {
      "epoch": 6.542996836353178,
      "grad_norm": 3.8189209590200335e-05,
      "learning_rate": 0.0008691458153580674,
      "loss": 0.0018,
      "step": 22750
    },
    {
      "epoch": 6.557377049180328,
      "grad_norm": 0.1295178383588791,
      "learning_rate": 0.0008688582111015243,
      "loss": 0.0037,
      "step": 22800
    },
    {
      "epoch": 6.571757262007478,
      "grad_norm": 0.00036722002550959587,
      "learning_rate": 0.0008685706068449813,
      "loss": 0.0062,
      "step": 22850
    },
    {
      "epoch": 6.5861374748346275,
      "grad_norm": 0.0001243126898771152,
      "learning_rate": 0.0008682830025884383,
      "loss": 0.003,
      "step": 22900
    },
    {
      "epoch": 6.600517687661777,
      "grad_norm": 2.1627085516229272e-05,
      "learning_rate": 0.0008679953983318953,
      "loss": 0.002,
      "step": 22950
    },
    {
      "epoch": 6.614897900488927,
      "grad_norm": 0.009385366924107075,
      "learning_rate": 0.0008677077940753524,
      "loss": 0.0018,
      "step": 23000
    },
    {
      "epoch": 6.629278113316077,
      "grad_norm": 0.07041481137275696,
      "learning_rate": 0.0008674201898188094,
      "loss": 0.0058,
      "step": 23050
    },
    {
      "epoch": 6.6436583261432265,
      "grad_norm": 0.0001334142143605277,
      "learning_rate": 0.0008671325855622664,
      "loss": 0.0031,
      "step": 23100
    },
    {
      "epoch": 6.658038538970377,
      "grad_norm": 0.20190545916557312,
      "learning_rate": 0.0008668449813057233,
      "loss": 0.0052,
      "step": 23150
    },
    {
      "epoch": 6.672418751797527,
      "grad_norm": 0.000305463676340878,
      "learning_rate": 0.0008665573770491804,
      "loss": 0.0013,
      "step": 23200
    },
    {
      "epoch": 6.686798964624677,
      "grad_norm": 0.016523931175470352,
      "learning_rate": 0.0008662697727926373,
      "loss": 0.0017,
      "step": 23250
    },
    {
      "epoch": 6.701179177451826,
      "grad_norm": 0.002127084881067276,
      "learning_rate": 0.0008659821685360943,
      "loss": 0.0019,
      "step": 23300
    },
    {
      "epoch": 6.715559390278976,
      "grad_norm": 0.00033451177296228707,
      "learning_rate": 0.0008656945642795514,
      "loss": 0.0024,
      "step": 23350
    },
    {
      "epoch": 6.729939603106126,
      "grad_norm": 0.00012400955893099308,
      "learning_rate": 0.0008654069600230083,
      "loss": 0.0038,
      "step": 23400
    },
    {
      "epoch": 6.744319815933276,
      "grad_norm": 6.153350113891065e-05,
      "learning_rate": 0.0008651193557664654,
      "loss": 0.0011,
      "step": 23450
    },
    {
      "epoch": 6.758700028760425,
      "grad_norm": 0.0005149800563231111,
      "learning_rate": 0.0008648317515099224,
      "loss": 0.0043,
      "step": 23500
    },
    {
      "epoch": 6.773080241587575,
      "grad_norm": 0.0002465284778736532,
      "learning_rate": 0.0008645441472533794,
      "loss": 0.0037,
      "step": 23550
    },
    {
      "epoch": 6.787460454414726,
      "grad_norm": 0.0008911933982744813,
      "learning_rate": 0.0008642565429968364,
      "loss": 0.0027,
      "step": 23600
    },
    {
      "epoch": 6.801840667241875,
      "grad_norm": 0.040682513266801834,
      "learning_rate": 0.0008639689387402934,
      "loss": 0.0038,
      "step": 23650
    },
    {
      "epoch": 6.816220880069025,
      "grad_norm": 0.00025151329464279115,
      "learning_rate": 0.0008636813344837504,
      "loss": 0.0028,
      "step": 23700
    },
    {
      "epoch": 6.830601092896175,
      "grad_norm": 9.165762457996607e-05,
      "learning_rate": 0.0008633937302272073,
      "loss": 0.0063,
      "step": 23750
    },
    {
      "epoch": 6.844981305723325,
      "grad_norm": 0.0003150340635329485,
      "learning_rate": 0.0008631061259706644,
      "loss": 0.0026,
      "step": 23800
    },
    {
      "epoch": 6.859361518550474,
      "grad_norm": 0.00034178115311078727,
      "learning_rate": 0.0008628185217141213,
      "loss": 0.0016,
      "step": 23850
    },
    {
      "epoch": 6.873741731377624,
      "grad_norm": 0.0027321865782141685,
      "learning_rate": 0.0008625309174575784,
      "loss": 0.0027,
      "step": 23900
    },
    {
      "epoch": 6.888121944204774,
      "grad_norm": 0.018379371613264084,
      "learning_rate": 0.0008622433132010355,
      "loss": 0.0068,
      "step": 23950
    },
    {
      "epoch": 6.902502157031924,
      "grad_norm": 0.0001463200169382617,
      "learning_rate": 0.0008619557089444924,
      "loss": 0.001,
      "step": 24000
    },
    {
      "epoch": 6.916882369859074,
      "grad_norm": 0.00010873936116695404,
      "learning_rate": 0.0008616681046879494,
      "loss": 0.0031,
      "step": 24050
    },
    {
      "epoch": 6.931262582686224,
      "grad_norm": 0.042368169873952866,
      "learning_rate": 0.0008613805004314064,
      "loss": 0.004,
      "step": 24100
    },
    {
      "epoch": 6.945642795513374,
      "grad_norm": 0.002279788488522172,
      "learning_rate": 0.0008610928961748634,
      "loss": 0.0036,
      "step": 24150
    },
    {
      "epoch": 6.9600230083405235,
      "grad_norm": 0.013845541514456272,
      "learning_rate": 0.0008608052919183203,
      "loss": 0.0022,
      "step": 24200
    },
    {
      "epoch": 6.974403221167673,
      "grad_norm": 0.01810004934668541,
      "learning_rate": 0.0008605176876617774,
      "loss": 0.0027,
      "step": 24250
    },
    {
      "epoch": 6.988783433994823,
      "grad_norm": 0.0001400871988153085,
      "learning_rate": 0.0008602300834052345,
      "loss": 0.0022,
      "step": 24300
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.013910106383264065,
      "eval_runtime": 11.7994,
      "eval_samples_per_second": 4044.191,
      "eval_steps_per_second": 63.224,
      "step": 24339
    },
    {
      "epoch": 7.003163646821973,
      "grad_norm": 0.01809599995613098,
      "learning_rate": 0.0008599424791486914,
      "loss": 0.0028,
      "step": 24350
    },
    {
      "epoch": 7.017543859649122,
      "grad_norm": 0.00018395176448393613,
      "learning_rate": 0.0008596548748921485,
      "loss": 0.0069,
      "step": 24400
    },
    {
      "epoch": 7.031924072476273,
      "grad_norm": 0.0016535002505406737,
      "learning_rate": 0.0008593672706356054,
      "loss": 0.003,
      "step": 24450
    },
    {
      "epoch": 7.046304285303423,
      "grad_norm": 0.017117001116275787,
      "learning_rate": 0.0008590796663790624,
      "loss": 0.0037,
      "step": 24500
    },
    {
      "epoch": 7.0606844981305725,
      "grad_norm": 0.0005481961416080594,
      "learning_rate": 0.0008587920621225195,
      "loss": 0.0034,
      "step": 24550
    },
    {
      "epoch": 7.075064710957722,
      "grad_norm": 0.00013061673962511122,
      "learning_rate": 0.0008585044578659764,
      "loss": 0.003,
      "step": 24600
    },
    {
      "epoch": 7.089444923784872,
      "grad_norm": 0.0003748445014934987,
      "learning_rate": 0.0008582168536094334,
      "loss": 0.0029,
      "step": 24650
    },
    {
      "epoch": 7.103825136612022,
      "grad_norm": 0.00012464633618947119,
      "learning_rate": 0.0008579292493528904,
      "loss": 0.0015,
      "step": 24700
    },
    {
      "epoch": 7.1182053494391715,
      "grad_norm": 0.03237820044159889,
      "learning_rate": 0.0008576416450963475,
      "loss": 0.0019,
      "step": 24750
    },
    {
      "epoch": 7.132585562266321,
      "grad_norm": 6.225994729902595e-05,
      "learning_rate": 0.0008573540408398044,
      "loss": 0.0012,
      "step": 24800
    },
    {
      "epoch": 7.146965775093471,
      "grad_norm": 0.0006010619108565152,
      "learning_rate": 0.0008570664365832615,
      "loss": 0.0029,
      "step": 24850
    },
    {
      "epoch": 7.161345987920622,
      "grad_norm": 0.00011586125037865713,
      "learning_rate": 0.0008567788323267185,
      "loss": 0.0025,
      "step": 24900
    },
    {
      "epoch": 7.175726200747771,
      "grad_norm": 0.00011184910545125604,
      "learning_rate": 0.0008564912280701754,
      "loss": 0.0046,
      "step": 24950
    },
    {
      "epoch": 7.190106413574921,
      "grad_norm": 0.0006602784269489348,
      "learning_rate": 0.0008562036238136325,
      "loss": 0.003,
      "step": 25000
    },
    {
      "epoch": 7.204486626402071,
      "grad_norm": 0.0015146706718951464,
      "learning_rate": 0.0008559160195570894,
      "loss": 0.0023,
      "step": 25050
    },
    {
      "epoch": 7.218866839229221,
      "grad_norm": 4.9065216444432735e-05,
      "learning_rate": 0.0008556284153005464,
      "loss": 0.0012,
      "step": 25100
    },
    {
      "epoch": 7.23324705205637,
      "grad_norm": 0.055083826184272766,
      "learning_rate": 0.0008553408110440036,
      "loss": 0.0032,
      "step": 25150
    },
    {
      "epoch": 7.24762726488352,
      "grad_norm": 0.00016057572793215513,
      "learning_rate": 0.0008550532067874605,
      "loss": 0.0021,
      "step": 25200
    },
    {
      "epoch": 7.26200747771067,
      "grad_norm": 0.00028341595316305757,
      "learning_rate": 0.0008547656025309175,
      "loss": 0.0042,
      "step": 25250
    },
    {
      "epoch": 7.27638769053782,
      "grad_norm": 7.547840505139902e-05,
      "learning_rate": 0.0008544779982743745,
      "loss": 0.0072,
      "step": 25300
    },
    {
      "epoch": 7.29076790336497,
      "grad_norm": 0.007878832519054413,
      "learning_rate": 0.0008541903940178315,
      "loss": 0.0069,
      "step": 25350
    },
    {
      "epoch": 7.30514811619212,
      "grad_norm": 0.00031166471308097243,
      "learning_rate": 0.0008539027897612884,
      "loss": 0.0071,
      "step": 25400
    },
    {
      "epoch": 7.31952832901927,
      "grad_norm": 4.2537853005342185e-05,
      "learning_rate": 0.0008536151855047455,
      "loss": 0.0033,
      "step": 25450
    },
    {
      "epoch": 7.333908541846419,
      "grad_norm": 4.672454087994993e-05,
      "learning_rate": 0.0008533275812482025,
      "loss": 0.0049,
      "step": 25500
    },
    {
      "epoch": 7.348288754673569,
      "grad_norm": 0.00024355895584449172,
      "learning_rate": 0.0008530399769916594,
      "loss": 0.0069,
      "step": 25550
    },
    {
      "epoch": 7.362668967500719,
      "grad_norm": 0.0019915755838155746,
      "learning_rate": 0.0008527523727351166,
      "loss": 0.0038,
      "step": 25600
    },
    {
      "epoch": 7.377049180327869,
      "grad_norm": 0.04824002459645271,
      "learning_rate": 0.0008524647684785735,
      "loss": 0.0019,
      "step": 25650
    },
    {
      "epoch": 7.391429393155018,
      "grad_norm": 6.389429472619668e-05,
      "learning_rate": 0.0008521771642220305,
      "loss": 0.0021,
      "step": 25700
    },
    {
      "epoch": 7.405809605982169,
      "grad_norm": 0.008241728879511356,
      "learning_rate": 0.0008518895599654876,
      "loss": 0.003,
      "step": 25750
    },
    {
      "epoch": 7.420189818809319,
      "grad_norm": 0.0002240700414404273,
      "learning_rate": 0.0008516019557089445,
      "loss": 0.0048,
      "step": 25800
    },
    {
      "epoch": 7.4345700316364685,
      "grad_norm": 0.00010680179548216984,
      "learning_rate": 0.0008513143514524015,
      "loss": 0.0041,
      "step": 25850
    },
    {
      "epoch": 7.448950244463618,
      "grad_norm": 0.00015935013652779162,
      "learning_rate": 0.0008510267471958585,
      "loss": 0.0014,
      "step": 25900
    },
    {
      "epoch": 7.463330457290768,
      "grad_norm": 0.00016830471577122808,
      "learning_rate": 0.0008507391429393155,
      "loss": 0.0045,
      "step": 25950
    },
    {
      "epoch": 7.477710670117918,
      "grad_norm": 0.02452141046524048,
      "learning_rate": 0.0008504515386827724,
      "loss": 0.0009,
      "step": 26000
    },
    {
      "epoch": 7.492090882945067,
      "grad_norm": 8.45193862915039e-05,
      "learning_rate": 0.0008501639344262296,
      "loss": 0.0011,
      "step": 26050
    },
    {
      "epoch": 7.506471095772217,
      "grad_norm": 0.026212643831968307,
      "learning_rate": 0.0008498763301696866,
      "loss": 0.0023,
      "step": 26100
    },
    {
      "epoch": 7.520851308599367,
      "grad_norm": 0.00019755847461055964,
      "learning_rate": 0.0008495887259131435,
      "loss": 0.003,
      "step": 26150
    },
    {
      "epoch": 7.5352315214265175,
      "grad_norm": 0.03133034333586693,
      "learning_rate": 0.0008493011216566006,
      "loss": 0.002,
      "step": 26200
    },
    {
      "epoch": 7.549611734253667,
      "grad_norm": 0.007234633434563875,
      "learning_rate": 0.0008490135174000575,
      "loss": 0.0033,
      "step": 26250
    },
    {
      "epoch": 7.563991947080817,
      "grad_norm": 5.349839921109378e-05,
      "learning_rate": 0.0008487259131435145,
      "loss": 0.0038,
      "step": 26300
    },
    {
      "epoch": 7.578372159907967,
      "grad_norm": 0.010944580659270287,
      "learning_rate": 0.0008484383088869716,
      "loss": 0.0018,
      "step": 26350
    },
    {
      "epoch": 7.5927523727351165,
      "grad_norm": 9.798785322345793e-05,
      "learning_rate": 0.0008481507046304285,
      "loss": 0.004,
      "step": 26400
    },
    {
      "epoch": 7.607132585562266,
      "grad_norm": 0.000899273029062897,
      "learning_rate": 0.0008478631003738856,
      "loss": 0.0028,
      "step": 26450
    },
    {
      "epoch": 7.621512798389416,
      "grad_norm": 0.007049343548715115,
      "learning_rate": 0.0008475754961173426,
      "loss": 0.0038,
      "step": 26500
    },
    {
      "epoch": 7.635893011216566,
      "grad_norm": 0.003060664050281048,
      "learning_rate": 0.0008472878918607996,
      "loss": 0.0019,
      "step": 26550
    },
    {
      "epoch": 7.6502732240437155,
      "grad_norm": 0.001670739846304059,
      "learning_rate": 0.0008470002876042565,
      "loss": 0.0022,
      "step": 26600
    },
    {
      "epoch": 7.664653436870866,
      "grad_norm": 0.020115703344345093,
      "learning_rate": 0.0008467126833477136,
      "loss": 0.0027,
      "step": 26650
    },
    {
      "epoch": 7.679033649698016,
      "grad_norm": 0.0003003269375767559,
      "learning_rate": 0.0008464250790911706,
      "loss": 0.002,
      "step": 26700
    },
    {
      "epoch": 7.693413862525166,
      "grad_norm": 3.134455255349167e-05,
      "learning_rate": 0.0008461374748346275,
      "loss": 0.004,
      "step": 26750
    },
    {
      "epoch": 7.707794075352315,
      "grad_norm": 0.00013713997032027692,
      "learning_rate": 0.0008458498705780846,
      "loss": 0.0036,
      "step": 26800
    },
    {
      "epoch": 7.722174288179465,
      "grad_norm": 0.0004040040075778961,
      "learning_rate": 0.0008455622663215415,
      "loss": 0.0016,
      "step": 26850
    },
    {
      "epoch": 7.736554501006615,
      "grad_norm": 0.00028231937903910875,
      "learning_rate": 0.0008452746620649986,
      "loss": 0.0012,
      "step": 26900
    },
    {
      "epoch": 7.7509347138337645,
      "grad_norm": 0.02356177195906639,
      "learning_rate": 0.0008449870578084556,
      "loss": 0.0038,
      "step": 26950
    },
    {
      "epoch": 7.765314926660914,
      "grad_norm": 0.0019066372187808156,
      "learning_rate": 0.0008446994535519126,
      "loss": 0.0043,
      "step": 27000
    },
    {
      "epoch": 7.779695139488064,
      "grad_norm": 0.01980808936059475,
      "learning_rate": 0.0008444118492953696,
      "loss": 0.0051,
      "step": 27050
    },
    {
      "epoch": 7.794075352315215,
      "grad_norm": 0.0009626339306123555,
      "learning_rate": 0.0008441242450388266,
      "loss": 0.0014,
      "step": 27100
    },
    {
      "epoch": 7.808455565142364,
      "grad_norm": 0.01544518768787384,
      "learning_rate": 0.0008438366407822836,
      "loss": 0.0011,
      "step": 27150
    },
    {
      "epoch": 7.822835777969514,
      "grad_norm": 0.0014038264052942395,
      "learning_rate": 0.0008435490365257405,
      "loss": 0.0008,
      "step": 27200
    },
    {
      "epoch": 7.837215990796664,
      "grad_norm": 0.0009198288898915052,
      "learning_rate": 0.0008432614322691976,
      "loss": 0.0039,
      "step": 27250
    },
    {
      "epoch": 7.851596203623814,
      "grad_norm": 0.0004322819586377591,
      "learning_rate": 0.0008429738280126547,
      "loss": 0.0013,
      "step": 27300
    },
    {
      "epoch": 7.865976416450963,
      "grad_norm": 0.00040048034861683846,
      "learning_rate": 0.0008426862237561116,
      "loss": 0.0029,
      "step": 27350
    },
    {
      "epoch": 7.880356629278113,
      "grad_norm": 0.008884756825864315,
      "learning_rate": 0.0008423986194995687,
      "loss": 0.003,
      "step": 27400
    },
    {
      "epoch": 7.894736842105263,
      "grad_norm": 0.0008341788197867572,
      "learning_rate": 0.0008421110152430256,
      "loss": 0.0026,
      "step": 27450
    },
    {
      "epoch": 7.909117054932413,
      "grad_norm": 0.0003581016790121794,
      "learning_rate": 0.0008418234109864826,
      "loss": 0.0016,
      "step": 27500
    },
    {
      "epoch": 7.923497267759563,
      "grad_norm": 0.0001473476440878585,
      "learning_rate": 0.0008415358067299396,
      "loss": 0.0027,
      "step": 27550
    },
    {
      "epoch": 7.937877480586713,
      "grad_norm": 9.671664156485349e-05,
      "learning_rate": 0.0008412482024733966,
      "loss": 0.0022,
      "step": 27600
    },
    {
      "epoch": 7.952257693413863,
      "grad_norm": 0.013482505455613136,
      "learning_rate": 0.0008409605982168536,
      "loss": 0.0019,
      "step": 27650
    },
    {
      "epoch": 7.966637906241012,
      "grad_norm": 0.0018353170016780496,
      "learning_rate": 0.0008406729939603106,
      "loss": 0.0043,
      "step": 27700
    },
    {
      "epoch": 7.981018119068162,
      "grad_norm": 0.0002158653805963695,
      "learning_rate": 0.0008403853897037677,
      "loss": 0.0023,
      "step": 27750
    },
    {
      "epoch": 7.995398331895312,
      "grad_norm": 0.13857626914978027,
      "learning_rate": 0.0008400977854472246,
      "loss": 0.0025,
      "step": 27800
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.01123758777976036,
      "eval_runtime": 11.7266,
      "eval_samples_per_second": 4069.302,
      "eval_steps_per_second": 63.616,
      "step": 27816
    },
    {
      "epoch": 8.009778544722462,
      "grad_norm": 8.754769805818796e-05,
      "learning_rate": 0.0008398101811906817,
      "loss": 0.0053,
      "step": 27850
    },
    {
      "epoch": 8.024158757549612,
      "grad_norm": 0.0001548811560496688,
      "learning_rate": 0.0008395225769341387,
      "loss": 0.005,
      "step": 27900
    },
    {
      "epoch": 8.038538970376761,
      "grad_norm": 0.0003376194799784571,
      "learning_rate": 0.0008392349726775956,
      "loss": 0.0098,
      "step": 27950
    },
    {
      "epoch": 8.052919183203912,
      "grad_norm": 0.00013913260772824287,
      "learning_rate": 0.0008389473684210527,
      "loss": 0.0037,
      "step": 28000
    },
    {
      "epoch": 8.06729939603106,
      "grad_norm": 0.08385294675827026,
      "learning_rate": 0.0008386597641645096,
      "loss": 0.0026,
      "step": 28050
    },
    {
      "epoch": 8.081679608858211,
      "grad_norm": 8.89215589268133e-05,
      "learning_rate": 0.0008383721599079666,
      "loss": 0.0035,
      "step": 28100
    },
    {
      "epoch": 8.09605982168536,
      "grad_norm": 0.0022567766718566418,
      "learning_rate": 0.0008380845556514236,
      "loss": 0.0023,
      "step": 28150
    },
    {
      "epoch": 8.11044003451251,
      "grad_norm": 0.02848648838698864,
      "learning_rate": 0.0008377969513948807,
      "loss": 0.0021,
      "step": 28200
    },
    {
      "epoch": 8.124820247339661,
      "grad_norm": 0.01973527856171131,
      "learning_rate": 0.0008375093471383377,
      "loss": 0.0035,
      "step": 28250
    },
    {
      "epoch": 8.13920046016681,
      "grad_norm": 0.0004696760152000934,
      "learning_rate": 0.0008372217428817947,
      "loss": 0.0041,
      "step": 28300
    },
    {
      "epoch": 8.15358067299396,
      "grad_norm": 0.0009546267683617771,
      "learning_rate": 0.0008369341386252517,
      "loss": 0.002,
      "step": 28350
    },
    {
      "epoch": 8.16796088582111,
      "grad_norm": 0.011149128898978233,
      "learning_rate": 0.0008366465343687086,
      "loss": 0.0054,
      "step": 28400
    },
    {
      "epoch": 8.18234109864826,
      "grad_norm": 0.02942657098174095,
      "learning_rate": 0.0008363589301121657,
      "loss": 0.003,
      "step": 28450
    },
    {
      "epoch": 8.19672131147541,
      "grad_norm": 0.00012273585889488459,
      "learning_rate": 0.0008360713258556227,
      "loss": 0.0032,
      "step": 28500
    },
    {
      "epoch": 8.21110152430256,
      "grad_norm": 0.033226992934942245,
      "learning_rate": 0.0008357837215990796,
      "loss": 0.0016,
      "step": 28550
    },
    {
      "epoch": 8.225481737129709,
      "grad_norm": 0.000232304199016653,
      "learning_rate": 0.0008354961173425368,
      "loss": 0.0025,
      "step": 28600
    },
    {
      "epoch": 8.23986194995686,
      "grad_norm": 0.0008991716895252466,
      "learning_rate": 0.0008352085130859937,
      "loss": 0.0014,
      "step": 28650
    },
    {
      "epoch": 8.25424216278401,
      "grad_norm": 0.13035690784454346,
      "learning_rate": 0.0008349209088294507,
      "loss": 0.0023,
      "step": 28700
    },
    {
      "epoch": 8.268622375611159,
      "grad_norm": 0.0008381035877391696,
      "learning_rate": 0.0008346333045729077,
      "loss": 0.0021,
      "step": 28750
    },
    {
      "epoch": 8.28300258843831,
      "grad_norm": 0.00010231421038042754,
      "learning_rate": 0.0008343457003163647,
      "loss": 0.0035,
      "step": 28800
    },
    {
      "epoch": 8.297382801265458,
      "grad_norm": 0.04242374747991562,
      "learning_rate": 0.0008340580960598217,
      "loss": 0.0037,
      "step": 28850
    },
    {
      "epoch": 8.311763014092609,
      "grad_norm": 0.0021880727726966143,
      "learning_rate": 0.0008337704918032787,
      "loss": 0.0024,
      "step": 28900
    },
    {
      "epoch": 8.326143226919758,
      "grad_norm": 0.00047771993558853865,
      "learning_rate": 0.0008334828875467357,
      "loss": 0.0049,
      "step": 28950
    },
    {
      "epoch": 8.340523439746908,
      "grad_norm": 0.000983664533123374,
      "learning_rate": 0.0008331952832901926,
      "loss": 0.0095,
      "step": 29000
    },
    {
      "epoch": 8.354903652574059,
      "grad_norm": 6.117926386650652e-05,
      "learning_rate": 0.0008329076790336498,
      "loss": 0.0022,
      "step": 29050
    },
    {
      "epoch": 8.369283865401208,
      "grad_norm": 0.002526277909055352,
      "learning_rate": 0.0008326200747771068,
      "loss": 0.0027,
      "step": 29100
    },
    {
      "epoch": 8.383664078228358,
      "grad_norm": 0.00011170015204697847,
      "learning_rate": 0.0008323324705205637,
      "loss": 0.0018,
      "step": 29150
    },
    {
      "epoch": 8.398044291055507,
      "grad_norm": 0.03973805531859398,
      "learning_rate": 0.0008320448662640208,
      "loss": 0.0032,
      "step": 29200
    },
    {
      "epoch": 8.412424503882658,
      "grad_norm": 9.239800419891253e-05,
      "learning_rate": 0.0008317572620074777,
      "loss": 0.0035,
      "step": 29250
    },
    {
      "epoch": 8.426804716709807,
      "grad_norm": 0.010952229611575603,
      "learning_rate": 0.0008314696577509347,
      "loss": 0.0057,
      "step": 29300
    },
    {
      "epoch": 8.441184929536957,
      "grad_norm": 0.0031126646790653467,
      "learning_rate": 0.0008311820534943917,
      "loss": 0.0022,
      "step": 29350
    },
    {
      "epoch": 8.455565142364106,
      "grad_norm": 0.00010988416033796966,
      "learning_rate": 0.0008308944492378487,
      "loss": 0.0028,
      "step": 29400
    },
    {
      "epoch": 8.469945355191257,
      "grad_norm": 0.000636046112049371,
      "learning_rate": 0.0008306068449813057,
      "loss": 0.0022,
      "step": 29450
    },
    {
      "epoch": 8.484325568018406,
      "grad_norm": 0.028830457478761673,
      "learning_rate": 0.0008303192407247628,
      "loss": 0.0045,
      "step": 29500
    },
    {
      "epoch": 8.498705780845556,
      "grad_norm": 0.04236872121691704,
      "learning_rate": 0.0008300316364682198,
      "loss": 0.0026,
      "step": 29550
    },
    {
      "epoch": 8.513085993672707,
      "grad_norm": 9.255146869691089e-05,
      "learning_rate": 0.0008297440322116767,
      "loss": 0.0042,
      "step": 29600
    },
    {
      "epoch": 8.527466206499856,
      "grad_norm": 0.00012956306454725564,
      "learning_rate": 0.0008294564279551338,
      "loss": 0.0036,
      "step": 29650
    },
    {
      "epoch": 8.541846419327007,
      "grad_norm": 0.00010443298378959298,
      "learning_rate": 0.0008291688236985907,
      "loss": 0.006,
      "step": 29700
    },
    {
      "epoch": 8.556226632154155,
      "grad_norm": 7.150048622861505e-05,
      "learning_rate": 0.0008288812194420477,
      "loss": 0.0032,
      "step": 29750
    },
    {
      "epoch": 8.570606844981306,
      "grad_norm": 0.00015860590792726725,
      "learning_rate": 0.0008285936151855048,
      "loss": 0.0031,
      "step": 29800
    },
    {
      "epoch": 8.584987057808455,
      "grad_norm": 0.019643323495984077,
      "learning_rate": 0.0008283060109289617,
      "loss": 0.0015,
      "step": 29850
    },
    {
      "epoch": 8.599367270635605,
      "grad_norm": 0.020973680540919304,
      "learning_rate": 0.0008280184066724187,
      "loss": 0.0022,
      "step": 29900
    },
    {
      "epoch": 8.613747483462756,
      "grad_norm": 0.06789937615394592,
      "learning_rate": 0.0008277308024158758,
      "loss": 0.0025,
      "step": 29950
    },
    {
      "epoch": 8.628127696289905,
      "grad_norm": 0.0008123383740894496,
      "learning_rate": 0.0008274431981593328,
      "loss": 0.0059,
      "step": 30000
    },
    {
      "epoch": 8.642507909117056,
      "grad_norm": 0.016299830749630928,
      "learning_rate": 0.0008271555939027898,
      "loss": 0.0029,
      "step": 30050
    },
    {
      "epoch": 8.656888121944204,
      "grad_norm": 0.00030315358890220523,
      "learning_rate": 0.0008268679896462468,
      "loss": 0.0047,
      "step": 30100
    },
    {
      "epoch": 8.671268334771355,
      "grad_norm": 0.00928559247404337,
      "learning_rate": 0.0008265803853897038,
      "loss": 0.0008,
      "step": 30150
    },
    {
      "epoch": 8.685648547598504,
      "grad_norm": 8.545280434191227e-05,
      "learning_rate": 0.0008262927811331607,
      "loss": 0.0037,
      "step": 30200
    },
    {
      "epoch": 8.700028760425655,
      "grad_norm": 0.0064842659048736095,
      "learning_rate": 0.0008260051768766178,
      "loss": 0.0061,
      "step": 30250
    },
    {
      "epoch": 8.714408973252803,
      "grad_norm": 0.0032584473956376314,
      "learning_rate": 0.0008257175726200747,
      "loss": 0.0024,
      "step": 30300
    },
    {
      "epoch": 8.728789186079954,
      "grad_norm": 0.006041527725756168,
      "learning_rate": 0.0008254299683635318,
      "loss": 0.0048,
      "step": 30350
    },
    {
      "epoch": 8.743169398907105,
      "grad_norm": 5.3098396165296435e-05,
      "learning_rate": 0.0008251423641069889,
      "loss": 0.0033,
      "step": 30400
    },
    {
      "epoch": 8.757549611734254,
      "grad_norm": 0.05686253309249878,
      "learning_rate": 0.0008248547598504458,
      "loss": 0.0023,
      "step": 30450
    },
    {
      "epoch": 8.771929824561404,
      "grad_norm": 8.666341454954818e-05,
      "learning_rate": 0.0008245671555939028,
      "loss": 0.0052,
      "step": 30500
    },
    {
      "epoch": 8.786310037388553,
      "grad_norm": 0.00021440748241730034,
      "learning_rate": 0.0008242795513373598,
      "loss": 0.002,
      "step": 30550
    },
    {
      "epoch": 8.800690250215704,
      "grad_norm": 0.000194267209735699,
      "learning_rate": 0.0008239919470808168,
      "loss": 0.0016,
      "step": 30600
    },
    {
      "epoch": 8.815070463042852,
      "grad_norm": 0.0562095008790493,
      "learning_rate": 0.0008237043428242738,
      "loss": 0.0038,
      "step": 30650
    },
    {
      "epoch": 8.829450675870003,
      "grad_norm": 0.01714950241148472,
      "learning_rate": 0.0008234167385677308,
      "loss": 0.0034,
      "step": 30700
    },
    {
      "epoch": 8.843830888697152,
      "grad_norm": 0.0969601422548294,
      "learning_rate": 0.0008231291343111878,
      "loss": 0.002,
      "step": 30750
    },
    {
      "epoch": 8.858211101524303,
      "grad_norm": 0.0006856310646981001,
      "learning_rate": 0.0008228415300546448,
      "loss": 0.0012,
      "step": 30800
    },
    {
      "epoch": 8.872591314351453,
      "grad_norm": 0.00025222485419362783,
      "learning_rate": 0.0008225539257981019,
      "loss": 0.0052,
      "step": 30850
    },
    {
      "epoch": 8.886971527178602,
      "grad_norm": 0.0008510937332175672,
      "learning_rate": 0.0008222663215415588,
      "loss": 0.003,
      "step": 30900
    },
    {
      "epoch": 8.901351740005753,
      "grad_norm": 0.01711861975491047,
      "learning_rate": 0.0008219787172850158,
      "loss": 0.0017,
      "step": 30950
    },
    {
      "epoch": 8.915731952832902,
      "grad_norm": 0.00018502034072298557,
      "learning_rate": 0.0008216911130284729,
      "loss": 0.0046,
      "step": 31000
    },
    {
      "epoch": 8.930112165660052,
      "grad_norm": 0.0027283576782792807,
      "learning_rate": 0.0008214035087719298,
      "loss": 0.0029,
      "step": 31050
    },
    {
      "epoch": 8.944492378487201,
      "grad_norm": 0.012974519282579422,
      "learning_rate": 0.0008211159045153868,
      "loss": 0.0031,
      "step": 31100
    },
    {
      "epoch": 8.958872591314352,
      "grad_norm": 4.962798266205937e-05,
      "learning_rate": 0.0008208283002588438,
      "loss": 0.0026,
      "step": 31150
    },
    {
      "epoch": 8.9732528041415,
      "grad_norm": 0.0020082241389900446,
      "learning_rate": 0.0008205406960023009,
      "loss": 0.0043,
      "step": 31200
    },
    {
      "epoch": 8.987633016968651,
      "grad_norm": 0.018209535628557205,
      "learning_rate": 0.0008202530917457579,
      "loss": 0.0039,
      "step": 31250
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.01264193281531334,
      "eval_runtime": 11.6368,
      "eval_samples_per_second": 4100.705,
      "eval_steps_per_second": 64.107,
      "step": 31293
    },
    {
      "epoch": 9.002013229795802,
      "grad_norm": 0.0007946937112137675,
      "learning_rate": 0.0008199654874892149,
      "loss": 0.0016,
      "step": 31300
    },
    {
      "epoch": 9.01639344262295,
      "grad_norm": 0.00021794393251184374,
      "learning_rate": 0.0008196778832326719,
      "loss": 0.0029,
      "step": 31350
    },
    {
      "epoch": 9.030773655450101,
      "grad_norm": 0.051154330372810364,
      "learning_rate": 0.0008193902789761288,
      "loss": 0.0035,
      "step": 31400
    },
    {
      "epoch": 9.04515386827725,
      "grad_norm": 0.0009665918187238276,
      "learning_rate": 0.0008191026747195859,
      "loss": 0.0018,
      "step": 31450
    },
    {
      "epoch": 9.0595340811044,
      "grad_norm": 0.009634808637201786,
      "learning_rate": 0.0008188150704630428,
      "loss": 0.0012,
      "step": 31500
    },
    {
      "epoch": 9.07391429393155,
      "grad_norm": 0.0009166346862912178,
      "learning_rate": 0.0008185274662064998,
      "loss": 0.0032,
      "step": 31550
    },
    {
      "epoch": 9.0882945067587,
      "grad_norm": 0.010962197557091713,
      "learning_rate": 0.000818239861949957,
      "loss": 0.0019,
      "step": 31600
    },
    {
      "epoch": 9.102674719585849,
      "grad_norm": 0.07257815450429916,
      "learning_rate": 0.0008179522576934139,
      "loss": 0.0016,
      "step": 31650
    },
    {
      "epoch": 9.117054932413,
      "grad_norm": 0.0001773837284417823,
      "learning_rate": 0.0008176646534368709,
      "loss": 0.0022,
      "step": 31700
    },
    {
      "epoch": 9.13143514524015,
      "grad_norm": 5.013855479774065e-05,
      "learning_rate": 0.0008173770491803279,
      "loss": 0.0029,
      "step": 31750
    },
    {
      "epoch": 9.1458153580673,
      "grad_norm": 0.016640357673168182,
      "learning_rate": 0.0008170894449237849,
      "loss": 0.0046,
      "step": 31800
    },
    {
      "epoch": 9.16019557089445,
      "grad_norm": 3.9311817090492696e-05,
      "learning_rate": 0.0008168018406672419,
      "loss": 0.0014,
      "step": 31850
    },
    {
      "epoch": 9.174575783721599,
      "grad_norm": 8.693712152307853e-05,
      "learning_rate": 0.0008165142364106989,
      "loss": 0.0013,
      "step": 31900
    },
    {
      "epoch": 9.18895599654875,
      "grad_norm": 0.016976337879896164,
      "learning_rate": 0.0008162266321541559,
      "loss": 0.0015,
      "step": 31950
    },
    {
      "epoch": 9.203336209375898,
      "grad_norm": 0.03640511631965637,
      "learning_rate": 0.0008159390278976128,
      "loss": 0.0032,
      "step": 32000
    },
    {
      "epoch": 9.217716422203049,
      "grad_norm": 0.0006354229408316314,
      "learning_rate": 0.00081565142364107,
      "loss": 0.0033,
      "step": 32050
    },
    {
      "epoch": 9.232096635030198,
      "grad_norm": 0.0067212278954684734,
      "learning_rate": 0.0008153638193845269,
      "loss": 0.0021,
      "step": 32100
    },
    {
      "epoch": 9.246476847857348,
      "grad_norm": 5.473688361234963e-05,
      "learning_rate": 0.0008150762151279839,
      "loss": 0.001,
      "step": 32150
    },
    {
      "epoch": 9.260857060684499,
      "grad_norm": 0.009452247060835361,
      "learning_rate": 0.000814788610871441,
      "loss": 0.0011,
      "step": 32200
    },
    {
      "epoch": 9.275237273511648,
      "grad_norm": 0.00019047388923354447,
      "learning_rate": 0.0008145010066148979,
      "loss": 0.0043,
      "step": 32250
    },
    {
      "epoch": 9.289617486338798,
      "grad_norm": 0.009696587920188904,
      "learning_rate": 0.0008142134023583549,
      "loss": 0.0023,
      "step": 32300
    },
    {
      "epoch": 9.303997699165947,
      "grad_norm": 0.004811556544154882,
      "learning_rate": 0.0008139257981018119,
      "loss": 0.0019,
      "step": 32350
    },
    {
      "epoch": 9.318377911993098,
      "grad_norm": 0.00041538316872902215,
      "learning_rate": 0.0008136381938452689,
      "loss": 0.0038,
      "step": 32400
    },
    {
      "epoch": 9.332758124820247,
      "grad_norm": 0.00016744599270168692,
      "learning_rate": 0.0008133505895887258,
      "loss": 0.0029,
      "step": 32450
    },
    {
      "epoch": 9.347138337647397,
      "grad_norm": 0.03480440378189087,
      "learning_rate": 0.000813062985332183,
      "loss": 0.0025,
      "step": 32500
    },
    {
      "epoch": 9.361518550474546,
      "grad_norm": 0.024297483265399933,
      "learning_rate": 0.00081277538107564,
      "loss": 0.0022,
      "step": 32550
    },
    {
      "epoch": 9.375898763301697,
      "grad_norm": 0.0004307963827159256,
      "learning_rate": 0.0008124877768190969,
      "loss": 0.0017,
      "step": 32600
    },
    {
      "epoch": 9.390278976128847,
      "grad_norm": 0.010403160937130451,
      "learning_rate": 0.000812200172562554,
      "loss": 0.0017,
      "step": 32650
    },
    {
      "epoch": 9.404659188955996,
      "grad_norm": 0.0001904039381770417,
      "learning_rate": 0.0008119125683060109,
      "loss": 0.0038,
      "step": 32700
    },
    {
      "epoch": 9.419039401783147,
      "grad_norm": 0.043622925877571106,
      "learning_rate": 0.0008116249640494679,
      "loss": 0.0023,
      "step": 32750
    },
    {
      "epoch": 9.433419614610296,
      "grad_norm": 0.0018303468823432922,
      "learning_rate": 0.000811337359792925,
      "loss": 0.0035,
      "step": 32800
    },
    {
      "epoch": 9.447799827437446,
      "grad_norm": 0.00020812558068428189,
      "learning_rate": 0.0008110497555363819,
      "loss": 0.0046,
      "step": 32850
    },
    {
      "epoch": 9.462180040264595,
      "grad_norm": 0.00042766158003360033,
      "learning_rate": 0.0008107621512798389,
      "loss": 0.0014,
      "step": 32900
    },
    {
      "epoch": 9.476560253091746,
      "grad_norm": 0.018845688551664352,
      "learning_rate": 0.000810474547023296,
      "loss": 0.0031,
      "step": 32950
    },
    {
      "epoch": 9.490940465918897,
      "grad_norm": 0.002199322683736682,
      "learning_rate": 0.000810186942766753,
      "loss": 0.0026,
      "step": 33000
    },
    {
      "epoch": 9.505320678746045,
      "grad_norm": 0.0002279472246300429,
      "learning_rate": 0.0008098993385102099,
      "loss": 0.0033,
      "step": 33050
    },
    {
      "epoch": 9.519700891573196,
      "grad_norm": 0.036202460527420044,
      "learning_rate": 0.000809611734253667,
      "loss": 0.0023,
      "step": 33100
    },
    {
      "epoch": 9.534081104400345,
      "grad_norm": 0.012632337398827076,
      "learning_rate": 0.000809324129997124,
      "loss": 0.003,
      "step": 33150
    },
    {
      "epoch": 9.548461317227495,
      "grad_norm": 0.00035334969288669527,
      "learning_rate": 0.0008090365257405809,
      "loss": 0.0016,
      "step": 33200
    },
    {
      "epoch": 9.562841530054644,
      "grad_norm": 0.04331590607762337,
      "learning_rate": 0.000808748921484038,
      "loss": 0.0013,
      "step": 33250
    },
    {
      "epoch": 9.577221742881795,
      "grad_norm": 0.00018627640383783728,
      "learning_rate": 0.0008084613172274949,
      "loss": 0.0057,
      "step": 33300
    },
    {
      "epoch": 9.591601955708944,
      "grad_norm": 0.00014938708045519888,
      "learning_rate": 0.000808173712970952,
      "loss": 0.0032,
      "step": 33350
    },
    {
      "epoch": 9.605982168536094,
      "grad_norm": 0.01424699742347002,
      "learning_rate": 0.0008078861087144091,
      "loss": 0.0045,
      "step": 33400
    },
    {
      "epoch": 9.620362381363243,
      "grad_norm": 0.0005835050251334906,
      "learning_rate": 0.000807598504457866,
      "loss": 0.0058,
      "step": 33450
    },
    {
      "epoch": 9.634742594190394,
      "grad_norm": 0.0010034787701442838,
      "learning_rate": 0.000807310900201323,
      "loss": 0.0076,
      "step": 33500
    },
    {
      "epoch": 9.649122807017545,
      "grad_norm": 0.006592285353690386,
      "learning_rate": 0.00080702329594478,
      "loss": 0.0034,
      "step": 33550
    },
    {
      "epoch": 9.663503019844693,
      "grad_norm": 0.03260616958141327,
      "learning_rate": 0.000806735691688237,
      "loss": 0.0039,
      "step": 33600
    },
    {
      "epoch": 9.677883232671844,
      "grad_norm": 0.00017299188766628504,
      "learning_rate": 0.0008064480874316939,
      "loss": 0.0023,
      "step": 33650
    },
    {
      "epoch": 9.692263445498993,
      "grad_norm": 9.727384167490527e-05,
      "learning_rate": 0.000806160483175151,
      "loss": 0.0046,
      "step": 33700
    },
    {
      "epoch": 9.706643658326144,
      "grad_norm": 0.0021681273356080055,
      "learning_rate": 0.000805872878918608,
      "loss": 0.0063,
      "step": 33750
    },
    {
      "epoch": 9.721023871153292,
      "grad_norm": 0.00018534844275563955,
      "learning_rate": 0.000805585274662065,
      "loss": 0.0037,
      "step": 33800
    },
    {
      "epoch": 9.735404083980443,
      "grad_norm": 0.0015927936183288693,
      "learning_rate": 0.0008052976704055221,
      "loss": 0.0055,
      "step": 33850
    },
    {
      "epoch": 9.749784296807594,
      "grad_norm": 5.494839933817275e-05,
      "learning_rate": 0.000805010066148979,
      "loss": 0.0078,
      "step": 33900
    },
    {
      "epoch": 9.764164509634742,
      "grad_norm": 0.0001024304874590598,
      "learning_rate": 0.000804722461892436,
      "loss": 0.0018,
      "step": 33950
    },
    {
      "epoch": 9.778544722461893,
      "grad_norm": 0.01910032145678997,
      "learning_rate": 0.0008044348576358931,
      "loss": 0.0036,
      "step": 34000
    },
    {
      "epoch": 9.792924935289042,
      "grad_norm": 0.0001860040210885927,
      "learning_rate": 0.00080414725337935,
      "loss": 0.0023,
      "step": 34050
    },
    {
      "epoch": 9.807305148116193,
      "grad_norm": 0.01692694053053856,
      "learning_rate": 0.000803859649122807,
      "loss": 0.0054,
      "step": 34100
    },
    {
      "epoch": 9.821685360943341,
      "grad_norm": 0.005506233312189579,
      "learning_rate": 0.000803572044866264,
      "loss": 0.0071,
      "step": 34150
    },
    {
      "epoch": 9.836065573770492,
      "grad_norm": 0.001521476311609149,
      "learning_rate": 0.000803284440609721,
      "loss": 0.0063,
      "step": 34200
    },
    {
      "epoch": 9.850445786597641,
      "grad_norm": 0.030575254932045937,
      "learning_rate": 0.000802996836353178,
      "loss": 0.0022,
      "step": 34250
    },
    {
      "epoch": 9.864825999424792,
      "grad_norm": 0.00045319212949834764,
      "learning_rate": 0.0008027092320966351,
      "loss": 0.0008,
      "step": 34300
    },
    {
      "epoch": 9.87920621225194,
      "grad_norm": 0.0013819829327985644,
      "learning_rate": 0.0008024216278400921,
      "loss": 0.002,
      "step": 34350
    },
    {
      "epoch": 9.893586425079091,
      "grad_norm": 0.13391999900341034,
      "learning_rate": 0.000802134023583549,
      "loss": 0.0041,
      "step": 34400
    },
    {
      "epoch": 9.907966637906242,
      "grad_norm": 0.0005471984040923417,
      "learning_rate": 0.0008018464193270061,
      "loss": 0.0049,
      "step": 34450
    },
    {
      "epoch": 9.92234685073339,
      "grad_norm": 7.0811620389577e-05,
      "learning_rate": 0.000801558815070463,
      "loss": 0.0005,
      "step": 34500
    },
    {
      "epoch": 9.936727063560541,
      "grad_norm": 0.0017307669622823596,
      "learning_rate": 0.00080127121081392,
      "loss": 0.0024,
      "step": 34550
    },
    {
      "epoch": 9.95110727638769,
      "grad_norm": 0.012219459749758244,
      "learning_rate": 0.0008009836065573771,
      "loss": 0.003,
      "step": 34600
    },
    {
      "epoch": 9.96548748921484,
      "grad_norm": 0.0003811603528447449,
      "learning_rate": 0.000800696002300834,
      "loss": 0.0023,
      "step": 34650
    },
    {
      "epoch": 9.97986770204199,
      "grad_norm": 0.0005067018209956586,
      "learning_rate": 0.0008004083980442911,
      "loss": 0.0038,
      "step": 34700
    },
    {
      "epoch": 9.99424791486914,
      "grad_norm": 0.23989643156528473,
      "learning_rate": 0.0008001207937877481,
      "loss": 0.0062,
      "step": 34750
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.010902230627834797,
      "eval_runtime": 12.2458,
      "eval_samples_per_second": 3896.777,
      "eval_steps_per_second": 60.919,
      "step": 34770
    },
    {
      "epoch": 10.00862812769629,
      "grad_norm": 0.00025379564613103867,
      "learning_rate": 0.0007998331895312051,
      "loss": 0.0009,
      "step": 34800
    },
    {
      "epoch": 10.02300834052344,
      "grad_norm": 0.0039877453818917274,
      "learning_rate": 0.000799545585274662,
      "loss": 0.0059,
      "step": 34850
    },
    {
      "epoch": 10.03738855335059,
      "grad_norm": 0.0006898054271005094,
      "learning_rate": 0.0007992579810181191,
      "loss": 0.0012,
      "step": 34900
    },
    {
      "epoch": 10.051768766177739,
      "grad_norm": 0.00010115680197486654,
      "learning_rate": 0.0007989703767615761,
      "loss": 0.0031,
      "step": 34950
    },
    {
      "epoch": 10.06614897900489,
      "grad_norm": 5.525936285266653e-05,
      "learning_rate": 0.000798682772505033,
      "loss": 0.0036,
      "step": 35000
    },
    {
      "epoch": 10.080529191832039,
      "grad_norm": 0.00011161668953718618,
      "learning_rate": 0.0007983951682484901,
      "loss": 0.0026,
      "step": 35050
    },
    {
      "epoch": 10.09490940465919,
      "grad_norm": 0.00013750497600995004,
      "learning_rate": 0.000798107563991947,
      "loss": 0.0029,
      "step": 35100
    },
    {
      "epoch": 10.109289617486338,
      "grad_norm": 0.07480132579803467,
      "learning_rate": 0.0007978199597354041,
      "loss": 0.0028,
      "step": 35150
    },
    {
      "epoch": 10.123669830313489,
      "grad_norm": 0.00012745028652716428,
      "learning_rate": 0.0007975323554788611,
      "loss": 0.004,
      "step": 35200
    },
    {
      "epoch": 10.13805004314064,
      "grad_norm": 0.14802142977714539,
      "learning_rate": 0.0007972447512223181,
      "loss": 0.0043,
      "step": 35250
    },
    {
      "epoch": 10.152430255967788,
      "grad_norm": 0.002844462404027581,
      "learning_rate": 0.0007969571469657751,
      "loss": 0.0028,
      "step": 35300
    },
    {
      "epoch": 10.166810468794939,
      "grad_norm": 0.00019379645527806133,
      "learning_rate": 0.0007966695427092321,
      "loss": 0.0061,
      "step": 35350
    },
    {
      "epoch": 10.181190681622088,
      "grad_norm": 0.0001529731962364167,
      "learning_rate": 0.0007963819384526891,
      "loss": 0.0036,
      "step": 35400
    },
    {
      "epoch": 10.195570894449238,
      "grad_norm": 0.0005302235367707908,
      "learning_rate": 0.000796094334196146,
      "loss": 0.0038,
      "step": 35450
    },
    {
      "epoch": 10.209951107276387,
      "grad_norm": 0.0005565003375522792,
      "learning_rate": 0.0007958067299396031,
      "loss": 0.0022,
      "step": 35500
    },
    {
      "epoch": 10.224331320103538,
      "grad_norm": 0.00018822922720573843,
      "learning_rate": 0.0007955191256830602,
      "loss": 0.0037,
      "step": 35550
    },
    {
      "epoch": 10.238711532930687,
      "grad_norm": 0.019507061690092087,
      "learning_rate": 0.0007952315214265171,
      "loss": 0.0031,
      "step": 35600
    },
    {
      "epoch": 10.253091745757837,
      "grad_norm": 0.06351424008607864,
      "learning_rate": 0.0007949439171699742,
      "loss": 0.0019,
      "step": 35650
    },
    {
      "epoch": 10.267471958584988,
      "grad_norm": 0.014470024034380913,
      "learning_rate": 0.0007946563129134311,
      "loss": 0.0038,
      "step": 35700
    },
    {
      "epoch": 10.281852171412137,
      "grad_norm": 7.980719965416938e-05,
      "learning_rate": 0.0007943687086568881,
      "loss": 0.0029,
      "step": 35750
    },
    {
      "epoch": 10.296232384239287,
      "grad_norm": 0.00031598631176166236,
      "learning_rate": 0.0007940811044003451,
      "loss": 0.0027,
      "step": 35800
    },
    {
      "epoch": 10.310612597066436,
      "grad_norm": 0.00038963559200055897,
      "learning_rate": 0.0007937935001438021,
      "loss": 0.0025,
      "step": 35850
    },
    {
      "epoch": 10.324992809893587,
      "grad_norm": 0.0614350363612175,
      "learning_rate": 0.0007935058958872591,
      "loss": 0.002,
      "step": 35900
    },
    {
      "epoch": 10.339373022720736,
      "grad_norm": 0.547601580619812,
      "learning_rate": 0.0007932182916307162,
      "loss": 0.0053,
      "step": 35950
    },
    {
      "epoch": 10.353753235547886,
      "grad_norm": 0.0006895602564327419,
      "learning_rate": 0.0007929306873741732,
      "loss": 0.0024,
      "step": 36000
    },
    {
      "epoch": 10.368133448375035,
      "grad_norm": 0.0015423991717398167,
      "learning_rate": 0.0007926430831176301,
      "loss": 0.0021,
      "step": 36050
    },
    {
      "epoch": 10.382513661202186,
      "grad_norm": 0.0015839876141399145,
      "learning_rate": 0.0007923554788610872,
      "loss": 0.0032,
      "step": 36100
    },
    {
      "epoch": 10.396893874029336,
      "grad_norm": 0.04777204617857933,
      "learning_rate": 0.0007920678746045442,
      "loss": 0.0021,
      "step": 36150
    },
    {
      "epoch": 10.411274086856485,
      "grad_norm": 0.0006857726257294416,
      "learning_rate": 0.0007917802703480011,
      "loss": 0.0023,
      "step": 36200
    },
    {
      "epoch": 10.425654299683636,
      "grad_norm": 0.00018913595704361796,
      "learning_rate": 0.0007914926660914582,
      "loss": 0.0011,
      "step": 36250
    },
    {
      "epoch": 10.440034512510785,
      "grad_norm": 0.0010950354626402259,
      "learning_rate": 0.0007912050618349151,
      "loss": 0.0037,
      "step": 36300
    },
    {
      "epoch": 10.454414725337935,
      "grad_norm": 0.005993627943098545,
      "learning_rate": 0.0007909174575783721,
      "loss": 0.0009,
      "step": 36350
    },
    {
      "epoch": 10.468794938165084,
      "grad_norm": 0.005819281097501516,
      "learning_rate": 0.0007906298533218292,
      "loss": 0.0036,
      "step": 36400
    },
    {
      "epoch": 10.483175150992235,
      "grad_norm": 0.10071375966072083,
      "learning_rate": 0.0007903422490652862,
      "loss": 0.0035,
      "step": 36450
    },
    {
      "epoch": 10.497555363819384,
      "grad_norm": 0.0008228271035477519,
      "learning_rate": 0.0007900546448087432,
      "loss": 0.0018,
      "step": 36500
    },
    {
      "epoch": 10.511935576646534,
      "grad_norm": 0.002529243240132928,
      "learning_rate": 0.0007897670405522002,
      "loss": 0.0024,
      "step": 36550
    },
    {
      "epoch": 10.526315789473685,
      "grad_norm": 0.00032129717874340713,
      "learning_rate": 0.0007894794362956572,
      "loss": 0.0049,
      "step": 36600
    },
    {
      "epoch": 10.540696002300834,
      "grad_norm": 0.0645858496427536,
      "learning_rate": 0.0007891918320391141,
      "loss": 0.0049,
      "step": 36650
    },
    {
      "epoch": 10.555076215127984,
      "grad_norm": 0.000162062919116579,
      "learning_rate": 0.0007889042277825712,
      "loss": 0.0023,
      "step": 36700
    },
    {
      "epoch": 10.569456427955133,
      "grad_norm": 0.001016592257656157,
      "learning_rate": 0.0007886166235260282,
      "loss": 0.0019,
      "step": 36750
    },
    {
      "epoch": 10.583836640782284,
      "grad_norm": 8.01169007900171e-05,
      "learning_rate": 0.0007883290192694851,
      "loss": 0.0027,
      "step": 36800
    },
    {
      "epoch": 10.598216853609433,
      "grad_norm": 0.0007622120901942253,
      "learning_rate": 0.0007880414150129423,
      "loss": 0.0023,
      "step": 36850
    },
    {
      "epoch": 10.612597066436583,
      "grad_norm": 0.0007284002494998276,
      "learning_rate": 0.0007877538107563992,
      "loss": 0.0035,
      "step": 36900
    },
    {
      "epoch": 10.626977279263734,
      "grad_norm": 0.00039661501068621874,
      "learning_rate": 0.0007874662064998562,
      "loss": 0.0047,
      "step": 36950
    },
    {
      "epoch": 10.641357492090883,
      "grad_norm": 0.022682487964630127,
      "learning_rate": 0.0007871786022433132,
      "loss": 0.0011,
      "step": 37000
    },
    {
      "epoch": 10.655737704918034,
      "grad_norm": 3.869271677103825e-05,
      "learning_rate": 0.0007868909979867702,
      "loss": 0.0017,
      "step": 37050
    },
    {
      "epoch": 10.670117917745182,
      "grad_norm": 0.04155120998620987,
      "learning_rate": 0.0007866033937302272,
      "loss": 0.0024,
      "step": 37100
    },
    {
      "epoch": 10.684498130572333,
      "grad_norm": 6.8890571128577e-05,
      "learning_rate": 0.0007863157894736842,
      "loss": 0.0029,
      "step": 37150
    },
    {
      "epoch": 10.698878343399482,
      "grad_norm": 2.466708974679932e-05,
      "learning_rate": 0.0007860281852171412,
      "loss": 0.004,
      "step": 37200
    },
    {
      "epoch": 10.713258556226632,
      "grad_norm": 9.757388761499897e-05,
      "learning_rate": 0.0007857405809605981,
      "loss": 0.0033,
      "step": 37250
    },
    {
      "epoch": 10.727638769053781,
      "grad_norm": 0.164540633559227,
      "learning_rate": 0.0007854529767040553,
      "loss": 0.0036,
      "step": 37300
    },
    {
      "epoch": 10.742018981880932,
      "grad_norm": 0.0010651497868821025,
      "learning_rate": 0.0007851653724475123,
      "loss": 0.0032,
      "step": 37350
    },
    {
      "epoch": 10.75639919470808,
      "grad_norm": 0.0001454181328881532,
      "learning_rate": 0.0007848777681909692,
      "loss": 0.0016,
      "step": 37400
    },
    {
      "epoch": 10.770779407535231,
      "grad_norm": 0.011951836757361889,
      "learning_rate": 0.0007845901639344263,
      "loss": 0.0025,
      "step": 37450
    },
    {
      "epoch": 10.785159620362382,
      "grad_norm": 0.0021238508634269238,
      "learning_rate": 0.0007843025596778832,
      "loss": 0.0026,
      "step": 37500
    },
    {
      "epoch": 10.799539833189531,
      "grad_norm": 0.02566620707511902,
      "learning_rate": 0.0007840149554213402,
      "loss": 0.0025,
      "step": 37550
    },
    {
      "epoch": 10.813920046016682,
      "grad_norm": 0.0006963195628486574,
      "learning_rate": 0.0007837273511647972,
      "loss": 0.004,
      "step": 37600
    },
    {
      "epoch": 10.82830025884383,
      "grad_norm": 0.009771104902029037,
      "learning_rate": 0.0007834397469082542,
      "loss": 0.0037,
      "step": 37650
    },
    {
      "epoch": 10.842680471670981,
      "grad_norm": 0.001190162030979991,
      "learning_rate": 0.0007831521426517113,
      "loss": 0.0014,
      "step": 37700
    },
    {
      "epoch": 10.85706068449813,
      "grad_norm": 0.022170158103108406,
      "learning_rate": 0.0007828645383951683,
      "loss": 0.0009,
      "step": 37750
    },
    {
      "epoch": 10.87144089732528,
      "grad_norm": 0.00015027521294541657,
      "learning_rate": 0.0007825769341386253,
      "loss": 0.0029,
      "step": 37800
    },
    {
      "epoch": 10.885821110152431,
      "grad_norm": 4.481278301682323e-05,
      "learning_rate": 0.0007822893298820822,
      "loss": 0.0037,
      "step": 37850
    },
    {
      "epoch": 10.90020132297958,
      "grad_norm": 0.00010278647823724896,
      "learning_rate": 0.0007820017256255393,
      "loss": 0.0016,
      "step": 37900
    },
    {
      "epoch": 10.91458153580673,
      "grad_norm": 0.00012669767602346838,
      "learning_rate": 0.0007817141213689962,
      "loss": 0.0049,
      "step": 37950
    },
    {
      "epoch": 10.92896174863388,
      "grad_norm": 0.0005763476365245879,
      "learning_rate": 0.0007814265171124532,
      "loss": 0.0043,
      "step": 38000
    },
    {
      "epoch": 10.94334196146103,
      "grad_norm": 0.00031125344685278833,
      "learning_rate": 0.0007811389128559103,
      "loss": 0.0053,
      "step": 38050
    },
    {
      "epoch": 10.957722174288179,
      "grad_norm": 0.00025115121388807893,
      "learning_rate": 0.0007808513085993672,
      "loss": 0.0054,
      "step": 38100
    },
    {
      "epoch": 10.97210238711533,
      "grad_norm": 0.0016236478695645928,
      "learning_rate": 0.0007805637043428243,
      "loss": 0.002,
      "step": 38150
    },
    {
      "epoch": 10.986482599942478,
      "grad_norm": 3.915642082574777e-05,
      "learning_rate": 0.0007802761000862813,
      "loss": 0.0038,
      "step": 38200
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.01447600219398737,
      "eval_runtime": 11.7762,
      "eval_samples_per_second": 4052.165,
      "eval_steps_per_second": 63.348,
      "step": 38247
    }
  ],
  "logging_steps": 50,
  "max_steps": 173850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 10
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6055083021926400.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
