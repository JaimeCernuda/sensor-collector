{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChronoTick 2: TimesFM 2.5 Fine-Tuning\n",
    "\n",
    "Fine-tune Google TimesFM 2.5 (200M) on univariate clock drift data.\n",
    "FT is strictly univariate; sensor covariates are only used at inference\n",
    "via XReg (ridge regression wrapper).\n",
    "\n",
    "## Experiments\n",
    "- E1: Univariate FT\n",
    "- E2: FT + XReg at inference (compare to FT-only)\n",
    "- E3: Per-machine vs combined training\n",
    "\n",
    "## Training Mode\n",
    "Set `TRAINING_MODE` to \"combined\" or \"per_machine\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# === Environment Setup ===\nimport os, subprocess, sys\n\nIN_COLAB = \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\")\n\nif IN_COLAB:\n    REPO_DIR = \"/content/sensor-collector\"\n    REPO_URL = \"https://github.com/JaimeCernuda/sensor-collector.git\"\n    GITHUB_TOKEN = None\n    try:\n        from google.colab import userdata\n        GITHUB_TOKEN = userdata.get(\"GITHUB_TOKEN\")\n    except Exception:\n        print(\"WARNING: GITHUB_TOKEN not available\")\n    auth_url = (\n        f\"https://{GITHUB_TOKEN}@github.com/JaimeCernuda/sensor-collector.git\"\n        if GITHUB_TOKEN\n        else REPO_URL\n    )\n    if os.path.exists(REPO_DIR):\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"remote\", \"set-url\", \"origin\", auth_url], check=True)\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"fetch\", \"-q\", \"origin\"], check=True)\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"reset\", \"--hard\", \"origin/main\"], check=True)\n    else:\n        subprocess.run([\"git\", \"clone\", \"-q\", auth_url, REPO_DIR], check=True)\n    subprocess.run([\"git\", \"-C\", REPO_DIR, \"config\", \"user.name\", \"Colab Runner\"], check=True)\n    subprocess.run([\"git\", \"-C\", REPO_DIR, \"config\", \"user.email\", \"colab@chronotick.dev\"], check=True)\n    subprocess.run([\"pip\", \"install\", \"-q\", \"-e\", f\"{REPO_DIR}/tick2/\"], check=True)\n    tick2_src = f\"{REPO_DIR}/tick2/src\"\n    if tick2_src not in sys.path:\n        sys.path.insert(0, tick2_src)\n\n    # Always mount Drive â€” needed for checkpoint persistence (models too large for git)\n    from google.colab import drive\n    drive.mount(\"/content/drive\")\n\n    # Data: prefer repo copy, fall back to Drive\n    DATA_DIR = f\"{REPO_DIR}/sensors/data\"\n    if not os.path.isdir(f\"{DATA_DIR}/24h_snapshot\"):\n        DATA_DIR = \"/content/drive/MyDrive/chronotick2/data\"\n\n    RESULTS_DIR = f\"{REPO_DIR}/tick2/notebooks/output/03\"\nelse:\n    GITHUB_TOKEN = None\n    DATA_DIR = None\n    RESULTS_DIR = os.path.join(\n        os.path.dirname(\"__file__\") if \"__file__\" in dir() else \".\", \"output\", \"03\"\n    )\n\nDEVICE_DIR_MAP = {\"cuda\": \"gpu\", \"cpu\": \"cpu\"}\n\n\ndef checkpoint_push(label):\n    \"\"\"Git add, commit, and push notebook 03d results.\"\"\"\n    if not IN_COLAB:\n        return\n    try:\n        subprocess.run(\n            [\"git\", \"-C\", REPO_DIR, \"add\", \"tick2/notebooks/output/03/\"],\n            check=True, capture_output=True,\n        )\n        status = subprocess.run(\n            [\"git\", \"-C\", REPO_DIR, \"status\", \"--porcelain\", \"tick2/notebooks/output/03/\"],\n            capture_output=True, text=True,\n        )\n        if not status.stdout.strip():\n            return\n        subprocess.run(\n            [\"git\", \"-C\", REPO_DIR, \"commit\", \"-m\",\n             f\"results: notebook 03d timesfm {label} ({device_label})\"],\n            check=True, capture_output=True,\n        )\n        if GITHUB_TOKEN:\n            subprocess.run(\n                [\"git\", \"-C\", REPO_DIR, \"push\"],\n                check=True, capture_output=True, timeout=60,\n            )\n            print(f\"  [CHECKPOINT] Pushed {label}\")\n    except Exception as e:\n        print(f\"  [CHECKPOINT WARNING] {e}\")\n\n\nprint(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Install TimesFM Dependencies ===\n",
    "if IN_COLAB:\n",
    "    subprocess.run(\n",
    "        \"git clone -q --depth 1 https://github.com/google-research/timesfm /content/timesfm\".split(),\n",
    "        capture_output=True,\n",
    "    )\n",
    "    subprocess.run(\n",
    "        \"touch /content/timesfm/src/timesfm/timesfm_2p5/__init__.py\".split(),\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\"pip\", \"install\", \"-q\", \"/content/timesfm[torch]\"],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "import timesfm\n",
    "assert hasattr(timesfm, \"TimesFM_2p5_200M_torch\"), \"TimesFM 2.5 not available\"\n",
    "print(\"timesfm ready\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Imports, Config & Training Mode ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from tick2.data.preprocessing import TARGET_COL, load_all\n",
    "from tick2.finetuning.base import FineTuneConfig\n",
    "from tick2.finetuning.data_prep import prepare_datasets\n",
    "from tick2.finetuning.timesfm_ft import finetune_timesfm, load_finetuned_timesfm\n",
    "from tick2.finetuning.evaluate import (\n",
    "    evaluate_finetuned,\n",
    "    load_zero_shot_baselines,\n",
    "    compare_ft_vs_zero_shot,\n",
    ")\n",
    "from tick2.utils.gpu import clear_gpu_memory\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# --- User Configuration ---\n",
    "TRAINING_MODE = \"combined\"  # \"combined\" or \"per_machine\"\n",
    "DEVICE_OVERRIDE = None       # None = auto-detect, \"cuda\", or \"cpu\"\n",
    "FORCE_RETRAIN = False        # Set True to retrain even if cached results exist\n",
    "\n",
    "# --- Derived settings ---\n",
    "device = DEVICE_OVERRIDE or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_label = DEVICE_DIR_MAP.get(device, device)\n",
    "config = FineTuneConfig(\n",
    "    context_length=1024,\n",
    "    prediction_length=96,\n",
    "    max_covariates=30,\n",
    "    seed=42,\n",
    ")\n",
    "print(f\"Device: {device}, Mode: {TRAINING_MODE}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Load and Prepare Data ===\n",
    "data_dir = Path(DATA_DIR) if DATA_DIR else None\n",
    "prepared = prepare_datasets(config, data_dir=data_dir)\n",
    "for name, p in prepared.items():\n",
    "    print(\n",
    "        f\"  {name:16s}: train={len(p.split.train)}, \"\n",
    "        f\"val={len(p.split.val)}, test={len(p.split.test)}\"\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# === Fine-Tune TimesFM 2.5 ===\nfrom tick2.utils.colab import save_checkpoint_to_drive, load_checkpoint_from_drive, setup_training_log\n\noutput_base = Path(RESULTS_DIR)\nft_output_dir = output_base / \"timesfm_ft\" / TRAINING_MODE\ndevice_results_dir = output_base / device_label\n\n# Persist training logs to disk (epoch losses, early stopping, errors)\nlog_path = setup_training_log(ft_output_dir)\nprint(f\"Training log: {log_path}\")\n\ncached_path = device_results_dir / f\"timesfm-2.5-ft_{TRAINING_MODE}.csv\"\n\n# Check for existing Drive checkpoint (resume after disconnect)\ndrive_model_name = f\"timesfm_ft/{TRAINING_MODE}/best_model.pt\"\nckpt_local = ft_output_dir / \"combined\" / \"best_model.pt\"\nif not cached_path.exists() and not FORCE_RETRAIN and not ckpt_local.exists():\n    resumed = load_checkpoint_from_drive(\n        model_name=drive_model_name,\n        local_path=str(ckpt_local),\n    )\n    if resumed:\n        print(f\"[RESUMED] Loaded checkpoint from Drive: {resumed}\")\n\nif cached_path.exists() and not FORCE_RETRAIN:\n    print(f\"[CACHED] {cached_path}\")\nelif ckpt_local.exists() and not FORCE_RETRAIN:\n    print(f\"[CACHED] Checkpoint exists at {ckpt_local}, skipping training\")\nelse:\n    clear_gpu_memory()\n    ft_results = finetune_timesfm(\n        prepared=prepared,\n        config=config,\n        output_dir=str(ft_output_dir),\n        training_mode=TRAINING_MODE,\n        learning_rate=1e-4,\n        num_epochs=50,\n        batch_size=64,\n        context_length=128,\n        horizon_length=32,\n    )\n    for r in ft_results:\n        print(f\"  {r.machine}: {r.training_time_s:.1f}s\")\n\n    # Save checkpoint to Drive for persistence (~800MB for TimesFM)\n    save_checkpoint_to_drive(\n        local_path=ft_output_dir / \"combined\",\n        model_name=f\"timesfm_ft/{TRAINING_MODE}\",\n    )\n\n    checkpoint_push(\"finetuning\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# === Evaluate Fine-Tuned Model ===\nfrom tick2.models.timesfm import TimesFMWrapper\n\nif cached_path.exists() and not FORCE_RETRAIN:\n    ft_eval_df = pd.read_csv(cached_path)\n    print(f\"Loaded cached evaluation: {len(ft_eval_df)} rows\")\nelse:\n    ckpt_path = ft_output_dir / \"combined\" if TRAINING_MODE == \"combined\" else ft_output_dir\n    ft_model = load_finetuned_timesfm(str(ckpt_path))\n\n    ft_wrapper = TimesFMWrapper(model_name=\"timesfm-2.5-ft\")\n    ft_wrapper._model = ft_model\n    ft_wrapper._device = device\n\n    ft_eval_df = evaluate_finetuned(\n        model=ft_wrapper,\n        prepared=prepared,\n        config=config,\n        training_mode=f\"ft_{TRAINING_MODE}\",\n    )\n    device_results_dir.mkdir(parents=True, exist_ok=True)\n    ft_eval_df.to_csv(cached_path, index=False)\n    checkpoint_push(\"evaluation\")\n\nprint(f\"Mean MAE: {ft_eval_df['mae'].mean():.4f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Load Zero-Shot Baselines ===\n",
    "zs_dir = output_base.parent / \"output\" / \"02\"\n",
    "zs_results = load_zero_shot_baselines(zs_dir, model_name=\"timesfm-2.5\")\n",
    "print(f\"Zero-shot: {len(zs_results)} rows\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Compare Fine-Tuned vs Zero-Shot ===\n",
    "comparison_df = compare_ft_vs_zero_shot(ft_eval_df, zs_results)\n",
    "\n",
    "# Compute per-machine improvement\n",
    "if not comparison_df.empty and len(comparison_df[\"training_mode\"].unique()) > 1:\n",
    "    pivot = comparison_df.pivot_table(\n",
    "        values=\"mae\",\n",
    "        index=[\"machine\", \"context_length\", \"horizon\"],\n",
    "        columns=\"training_mode\",\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    zs_col = \"zero_shot\"\n",
    "    ft_col = f\"ft_{TRAINING_MODE}\"\n",
    "    if zs_col in pivot.columns and ft_col in pivot.columns:\n",
    "        pivot[\"improvement_pct\"] = (\n",
    "            (pivot[zs_col] - pivot[ft_col]) / pivot[zs_col] * 100\n",
    "        )\n",
    "        print(\"\\n=== Per-Config Improvement ===\")\n",
    "        print(pivot.to_string())\n",
    "        print(f\"\\nMean improvement: {pivot['improvement_pct'].mean():.1f}%\")\n",
    "else:\n",
    "    print(\"No zero-shot baselines found for comparison.\")\n",
    "    print(\"Run notebook 02 first to generate TimesFM 2.5 zero-shot results.\")\n",
    "\n",
    "display(comparison_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Visualizations ===\n",
    "fig_dir = output_base / \"figures\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1. MAE Comparison: Fine-Tuned vs Zero-Shot ---\n",
    "if not comparison_df.empty and len(comparison_df[\"training_mode\"].unique()) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    uni_cmp = comparison_df[~comparison_df[\"with_covariates\"]]\n",
    "    sns.barplot(\n",
    "        data=uni_cmp, x=\"machine\", y=\"mae\",\n",
    "        hue=\"training_mode\", ax=ax,\n",
    "    )\n",
    "    ax.set_ylabel(\"MAE (ppm)\")\n",
    "    ax.set_title(\"TimesFM 2.5: Fine-Tuned vs Zero-Shot MAE\")\n",
    "    ax.legend(title=\"Mode\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(fig_dir / \"timesfm_ft_vs_zs_mae.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 2. Training Loss Curve ---\n",
    "if \"ft_results\" in dir() and ft_results:\n",
    "    fig, axes = plt.subplots(1, len(ft_results), figsize=(6 * len(ft_results), 4), squeeze=False)\n",
    "    for i, r in enumerate(ft_results):\n",
    "        ax = axes[0][i]\n",
    "        if r.train_loss:\n",
    "            ax.plot(r.train_loss, label=\"Train\", alpha=0.8)\n",
    "        if r.val_loss:\n",
    "            ax.plot(r.val_loss, label=\"Val\", alpha=0.8)\n",
    "            ax.axvline(r.best_epoch, color=\"red\", ls=\"--\", alpha=0.5, label=f\"Best epoch ({r.best_epoch})\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_title(f\"Training Loss: {r.machine}\")\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(fig_dir / \"timesfm_ft_loss_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 3. MAE by Machine and Horizon (FT only) ---\n",
    "if not ft_eval_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    uni_ft = ft_eval_df[~ft_eval_df[\"with_covariates\"]]\n",
    "    if not uni_ft.empty:\n",
    "        sns.barplot(\n",
    "            data=uni_ft, x=\"machine\", y=\"mae\",\n",
    "            hue=\"horizon\", ax=ax,\n",
    "        )\n",
    "        ax.set_ylabel(\"MAE (ppm)\")\n",
    "        ax.set_title(f\"Fine-Tuned TimesFM 2.5 MAE by Horizon ({TRAINING_MODE})\")\n",
    "        ax.legend(title=\"Horizon\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(fig_dir / \"timesfm_ft_mae_by_horizon.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Figures saved to: {fig_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Export Results ===\n",
    "export_dir = output_base / device_label\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CSV: fine-tuned evaluation\n",
    "ft_csv_path = export_dir / f\"timesfm-2.5-ft_{TRAINING_MODE}.csv\"\n",
    "ft_eval_df.to_csv(ft_csv_path, index=False)\n",
    "print(f\"FT results CSV: {ft_csv_path}\")\n",
    "\n",
    "# CSV: combined comparison (if baselines available)\n",
    "if not comparison_df.empty:\n",
    "    cmp_csv_path = export_dir / f\"timesfm_ft_vs_zs_{TRAINING_MODE}.csv\"\n",
    "    comparison_df.to_csv(cmp_csv_path, index=False)\n",
    "    print(f\"Comparison CSV: {cmp_csv_path}\")\n",
    "\n",
    "# LaTeX summary table\n",
    "if not comparison_df.empty and len(comparison_df[\"training_mode\"].unique()) > 1:\n",
    "    latex_summary = comparison_df.groupby([\"machine\", \"training_mode\"]).agg(\n",
    "        mae_mean=(\"mae\", \"mean\"),\n",
    "        rmse_mean=(\"rmse\", \"mean\"),\n",
    "        inference_ms=(\"inference_ms\", \"mean\"),\n",
    "    ).round(4)\n",
    "    latex_path = export_dir / f\"timesfm_ft_summary_{TRAINING_MODE}.tex\"\n",
    "    latex_summary.to_latex(str(latex_path))\n",
    "    print(f\"LaTeX table:    {latex_path}\")\n",
    "    print(\"\\n\" + latex_summary.to_string())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Final Push ===\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    os.chdir(REPO_DIR)\n",
    "    subprocess.run([\"git\", \"add\", \"tick2/notebooks/output/03/\"], check=True)\n",
    "    status = subprocess.run(\n",
    "        [\"git\", \"status\", \"--porcelain\", \"tick2/notebooks/output/03/\"],\n",
    "        capture_output=True, text=True,\n",
    "    )\n",
    "    if status.stdout.strip():\n",
    "        subprocess.run(\n",
    "            [\"git\", \"commit\", \"-m\",\n",
    "             f\"results: notebook 03d timesfm final outputs ({device_label})\"],\n",
    "            check=True,\n",
    "        )\n",
    "        if GITHUB_TOKEN:\n",
    "            subprocess.run([\"git\", \"push\"], check=True)\n",
    "            print(\"Pushed final outputs to GitHub.\")\n",
    "        else:\n",
    "            print(\"Committed locally but GITHUB_TOKEN not set.\")\n",
    "    else:\n",
    "        print(\"No new outputs to commit (checkpoints already pushed).\")\n",
    "else:\n",
    "    print(f\"Local run. Outputs saved to: {output_base}\")\n",
    "    print(\"Run 'git add tick2/notebooks/output/03/ && git commit && git push' to share.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}