{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": "# ChronoTick 2: Moirai 1.1 Fine-Tuning\n\nFine-tune Salesforce Moirai 1.1 Small (14M) using wide_multivariate mode.\nAll channels (target + sensors) are treated as joint targets during training;\nat inference, only the target channel prediction is extracted.\n\n## Experiments\n- **E1_univariate**: Drift-only FT, no sensor covariates (`max_covariates=0`)\n- **E2_cov10**: Top-10 SHAP features (`max_covariates=10`)\n- **E3_cov20**: Top-20 SHAP features (`max_covariates=20`)\n\nAll share: `max_epochs=20`, `learning_rate=1e-4`, `batch_size=32`,\n`patch_size=32`, `early_stopping_patience=5`.\n\n## Training Mode\nSet `TRAINING_MODE` to \"combined\" or \"per_machine\"."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    REPO_DIR = \"/content/sensor-collector\"\n",
    "    REPO_URL = \"https://github.com/JaimeCernuda/sensor-collector.git\"\n",
    "    GITHUB_TOKEN = None\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        GITHUB_TOKEN = userdata.get(\"GITHUB_TOKEN\")\n",
    "    except Exception:\n",
    "        print(\"WARNING: GITHUB_TOKEN not available\")\n",
    "    auth_url = (\n",
    "        f\"https://{GITHUB_TOKEN}@github.com/JaimeCernuda/sensor-collector.git\"\n",
    "        if GITHUB_TOKEN\n",
    "        else REPO_URL\n",
    "    )\n",
    "    if os.path.exists(REPO_DIR):\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", REPO_DIR, \"remote\", \"set-url\", \"origin\", auth_url], check=True\n",
    "        )\n",
    "        subprocess.run([\"git\", \"-C\", REPO_DIR, \"fetch\", \"-q\", \"origin\"], check=True)\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", REPO_DIR, \"reset\", \"--hard\", \"origin/main\"], check=True\n",
    "        )\n",
    "    else:\n",
    "        subprocess.run([\"git\", \"clone\", \"-q\", auth_url, REPO_DIR], check=True)\n",
    "    subprocess.run(\n",
    "        [\"git\", \"-C\", REPO_DIR, \"config\", \"user.name\", \"Colab Runner\"], check=True\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\"git\", \"-C\", REPO_DIR, \"config\", \"user.email\", \"colab@chronotick.dev\"],\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"-e\", f\"{REPO_DIR}/tick2/\"], check=True)\n",
    "    tick2_src = f\"{REPO_DIR}/tick2/src\"\n",
    "    if tick2_src not in sys.path:\n",
    "        sys.path.insert(0, tick2_src)\n",
    "\n",
    "    # Always mount Drive â€” needed for checkpoint persistence (models too large for git)\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # Data: prefer repo copy, fall back to Drive\n",
    "    DATA_DIR = f\"{REPO_DIR}/sensors/data\"\n",
    "    if not os.path.isdir(f\"{DATA_DIR}/24h_snapshot\"):\n",
    "        DATA_DIR = \"/content/drive/MyDrive/chronotick2/data\"\n",
    "\n",
    "    RESULTS_DIR = f\"{REPO_DIR}/tick2/notebooks/output/03\"\n",
    "else:\n",
    "    GITHUB_TOKEN = None\n",
    "    DATA_DIR = None\n",
    "    RESULTS_DIR = os.path.join(\n",
    "        os.path.dirname(\"__file__\") if \"__file__\" in dir() else \".\", \"output\", \"03\"\n",
    "    )\n",
    "\n",
    "DEVICE_DIR_MAP = {\"cuda\": \"gpu\", \"cpu\": \"cpu\"}\n",
    "\n",
    "\n",
    "def checkpoint_push(label):\n",
    "    if not IN_COLAB:\n",
    "        return\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", REPO_DIR, \"add\", \"tick2/notebooks/output/03/\"],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "        )\n",
    "        status = subprocess.run(\n",
    "            [\n",
    "                \"git\",\n",
    "                \"-C\",\n",
    "                REPO_DIR,\n",
    "                \"status\",\n",
    "                \"--porcelain\",\n",
    "                \"tick2/notebooks/output/03/\",\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        if not status.stdout.strip():\n",
    "            return\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"git\",\n",
    "                \"-C\",\n",
    "                REPO_DIR,\n",
    "                \"commit\",\n",
    "                \"-m\",\n",
    "                f\"results: notebook 03c moirai {label} ({device_label})\",\n",
    "            ],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "        )\n",
    "        if GITHUB_TOKEN:\n",
    "            subprocess.run(\n",
    "                [\"git\", \"-C\", REPO_DIR, \"fetch\", \"-q\", \"origin\"],\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run(\n",
    "                [\"git\", \"-C\", REPO_DIR, \"rebase\", \"origin/main\"],\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run(\n",
    "                [\"git\", \"-C\", REPO_DIR, \"push\"],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                timeout=60,\n",
    "            )\n",
    "            print(f\"  [CHECKPOINT] Pushed {label}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [CHECKPOINT WARNING] {e}\")\n",
    "\n",
    "\n",
    "print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Install Moirai Dependencies ===\n",
    "if IN_COLAB:\n",
    "    # uni2ts pins torch<2.5; install with --no-deps to keep CUDA torch\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"uni2ts\", \"--no-deps\"], check=True)\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"-q\",\n",
    "            \"einops>=0.7\",\n",
    "            \"gluonts>=0.14\",\n",
    "            \"jaxtyping\",\n",
    "            \"hydra-core\",\n",
    "            \"python-dotenv\",\n",
    "            \"lightning\",\n",
    "            \"safetensors\",\n",
    "            \"huggingface_hub\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "print(\"uni2ts ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports, Config & Training Mode ===\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from tick2.finetuning.base import FineTuneConfig\n",
    "from tick2.finetuning.data_prep import prepare_datasets\n",
    "from tick2.finetuning.evaluate import (\n",
    "    compare_ft_vs_zero_shot,\n",
    "    evaluate_finetuned,\n",
    "    load_zero_shot_baselines,\n",
    ")\n",
    "from tick2.finetuning.moirai_ft import finetune_moirai, load_finetuned_moirai\n",
    "from tick2.utils.gpu import clear_gpu_memory\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# --- User-configurable knobs ---\n",
    "TRAINING_MODE = \"combined\"  # \"combined\" or \"per_machine\"\n",
    "DEVICE_OVERRIDE = None  # None = auto-detect, \"cuda\", or \"cpu\"\n",
    "FORCE_RETRAIN = False  # Set True to retrain even if cached CSV exists\n",
    "\n",
    "device = DEVICE_OVERRIDE or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_label = DEVICE_DIR_MAP.get(device, device)\n",
    "config = FineTuneConfig(\n",
    "    context_length=1000, prediction_length=96, max_covariates=20, seed=42\n",
    ")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    vram = getattr(props, \"total_memory\", getattr(props, \"total_mem\", 0))\n",
    "    print(f\"GPU:  {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {vram / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "print(f\"Device: {device}, Mode: {TRAINING_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load & Prepare Data ===\n",
    "data_dir = Path(DATA_DIR) if DATA_DIR else None\n",
    "prepared = prepare_datasets(config, data_dir=data_dir)\n",
    "\n",
    "for name, p in prepared.items():\n",
    "    print(\n",
    "        f\"  {name:16s}: train={len(p.split.train)}, val={len(p.split.val)}, test={len(p.split.test)}, features={len(p.feature_cols)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fine-Tune Moirai 1.1 (E1, E2, E3) ===\n",
    "from tick2.finetuning.base import FineTuneResult\n",
    "from tick2.utils.colab import (\n",
    "    load_checkpoint_from_drive,\n",
    "    save_checkpoint_to_drive,\n",
    "    setup_training_log,\n",
    ")\n",
    "\n",
    "output_base = Path(RESULTS_DIR)\n",
    "ft_output_dir = output_base / \"moirai_ft\" / TRAINING_MODE\n",
    "device_results_dir = output_base / device_label\n",
    "device_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_path = setup_training_log(ft_output_dir)\n",
    "print(f\"Training log: {log_path}\")\n",
    "\n",
    "# --- Experiment definitions ---\n",
    "# E1: Univariate FT (drift only, no sensor covariates)\n",
    "# E2: Top-10 SHAP features\n",
    "# E3: Top-20 SHAP features (original notebook default)\n",
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"E1_univariate\",\n",
    "        \"max_covariates\": 0,\n",
    "        \"max_epochs\": 20,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": 32,\n",
    "        \"patch_size\": 32,\n",
    "        \"early_stopping_patience\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"E2_cov10\",\n",
    "        \"max_covariates\": 10,\n",
    "        \"max_epochs\": 20,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": 32,\n",
    "        \"patch_size\": 32,\n",
    "        \"early_stopping_patience\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"E3_cov20\",\n",
    "        \"max_covariates\": 20,\n",
    "        \"max_epochs\": 20,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": 32,\n",
    "        \"patch_size\": 32,\n",
    "        \"early_stopping_patience\": 5,\n",
    "    },\n",
    "]\n",
    "\n",
    "all_ft_results = []\n",
    "experiment_labels = {}\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    exp_name = exp[\"name\"]\n",
    "    n_cov = exp[\"max_covariates\"]\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\n",
    "        f\"  {exp_name}  (max_covariates={n_cov},\"\n",
    "        f\" lr={exp['learning_rate']},\"\n",
    "        f\" bs={exp['batch_size']})\"\n",
    "    )\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    exp_dir = ft_output_dir / exp_name\n",
    "\n",
    "    # Per-experiment FineTuneConfig with the correct max_covariates\n",
    "    ft_config = FineTuneConfig(\n",
    "        context_length=config.context_length,\n",
    "        prediction_length=config.prediction_length,\n",
    "        max_covariates=n_cov,\n",
    "        seed=config.seed,\n",
    "    )\n",
    "\n",
    "    # Check for cached checkpoint (local, then Drive)\n",
    "    ckpt_local = exp_dir / \"combined\" / \"best\"\n",
    "    cached_eval = device_results_dir / f\"moirai-1.1-ft-{exp_name}_{TRAINING_MODE}.csv\"\n",
    "\n",
    "    if not ckpt_local.exists() and not FORCE_RETRAIN:\n",
    "        drive_name = f\"moirai_ft/{TRAINING_MODE}/{exp_name}\"\n",
    "        resumed = load_checkpoint_from_drive(\n",
    "            model_name=drive_name,\n",
    "            local_path=str(ckpt_local),\n",
    "        )\n",
    "        if resumed:\n",
    "            print(f\"  [RESUMED] From Drive: {resumed}\")\n",
    "\n",
    "    if cached_eval.exists() and not FORCE_RETRAIN:\n",
    "        print(f\"  [CACHED] Eval exists: {cached_eval}\")\n",
    "        stub = FineTuneResult(\n",
    "            model_name=f\"moirai-1.1-ft-{exp_name}\",\n",
    "            machine=TRAINING_MODE,\n",
    "            checkpoint_path=str(ckpt_local),\n",
    "            config=exp,\n",
    "        )\n",
    "        all_ft_results.append(stub)\n",
    "        experiment_labels[exp_name] = [stub]\n",
    "        continue\n",
    "\n",
    "    if ckpt_local.exists() and not FORCE_RETRAIN:\n",
    "        print(f\"  [CACHED] Checkpoint: {ckpt_local}\")\n",
    "        stub = FineTuneResult(\n",
    "            model_name=f\"moirai-1.1-ft-{exp_name}\",\n",
    "            machine=TRAINING_MODE,\n",
    "            checkpoint_path=str(ckpt_local),\n",
    "            config=exp,\n",
    "        )\n",
    "        all_ft_results.append(stub)\n",
    "        experiment_labels[exp_name] = [stub]\n",
    "        continue\n",
    "\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    try:\n",
    "        ft_results = finetune_moirai(\n",
    "            prepared=prepared,\n",
    "            config=ft_config,\n",
    "            output_dir=str(exp_dir),\n",
    "            training_mode=TRAINING_MODE,\n",
    "            patch_size=exp[\"patch_size\"],\n",
    "            max_epochs=exp[\"max_epochs\"],\n",
    "            learning_rate=exp[\"learning_rate\"],\n",
    "            batch_size=exp[\"batch_size\"],\n",
    "            early_stopping_patience=exp[\"early_stopping_patience\"],\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        for r in ft_results:\n",
    "            r.model_name = f\"moirai-1.1-ft-{exp_name}\"\n",
    "            print(f\"  {r.machine}: {r.training_time_s:.1f}s, best_epoch={r.best_epoch}\")\n",
    "\n",
    "        all_ft_results.extend(ft_results)\n",
    "        experiment_labels[exp_name] = ft_results\n",
    "\n",
    "        save_checkpoint_to_drive(\n",
    "            local_path=exp_dir / \"combined\",\n",
    "            model_name=(f\"moirai_ft/{TRAINING_MODE}/{exp_name}\"),\n",
    "        )\n",
    "        checkpoint_push(exp_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] {exp_name}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        clear_gpu_memory()\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"  Completed: {list(experiment_labels.keys())}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate Fine-Tuned Models ===\n",
    "from tick2.finetuning.data_prep import combine_training_data\n",
    "from tick2.models.moirai import MoiraiWrapper\n",
    "\n",
    "# Compute shared feature intersection (same as training used)\n",
    "_, shared_features_all = combine_training_data(prepared)\n",
    "print(f\"Shared eval features available: {len(shared_features_all)}\")\n",
    "\n",
    "eval_dfs = []\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    exp_name = exp[\"name\"]\n",
    "    n_cov = exp[\"max_covariates\"]\n",
    "    print(f\"\\n--- Evaluating {exp_name} (max_covariates={n_cov}) ---\")\n",
    "\n",
    "    cached_eval = device_results_dir / f\"moirai-1.1-ft-{exp_name}_{TRAINING_MODE}.csv\"\n",
    "    if cached_eval.exists() and not FORCE_RETRAIN:\n",
    "        print(f\"  [CACHED] {cached_eval}\")\n",
    "        eval_dfs.append(pd.read_csv(cached_eval))\n",
    "        continue\n",
    "\n",
    "    # Find checkpoint\n",
    "    exp_dir = ft_output_dir / exp_name\n",
    "    ckpt_path = exp_dir / \"combined\" / \"best\"\n",
    "    if not ckpt_path.exists():\n",
    "        ckpt_path = exp_dir / \"combined\"\n",
    "    if not ckpt_path.exists():\n",
    "        print(f\"  [SKIP] No checkpoint for {exp_name}\")\n",
    "        continue\n",
    "\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    try:\n",
    "        # Determine eval features for this experiment\n",
    "        eval_features = shared_features_all[:n_cov] if n_cov > 0 else None\n",
    "\n",
    "        ft_model = load_finetuned_moirai(\n",
    "            str(ckpt_path),\n",
    "            context_length=config.context_length,\n",
    "            prediction_length=config.prediction_length,\n",
    "            n_covariates=n_cov,\n",
    "        )\n",
    "\n",
    "        ft_wrapper = MoiraiWrapper(\n",
    "            model_name=f\"moirai-1.1-ft-{exp_name}\",\n",
    "            max_covariates=n_cov,\n",
    "        )\n",
    "        ft_wrapper._model = ft_model.module if hasattr(ft_model, \"module\") else ft_model\n",
    "        ft_wrapper._device = device\n",
    "\n",
    "        results_for_exp = experiment_labels.get(exp_name, [])\n",
    "        ft_epochs = results_for_exp[0].best_epoch if results_for_exp else None\n",
    "        ft_time = results_for_exp[0].training_time_s if results_for_exp else None\n",
    "        ft_machines = results_for_exp[0].machine if results_for_exp else \"\"\n",
    "\n",
    "        eval_df = evaluate_finetuned(\n",
    "            model=ft_wrapper,\n",
    "            prepared=prepared,\n",
    "            config=config,\n",
    "            training_mode=f\"ft_{TRAINING_MODE}\",\n",
    "            ft_epochs=ft_epochs,\n",
    "            ft_time_s=ft_time,\n",
    "            ft_train_machines=ft_machines,\n",
    "            shared_feature_cols=eval_features,\n",
    "        )\n",
    "\n",
    "        if not eval_df.empty:\n",
    "            eval_df[\"experiment\"] = exp_name\n",
    "            eval_df.to_csv(cached_eval, index=False)\n",
    "            eval_dfs.append(eval_df)\n",
    "            print(f\"  MAE: {eval_df['mae'].mean():.4f}\")\n",
    "            print(f\"  Saved: {cached_eval}\")\n",
    "        else:\n",
    "            print(f\"  [WARN] No eval results for {exp_name}\")\n",
    "\n",
    "        checkpoint_push(f\"eval-{exp_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] Eval {exp_name}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        clear_gpu_memory()\n",
    "\n",
    "# Combine all evaluation results\n",
    "if eval_dfs:\n",
    "    ft_eval_df = pd.concat(eval_dfs, ignore_index=True)\n",
    "    print(f\"\\nTotal FT eval rows: {len(ft_eval_df)}\")\n",
    "    print(f\"Mean MAE:  {ft_eval_df['mae'].mean():.4f}\")\n",
    "    print(f\"Mean RMSE: {ft_eval_df['rmse'].mean():.4f}\")\n",
    "    if ft_eval_df[\"coverage\"].notna().any():\n",
    "        print(f\"Mean Coverage: {ft_eval_df['coverage'].mean():.1%}\")\n",
    "    display(ft_eval_df)\n",
    "else:\n",
    "    ft_eval_df = pd.DataFrame()\n",
    "    print(\"No evaluation results collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Zero-Shot Baselines ===\n",
    "zs_dir = output_base.parent / \"output\" / \"02\"\n",
    "zs_results = load_zero_shot_baselines(zs_dir, model_name=\"moirai-1.1-small\")\n",
    "print(f\"Zero-shot baselines: {len(zs_results)} rows\")\n",
    "if not zs_results.empty:\n",
    "    print(f\"  Mean MAE (ZS): {zs_results['mae'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"  No zero-shot results found. Run notebook 02 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comparison: Fine-Tuned vs Zero-Shot ===\n",
    "if not ft_eval_df.empty and not zs_results.empty:\n",
    "    combined = compare_ft_vs_zero_shot(ft_eval_df, zs_results)\n",
    "\n",
    "    # --- Per-experiment improvement vs best ZS ---\n",
    "    best_zs = (\n",
    "        zs_results.groupby(\"machine\")[\"mae\"]\n",
    "        .agg([\"min\", \"idxmin\"])\n",
    "        .rename(columns={\"min\": \"best_zs_mae\"})\n",
    "    )\n",
    "    best_zs[\"best_zs_ctx\"] = zs_results.loc[best_zs[\"idxmin\"], \"context_length\"].values\n",
    "    best_zs = best_zs.drop(columns=[\"idxmin\"])\n",
    "\n",
    "    summary_rows = []\n",
    "    for machine in ft_eval_df[\"machine\"].unique():\n",
    "        if machine not in best_zs.index:\n",
    "            continue\n",
    "        bzs_mae = best_zs.loc[machine, \"best_zs_mae\"]\n",
    "        bzs_ctx = int(best_zs.loc[machine, \"best_zs_ctx\"])\n",
    "\n",
    "        for exp in EXPERIMENTS:\n",
    "            exp_name = exp[\"name\"]\n",
    "            ft_mask = ft_eval_df[\"model\"].str.contains(exp_name, na=False) & (\n",
    "                ft_eval_df[\"machine\"] == machine\n",
    "            )\n",
    "            if not ft_mask.any():\n",
    "                continue\n",
    "            ft_mae = ft_eval_df.loc[ft_mask, \"mae\"].mean()\n",
    "\n",
    "            if bzs_mae > 0:\n",
    "                imp = (bzs_mae - ft_mae) / bzs_mae * 100\n",
    "                summary_rows.append(\n",
    "                    {\n",
    "                        \"machine\": machine,\n",
    "                        \"experiment\": exp_name,\n",
    "                        \"ft_mae\": ft_mae,\n",
    "                        \"best_zs_ctx\": bzs_ctx,\n",
    "                        \"best_zs_mae\": bzs_mae,\n",
    "                        \"vs_best_zs_pct\": imp,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows)\n",
    "        print(\"=== FT vs Best Zero-Shot ===\")\n",
    "        display(summary_df.round(4))\n",
    "\n",
    "        print(\"\\n=== Per-Experiment Summary ===\")\n",
    "        for exp in EXPERIMENTS:\n",
    "            exp_name = exp[\"name\"]\n",
    "            ed = summary_df[summary_df[\"experiment\"] == exp_name]\n",
    "            if not ed.empty:\n",
    "                ft_m = ed[\"ft_mae\"].mean()\n",
    "                zs_m = ed[\"best_zs_mae\"].mean()\n",
    "                imp_m = ed[\"vs_best_zs_pct\"].mean()\n",
    "                print(\n",
    "                    f\"  {exp_name}: FT={ft_m:.4f},\"\n",
    "                    f\" ZS={zs_m:.4f},\"\n",
    "                    f\" improvement={imp_m:+.1f}%\"\n",
    "                )\n",
    "    else:\n",
    "        print(\"Could not compute improvement.\")\n",
    "\n",
    "    print(f\"\\nCombined results: {len(combined)} rows\")\n",
    "    display(combined)\n",
    "elif ft_eval_df.empty:\n",
    "    combined = pd.DataFrame()\n",
    "    print(\"No FT results to compare.\")\n",
    "else:\n",
    "    combined = ft_eval_df.copy()\n",
    "    print(\"No zero-shot baselines to compare against.\")\n",
    "    display(ft_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualizations ===\n",
    "results_dir = Path(RESULTS_DIR)\n",
    "fig_dir = results_dir / \"figures\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not ft_eval_df.empty:\n",
    "    # --- 1. MAE Comparison Bar Chart (multi-experiment) ---\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "    plot_rows = []\n",
    "\n",
    "    # Add ZS baseline\n",
    "    if not zs_results.empty:\n",
    "        for machine in zs_results[\"machine\"].unique():\n",
    "            m_zs = zs_results[zs_results[\"machine\"] == machine]\n",
    "            plot_rows.append(\n",
    "                {\n",
    "                    \"machine\": machine,\n",
    "                    \"variant\": \"Zero-Shot\",\n",
    "                    \"mae\": m_zs[\"mae\"].mean(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Add FT experiments\n",
    "    for exp in EXPERIMENTS:\n",
    "        exp_name = exp[\"name\"]\n",
    "        exp_data = ft_eval_df[ft_eval_df[\"model\"].str.contains(exp_name, na=False)]\n",
    "        for machine in exp_data[\"machine\"].unique():\n",
    "            m_ft = exp_data[exp_data[\"machine\"] == machine]\n",
    "            plot_rows.append(\n",
    "                {\n",
    "                    \"machine\": machine,\n",
    "                    \"variant\": exp_name,\n",
    "                    \"mae\": m_ft[\"mae\"].mean(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    if plot_rows:\n",
    "        plot_df = pd.DataFrame(plot_rows)\n",
    "        sns.barplot(\n",
    "            data=plot_df,\n",
    "            x=\"machine\",\n",
    "            y=\"mae\",\n",
    "            hue=\"variant\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_ylabel(\"MAE (ppm)\")\n",
    "        ax.set_title(\"Moirai 1.1: FT vs Zero-Shot MAE by Machine\")\n",
    "        ax.legend(\n",
    "            title=\"Variant\",\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\n",
    "            fig_dir / \"moirai_ft_vs_zs_mae.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- 2. Coverage Comparison (if available) ---\n",
    "    if ft_eval_df[\"coverage\"].notna().any():\n",
    "        cov_data = ft_eval_df[ft_eval_df[\"coverage\"].notna()]\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        sns.barplot(\n",
    "            data=cov_data,\n",
    "            x=\"machine\",\n",
    "            y=\"coverage\",\n",
    "            hue=\"model\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.axhline(\n",
    "            0.8,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.5,\n",
    "            label=\"80% target\",\n",
    "        )\n",
    "        ax.set_ylabel(\"Coverage\")\n",
    "        ax.set_title(\"Prediction Interval Coverage\")\n",
    "        ax.legend(\n",
    "            title=\"Model\",\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\n",
    "            fig_dir / \"moirai_ft_coverage.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Saved figures to: {fig_dir}\")\n",
    "else:\n",
    "    print(\"No results to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export Results ===\n",
    "from tick2.benchmark.reporting import results_to_latex, save_results\n",
    "\n",
    "if not ft_eval_df.empty:\n",
    "    # Save combined FT results\n",
    "    ft_csv = device_results_dir / f\"moirai-1.1-ft-all_{TRAINING_MODE}.csv\"\n",
    "    ft_eval_df.to_csv(ft_csv, index=False)\n",
    "    print(f\"FT results CSV: {ft_csv}\")\n",
    "\n",
    "if not combined.empty:\n",
    "    csv_path, latex_path = save_results(\n",
    "        combined,\n",
    "        results_dir,\n",
    "        prefix=f\"moirai_ft_{TRAINING_MODE}\",\n",
    "    )\n",
    "    print(f\"Comparison CSV:   {csv_path}\")\n",
    "    print(f\"Comparison LaTeX: {latex_path}\")\n",
    "    latex = results_to_latex(\n",
    "        combined,\n",
    "        caption=f\"Moirai 1.1 fine-tuning vs zero-shot ({TRAINING_MODE})\",\n",
    "        label=\"tab:moirai-ft\",\n",
    "    )\n",
    "    print(f\"\\n{latex}\")\n",
    "else:\n",
    "    print(\"No results to export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Push ===\n",
    "if IN_COLAB:\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"git\", \"add\", \"tick2/notebooks/output/03/\"],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "    status = subprocess.run(\n",
    "        [\"git\", \"status\", \"--porcelain\", \"tick2/notebooks/output/03/\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "    )\n",
    "    if status.stdout.strip():\n",
    "        msg = f\"results: notebook 03c moirai-ft figures and combined ({device_label})\"\n",
    "        subprocess.run(\n",
    "            [\"git\", \"commit\", \"-m\", msg],\n",
    "            check=True,\n",
    "        )\n",
    "        if GITHUB_TOKEN:\n",
    "            subprocess.run(\n",
    "                [\"git\", \"fetch\", \"-q\", \"origin\"],\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run(\n",
    "                [\"git\", \"rebase\", \"origin/main\"],\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run([\"git\", \"push\"], check=True)\n",
    "            print(\"Pushed final outputs to GitHub.\")\n",
    "        else:\n",
    "            print(\"Committed locally (no token for push).\")\n",
    "    else:\n",
    "        print(\"No new outputs to commit.\")\n",
    "else:\n",
    "    print(f\"Local run. Outputs saved to: {results_dir}\")\n",
    "    print(\n",
    "        \"Run 'git add tick2/notebooks/output/03/ && git commit && git push' to share.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}