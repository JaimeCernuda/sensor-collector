{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChronoTick 2: Moirai 1.1 Fine-Tuning\n",
    "\n",
    "Fine-tune Salesforce Moirai 1.1 Small (14M) using wide_multivariate mode.\n",
    "All channels (target + sensors) are treated as joint targets during training;\n",
    "at inference, only the target channel prediction is extracted.\n",
    "\n",
    "## Experiments\n",
    "- E1: Univariate FT (drift only)\n",
    "- E2: Multivariate FT (drift + top-20 SHAP features)\n",
    "- E3: Per-machine vs combined training\n",
    "\n",
    "## Training Mode\n",
    "Set `TRAINING_MODE` to \"combined\" or \"per_machine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === Environment Setup ===\nimport os, subprocess, sys\n\nIN_COLAB = \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\")\n\nif IN_COLAB:\n    REPO_DIR = \"/content/sensor-collector\"\n    REPO_URL = \"https://github.com/JaimeCernuda/sensor-collector.git\"\n    GITHUB_TOKEN = None\n    try:\n        from google.colab import userdata\n        GITHUB_TOKEN = userdata.get(\"GITHUB_TOKEN\")\n    except Exception:\n        print(\"WARNING: GITHUB_TOKEN not available\")\n    auth_url = f\"https://{GITHUB_TOKEN}@github.com/JaimeCernuda/sensor-collector.git\" if GITHUB_TOKEN else REPO_URL\n    if os.path.exists(REPO_DIR):\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"remote\", \"set-url\", \"origin\", auth_url], check=True)\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"fetch\", \"-q\", \"origin\"], check=True)\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"reset\", \"--hard\", \"origin/main\"], check=True)\n    else:\n        subprocess.run([\"git\", \"clone\", \"-q\", auth_url, REPO_DIR], check=True)\n    subprocess.run([\"git\", \"-C\", REPO_DIR, \"config\", \"user.name\", \"Colab Runner\"], check=True)\n    subprocess.run([\"git\", \"-C\", REPO_DIR, \"config\", \"user.email\", \"colab@chronotick.dev\"], check=True)\n    subprocess.run([\"pip\", \"install\", \"-q\", \"-e\", f\"{REPO_DIR}/tick2/\"], check=True)\n    tick2_src = f\"{REPO_DIR}/tick2/src\"\n    if tick2_src not in sys.path:\n        sys.path.insert(0, tick2_src)\n\n    # Always mount Drive â€” needed for checkpoint persistence (models too large for git)\n    from google.colab import drive\n    drive.mount(\"/content/drive\")\n\n    # Data: prefer repo copy, fall back to Drive\n    DATA_DIR = f\"{REPO_DIR}/sensors/data\"\n    if not os.path.isdir(f\"{DATA_DIR}/24h_snapshot\"):\n        DATA_DIR = \"/content/drive/MyDrive/chronotick2/data\"\n\n    RESULTS_DIR = f\"{REPO_DIR}/tick2/notebooks/output/03\"\nelse:\n    GITHUB_TOKEN = None\n    DATA_DIR = None\n    RESULTS_DIR = os.path.join(os.path.dirname(\"__file__\") if \"__file__\" in dir() else \".\", \"output\", \"03\")\n\nDEVICE_DIR_MAP = {\"cuda\": \"gpu\", \"cpu\": \"cpu\"}\n\ndef checkpoint_push(label):\n    if not IN_COLAB:\n        return\n    try:\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"add\", \"tick2/notebooks/output/03/\"], check=True, capture_output=True)\n        status = subprocess.run([\"git\", \"-C\", REPO_DIR, \"status\", \"--porcelain\", \"tick2/notebooks/output/03/\"], capture_output=True, text=True)\n        if not status.stdout.strip():\n            return\n        subprocess.run([\"git\", \"-C\", REPO_DIR, \"commit\", \"-m\", f\"results: notebook 03c moirai {label} ({device_label})\"], check=True, capture_output=True)\n        if GITHUB_TOKEN:\n            subprocess.run([\"git\", \"-C\", REPO_DIR, \"push\"], check=True, capture_output=True, timeout=60)\n            print(f\"  [CHECKPOINT] Pushed {label}\")\n    except Exception as e:\n        print(f\"  [CHECKPOINT WARNING] {e}\")\n\nprint(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === Install Moirai Dependencies ===\nif IN_COLAB:\n    # uni2ts pins torch<2.5; install with --no-deps to keep CUDA torch\n    subprocess.run([\"pip\", \"install\", \"-q\", \"uni2ts\", \"--no-deps\"], check=True)\n    subprocess.run([\"pip\", \"install\", \"-q\", \"einops>=0.7\", \"gluonts>=0.14\", \"jaxtyping\", \"hydra-core\", \"python-dotenv\", \"lightning\", \"safetensors\", \"huggingface_hub\"], check=True)\n\nfrom uni2ts.model.moirai import MoiraiForecast, MoiraiModule\nprint(\"uni2ts ready\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports, Config & Training Mode ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from tick2.data.preprocessing import TARGET_COL, load_all\n",
    "from tick2.finetuning.base import FineTuneConfig\n",
    "from tick2.finetuning.data_prep import prepare_datasets\n",
    "from tick2.finetuning.moirai_ft import finetune_moirai, load_finetuned_moirai\n",
    "from tick2.finetuning.evaluate import evaluate_finetuned, load_zero_shot_baselines, compare_ft_vs_zero_shot\n",
    "from tick2.utils.gpu import clear_gpu_memory\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# --- User-configurable knobs ---\n",
    "TRAINING_MODE = \"combined\"   # \"combined\" or \"per_machine\"\n",
    "DEVICE_OVERRIDE = None       # None = auto-detect, \"cuda\", or \"cpu\"\n",
    "FORCE_RETRAIN = False        # Set True to retrain even if cached CSV exists\n",
    "\n",
    "device = DEVICE_OVERRIDE or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_label = DEVICE_DIR_MAP.get(device, device)\n",
    "config = FineTuneConfig(context_length=1000, prediction_length=96, max_covariates=20, seed=42)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    vram = getattr(props, \"total_memory\", getattr(props, \"total_mem\", 0))\n",
    "    print(f\"GPU:  {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {vram / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "print(f\"Device: {device}, Mode: {TRAINING_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load & Prepare Data ===\n",
    "data_dir = Path(DATA_DIR) if DATA_DIR else None\n",
    "prepared = prepare_datasets(config, data_dir=data_dir)\n",
    "\n",
    "for name, p in prepared.items():\n",
    "    print(f\"  {name:16s}: train={len(p.split.train)}, val={len(p.split.val)}, test={len(p.split.test)}, features={len(p.feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === Fine-Tune Moirai 1.1 ===\nfrom tick2.utils.colab import save_checkpoint_to_drive, load_checkpoint_from_drive, setup_training_log\n\noutput_base = Path(RESULTS_DIR)\nft_output_dir = output_base / \"moirai_ft\" / TRAINING_MODE\ndevice_results_dir = output_base / device_label\n\n# Persist training logs to disk (epoch losses, early stopping, errors)\nlog_path = setup_training_log(ft_output_dir)\nprint(f\"Training log: {log_path}\")\n\ncached_path = device_results_dir / f\"moirai-1.1-ft_{TRAINING_MODE}.csv\"\nft_results = None\n\n# Check for existing Drive checkpoint (resume after disconnect)\ndrive_model_name = f\"moirai_ft/{TRAINING_MODE}/best\"\nckpt_local = ft_output_dir / \"combined\" / \"best\"\nif not cached_path.exists() and not FORCE_RETRAIN and not ckpt_local.exists():\n    resumed = load_checkpoint_from_drive(\n        model_name=drive_model_name,\n        local_path=str(ckpt_local),\n    )\n    if resumed:\n        print(f\"[RESUMED] Loaded checkpoint from Drive: {resumed}\")\n\nif cached_path.exists() and not FORCE_RETRAIN:\n    print(f\"[CACHED] {cached_path}\")\nelif ckpt_local.exists() and not FORCE_RETRAIN:\n    print(f\"[CACHED] Checkpoint exists at {ckpt_local}, skipping training\")\nelse:\n    clear_gpu_memory()\n    ft_results = finetune_moirai(\n        prepared=prepared,\n        config=config,\n        output_dir=str(ft_output_dir),\n        training_mode=TRAINING_MODE,\n        patch_size=32,\n        max_epochs=20,\n        learning_rate=1e-4,\n        batch_size=32,\n        early_stopping_patience=5,\n        device=device,\n    )\n    for r in ft_results:\n        print(f\"  {r.machine}: {r.training_time_s:.1f}s, best_epoch={r.best_epoch}\")\n\n    # Save checkpoint to Drive for persistence\n    save_checkpoint_to_drive(\n        local_path=ckpt_local,\n        model_name=drive_model_name,\n    )\n\n    checkpoint_push(\"finetuning\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate Fine-Tuned Model ===\n",
    "from tick2.models.moirai import MoiraiWrapper\n",
    "\n",
    "if cached_path.exists() and not FORCE_RETRAIN:\n",
    "    ft_eval_df = pd.read_csv(cached_path)\n",
    "    print(f\"Loaded cached evaluation: {len(ft_eval_df)} rows\")\n",
    "else:\n",
    "    # Load FT model and create wrapper\n",
    "    ckpt_path = ft_output_dir / \"combined\" / \"best\" if TRAINING_MODE == \"combined\" else ft_output_dir\n",
    "    ft_model = load_finetuned_moirai(\n",
    "        str(ckpt_path),\n",
    "        context_length=config.context_length,\n",
    "        prediction_length=config.prediction_length,\n",
    "        n_covariates=config.max_covariates,\n",
    "    )\n",
    "\n",
    "    ft_wrapper = MoiraiWrapper(model_name=\"moirai-1.1-ft\", max_covariates=config.max_covariates)\n",
    "    ft_wrapper._model = ft_model.module if hasattr(ft_model, 'module') else ft_model\n",
    "    ft_wrapper._device = device\n",
    "\n",
    "    ft_eval_df = evaluate_finetuned(\n",
    "        model=ft_wrapper,\n",
    "        prepared=prepared,\n",
    "        config=config,\n",
    "        training_mode=f\"ft_{TRAINING_MODE}\",\n",
    "    )\n",
    "    device_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ft_eval_df.to_csv(cached_path, index=False)\n",
    "    checkpoint_push(\"evaluation\")\n",
    "\n",
    "print(f\"Mean MAE: {ft_eval_df['mae'].mean():.4f}\")\n",
    "print(f\"Rows:     {len(ft_eval_df)}\")\n",
    "display(ft_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Zero-Shot Baselines ===\n",
    "zs_dir = output_base.parent / \"output\" / \"02\"\n",
    "zs_results = load_zero_shot_baselines(zs_dir, model_name=\"moirai-1.1-small\")\n",
    "print(f\"Zero-shot baselines: {len(zs_results)} rows\")\n",
    "if not zs_results.empty:\n",
    "    print(f\"  Mean MAE (ZS): {zs_results['mae'].mean():.4f}\")\n",
    "else:\n",
    "    print(\"  No zero-shot results found. Run notebook 02 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comparison: Fine-Tuned vs Zero-Shot ===\n",
    "if not zs_results.empty:\n",
    "    comparison_df = compare_ft_vs_zero_shot(ft_eval_df, zs_results)\n",
    "\n",
    "    # Compute improvement per machine and covariate mode\n",
    "    merge_cols = [\"machine\", \"context_length\", \"horizon\", \"with_covariates\"]\n",
    "    ft_sub = ft_eval_df[merge_cols + [\"mae\"]].rename(columns={\"mae\": \"mae_ft\"})\n",
    "    zs_sub = zs_results[merge_cols + [\"mae\"]].rename(columns={\"mae\": \"mae_zs\"})\n",
    "    merged = ft_sub.merge(zs_sub, on=merge_cols, how=\"inner\")\n",
    "    merged[\"improvement_pct\"] = (1 - merged[\"mae_ft\"] / merged[\"mae_zs\"]) * 100\n",
    "\n",
    "    print(\"=== Improvement Summary ===\")\n",
    "    print(f\"  Overall mean improvement: {merged['improvement_pct'].mean():.1f}%\")\n",
    "    print()\n",
    "    print(\"  Per machine:\")\n",
    "    for machine, group in merged.groupby(\"machine\"):\n",
    "        print(f\"    {machine:16s}: {group['improvement_pct'].mean():+.1f}%  (FT MAE={group['mae_ft'].mean():.4f}, ZS MAE={group['mae_zs'].mean():.4f})\")\n",
    "    print()\n",
    "    display(merged)\n",
    "else:\n",
    "    comparison_df = ft_eval_df.copy()\n",
    "    print(\"Skipping comparison (no zero-shot baselines available).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualizations ===\n",
    "results_dir = Path(RESULTS_DIR)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1. MAE Comparison: Fine-Tuned vs Zero-Shot ---\n",
    "if not zs_results.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plot_data = []\n",
    "    for machine in sorted(ft_eval_df[\"machine\"].unique()):\n",
    "        ft_mae = ft_eval_df[ft_eval_df[\"machine\"] == machine][\"mae\"].mean()\n",
    "        zs_mae = zs_results[zs_results[\"machine\"] == machine][\"mae\"].mean() if machine in zs_results[\"machine\"].values else None\n",
    "        plot_data.append({\"machine\": machine, \"MAE\": ft_mae, \"mode\": \"Fine-Tuned\"})\n",
    "        if zs_mae is not None:\n",
    "            plot_data.append({\"machine\": machine, \"MAE\": zs_mae, \"mode\": \"Zero-Shot\"})\n",
    "    bar_df = pd.DataFrame(plot_data)\n",
    "    sns.barplot(data=bar_df, x=\"machine\", y=\"MAE\", hue=\"mode\", ax=ax)\n",
    "    ax.set_ylabel(\"MAE (ppm)\")\n",
    "    ax.set_title(f\"Moirai 1.1: Fine-Tuned ({TRAINING_MODE}) vs Zero-Shot\")\n",
    "    ax.legend(title=\"Mode\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(results_dir / f\"moirai_ft_vs_zs_{TRAINING_MODE}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 2. Training Loss Curves ---\n",
    "if ft_results is not None:\n",
    "    fig, axes = plt.subplots(1, len(ft_results), figsize=(6 * len(ft_results), 4), squeeze=False)\n",
    "    for i, r in enumerate(ft_results):\n",
    "        ax = axes[0, i]\n",
    "        epochs = range(1, len(r.train_loss) + 1)\n",
    "        ax.plot(epochs, r.train_loss, label=\"Train Loss\", marker=\"o\", markersize=3)\n",
    "        ax.plot(epochs, r.val_loss, label=\"Val Loss\", marker=\"s\", markersize=3)\n",
    "        ax.axvline(r.best_epoch + 1, color=\"red\", linestyle=\"--\", alpha=0.7, label=f\"Best Epoch ({r.best_epoch + 1})\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_title(f\"{r.machine} ({r.training_time_s:.0f}s)\")\n",
    "        ax.legend(fontsize=8)\n",
    "    fig.suptitle(f\"Moirai 1.1 Fine-Tuning Loss ({TRAINING_MODE})\", fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(results_dir / f\"moirai_ft_loss_{TRAINING_MODE}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Training loss curves not available (loaded from cache).\")\n",
    "\n",
    "print(f\"Saved figures to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export Results ===\n",
    "results_dir = Path(RESULTS_DIR)\n",
    "device_results_dir = results_dir / device_label\n",
    "device_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined comparison CSV\n",
    "if not zs_results.empty:\n",
    "    comparison_csv = device_results_dir / f\"moirai_ft_vs_zs_{TRAINING_MODE}.csv\"\n",
    "    comparison_df.to_csv(comparison_csv, index=False)\n",
    "    print(f\"Comparison CSV: {comparison_csv}\")\n",
    "\n",
    "# Save LaTeX table\n",
    "summary = ft_eval_df.groupby([\"machine\", \"with_covariates\"]).agg(\n",
    "    mae=(\"mae\", \"mean\"),\n",
    "    rmse=(\"rmse\", \"mean\"),\n",
    "    coverage=(\"coverage\", \"mean\"),\n",
    "    inference_ms=(\"inference_ms\", \"mean\"),\n",
    ").round(4).reset_index()\n",
    "\n",
    "latex_path = results_dir / f\"moirai_ft_{TRAINING_MODE}.tex\"\n",
    "with open(latex_path, \"w\") as f:\n",
    "    f.write(summary.to_latex(index=False, float_format=\"%.4f\"))\n",
    "print(f\"LaTeX table:    {latex_path}\")\n",
    "print()\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Push ===\n",
    "if IN_COLAB:\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "    # Stage all outputs\n",
    "    subprocess.run([\"git\", \"add\", \"tick2/notebooks/output/03/\"], check=True)\n",
    "\n",
    "    status = subprocess.run(\n",
    "        [\"git\", \"status\", \"--porcelain\", \"tick2/notebooks/output/03/\"],\n",
    "        capture_output=True, text=True,\n",
    "    )\n",
    "    if status.stdout.strip():\n",
    "        subprocess.run(\n",
    "            [\"git\", \"commit\", \"-m\",\n",
    "             f\"results: notebook 03c moirai fine-tuning final ({TRAINING_MODE}, {device_label})\"],\n",
    "            check=True,\n",
    "        )\n",
    "        if GITHUB_TOKEN:\n",
    "            subprocess.run([\"git\", \"push\"], check=True)\n",
    "            print(\"Pushed final outputs to GitHub.\")\n",
    "        else:\n",
    "            print(\"Committed locally but GITHUB_TOKEN not set.\")\n",
    "    else:\n",
    "        print(\"No new outputs to commit.\")\n",
    "else:\n",
    "    print(f\"Local run. Outputs saved to: {Path(RESULTS_DIR)}\")\n",
    "    print(\"Run 'git add tick2/notebooks/output/03/ && git commit && git push' to share.\")"
   ]
  }
 ]
}