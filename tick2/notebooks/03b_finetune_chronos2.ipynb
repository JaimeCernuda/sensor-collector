{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# ChronoTick 2: Chronos-2 Fine-Tuning\n",
    "\n",
    "Fine-tune Amazon Chronos-2 Small (28M) using LoRA and full fine-tuning.\n",
    "Supports covariates via past_covariates and future_covariates dicts.\n",
    "\n",
    "## Experiments\n",
    "- E1: LoRA FT on univariate drift only\n",
    "- E2: LoRA FT with sensor covariates\n",
    "- E3: Full FT vs LoRA comparison\n",
    "\n",
    "## Training Mode\n",
    "Set `TRAINING_MODE` to \"combined\" (all 4 machines) or \"per_machine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    REPO_DIR = \"/content/sensor-collector\"\n",
    "    REPO_URL = \"https://github.com/JaimeCernuda/sensor-collector.git\"\n",
    "    GITHUB_TOKEN = None\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        GITHUB_TOKEN = userdata.get(\"GITHUB_TOKEN\")\n",
    "    except Exception:\n",
    "        print(\"WARNING: GITHUB_TOKEN not available\")\n",
    "\n",
    "    auth_url = (\n",
    "        f\"https://{GITHUB_TOKEN}@github.com/JaimeCernuda/sensor-collector.git\"\n",
    "        if GITHUB_TOKEN\n",
    "        else REPO_URL\n",
    "    )\n",
    "\n",
    "    if os.path.exists(REPO_DIR):\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", REPO_DIR, \"remote\", \"set-url\", \"origin\", auth_url],\n",
    "            check=True,\n",
    "        )\n",
    "        subprocess.run([\"git\", \"-C\", REPO_DIR, \"fetch\", \"-q\", \"origin\"], check=True)\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", REPO_DIR, \"reset\", \"--hard\", \"origin/main\"],\n",
    "            check=True,\n",
    "        )\n",
    "    else:\n",
    "        subprocess.run([\"git\", \"clone\", \"-q\", auth_url, REPO_DIR], check=True)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"git\", \"-C\", REPO_DIR, \"config\", \"user.name\", \"Colab Runner\"],\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [\"git\", \"-C\", REPO_DIR, \"config\", \"user.email\", \"colab@chronotick.dev\"],\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"-e\", f\"{REPO_DIR}/tick2/\"], check=True)\n",
    "\n",
    "    tick2_src = f\"{REPO_DIR}/tick2/src\"\n",
    "    if tick2_src not in sys.path:\n",
    "        sys.path.insert(0, tick2_src)\n",
    "\n",
    "    # Always mount Drive â€” needed for checkpoint persistence (models too large for git)\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # Data: prefer repo copy, fall back to Drive\n",
    "    DATA_DIR = f\"{REPO_DIR}/sensors/data\"\n",
    "    if not os.path.isdir(f\"{DATA_DIR}/24h_snapshot\"):\n",
    "        DATA_DIR = \"/content/drive/MyDrive/chronotick2/data\"\n",
    "\n",
    "    RESULTS_DIR = f\"{REPO_DIR}/tick2/notebooks/output/03\"\n",
    "else:\n",
    "    GITHUB_TOKEN = None\n",
    "    DATA_DIR = None\n",
    "    RESULTS_DIR = os.path.join(\n",
    "        os.path.dirname(\"__file__\") if \"__file__\" in dir() else \".\",\n",
    "        \"output\",\n",
    "        \"03\",\n",
    "    )\n",
    "\n",
    "DEVICE_DIR_MAP = {\"cuda\": \"gpu\", \"cpu\": \"cpu\"}\n",
    "\n",
    "\n",
    "def checkpoint_push(label):\n",
    "    \"\"\"Git add, commit, and push results after a step completes.\"\"\"\n",
    "    if not IN_COLAB:\n",
    "        return\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", REPO_DIR, \"add\", \"tick2/notebooks/output/03/\"],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "        )\n",
    "        status = subprocess.run(\n",
    "            [\n",
    "                \"git\",\n",
    "                \"-C\",\n",
    "                REPO_DIR,\n",
    "                \"status\",\n",
    "                \"--porcelain\",\n",
    "                \"tick2/notebooks/output/03/\",\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        if not status.stdout.strip():\n",
    "            return\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"git\",\n",
    "                \"-C\",\n",
    "                REPO_DIR,\n",
    "                \"commit\",\n",
    "                \"-m\",\n",
    "                f\"results: notebook 03b chronos2 {label} ({device_label})\",\n",
    "            ],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "        )\n",
    "        if GITHUB_TOKEN:\n",
    "            fetch_cmd = [\n",
    "                \"git\",\n",
    "                \"-C\",\n",
    "                REPO_DIR,\n",
    "                \"fetch\",\n",
    "                \"-q\",\n",
    "                \"origin\",\n",
    "            ]\n",
    "            rebase_cmd = [\n",
    "                \"git\",\n",
    "                \"-C\",\n",
    "                REPO_DIR,\n",
    "                \"rebase\",\n",
    "                \"origin/main\",\n",
    "            ]\n",
    "            subprocess.run(\n",
    "                fetch_cmd,\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run(\n",
    "                rebase_cmd,\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run(\n",
    "                [\"git\", \"-C\", REPO_DIR, \"push\"],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                timeout=60,\n",
    "            )\n",
    "            print(f\"  [CHECKPOINT] Pushed {label}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [CHECKPOINT WARNING] {e}\")\n",
    "\n",
    "\n",
    "print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Install Chronos-2 dependencies ===\n",
    "if IN_COLAB:\n",
    "    subprocess.run(\n",
    "        [\"pip\", \"install\", \"-q\", \"chronos-forecasting[extras]>=2.2\"],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"chronos-forecasting ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports, Config & Training Mode ===\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from tick2.finetuning.base import FineTuneConfig\n",
    "from tick2.finetuning.chronos2_ft import (\n",
    "    finetune_chronos2,\n",
    "    load_finetuned_chronos2,\n",
    ")\n",
    "from tick2.finetuning.data_prep import prepare_datasets\n",
    "from tick2.finetuning.evaluate import (\n",
    "    compare_ft_vs_zero_shot,\n",
    "    evaluate_finetuned,\n",
    "    load_zero_shot_baselines,\n",
    ")\n",
    "from tick2.utils.gpu import clear_gpu_memory\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# --- Training configuration ---\n",
    "TRAINING_MODE = \"combined\"  # \"combined\" or \"per_machine\"\n",
    "DEVICE_OVERRIDE = None\n",
    "FORCE_RETRAIN = False\n",
    "\n",
    "device = DEVICE_OVERRIDE or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_label = DEVICE_DIR_MAP.get(device, device)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    vram = getattr(\n",
    "        props,\n",
    "        \"total_memory\",\n",
    "        getattr(props, \"total_mem\", 0),\n",
    "    )\n",
    "    print(f\"GPU:  {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {vram / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "config = FineTuneConfig(\n",
    "    context_length=2048,\n",
    "    prediction_length=96,\n",
    "    max_covariates=30,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Device: {device}, Mode: {TRAINING_MODE}\")\n",
    "print(f\"Context: {config.context_length}, Prediction: {config.prediction_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load and Prepare Data ===\n",
    "data_dir = Path(DATA_DIR) if DATA_DIR else None\n",
    "prepared = prepare_datasets(config, data_dir=data_dir)\n",
    "\n",
    "for name, p in prepared.items():\n",
    "    print(\n",
    "        f\"  {name:16s}: train={len(p.split.train)}, \"\n",
    "        f\"val={len(p.split.val)}, test={len(p.split.test)}, \"\n",
    "        f\"features={len(p.feature_cols)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Fine-Tune Chronos-2 (E1, E2, E3) ===\n",
    "from tick2.utils.colab import (\n",
    "    load_checkpoint_from_drive,\n",
    "    save_checkpoint_to_drive,\n",
    "    setup_training_log,\n",
    ")\n",
    "\n",
    "output_base = Path(RESULTS_DIR)\n",
    "ft_output_dir = output_base / \"chronos2_ft\" / TRAINING_MODE\n",
    "device_results_dir = output_base / device_label\n",
    "device_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "log_path = setup_training_log(ft_output_dir)\n",
    "print(f\"Training log: {log_path}\")\n",
    "\n",
    "# --- Experiment definitions ---\n",
    "# E1: LoRA FT on univariate drift only\n",
    "# E2: LoRA FT with sensor covariates\n",
    "# E3: Full FT with sensor covariates\n",
    "# Note: E3 requires A100+ (full FT OOMs on T4 at bs=256)\n",
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"E1_lora_uni\",\n",
    "        \"finetune_mode\": \"lora\",\n",
    "        \"with_covariates\": False,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"num_steps\": 1000,\n",
    "        \"batch_size\": 256,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"E2_lora_cov\",\n",
    "        \"finetune_mode\": \"lora\",\n",
    "        \"with_covariates\": True,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"num_steps\": 1000,\n",
    "        \"batch_size\": 256,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"E3_full_cov\",\n",
    "        \"finetune_mode\": \"full\",\n",
    "        \"with_covariates\": True,\n",
    "        \"learning_rate\": 1e-6,\n",
    "        \"num_steps\": 1000,\n",
    "        \"batch_size\": 256,\n",
    "    },\n",
    "]\n",
    "\n",
    "all_ft_results = []\n",
    "experiment_labels = {}\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    exp_name = exp[\"name\"]\n",
    "    ft_mode = exp[\"finetune_mode\"]\n",
    "    cov = exp[\"with_covariates\"]\n",
    "    bs = exp[\"batch_size\"]\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\n",
    "        f\"  {exp_name}  (ft={ft_mode},\"\n",
    "        f\" covariates={cov},\"\n",
    "        f\" lr={exp['learning_rate']},\"\n",
    "        f\" bs={bs})\"\n",
    "    )\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    exp_dir = ft_output_dir / exp_name\n",
    "\n",
    "    # Check for cached checkpoint (local, then Drive)\n",
    "    ckpt_local = exp_dir / \"combined\" / \"combined_best\"\n",
    "    ckpt_parent = exp_dir / \"combined\"\n",
    "    cached_eval = device_results_dir / f\"chronos2-ft-{exp_name}_{TRAINING_MODE}.csv\"\n",
    "\n",
    "    # Restore from Drive to ckpt_parent (not ckpt_local)\n",
    "    # so the directory structure matches what save_checkpoint_to_drive created\n",
    "    if not ckpt_local.exists() and not FORCE_RETRAIN:\n",
    "        drive_name = f\"chronos2_ft/{TRAINING_MODE}/{exp_name}\"\n",
    "        resumed = load_checkpoint_from_drive(\n",
    "            model_name=drive_name,\n",
    "            local_path=str(ckpt_parent),\n",
    "        )\n",
    "        if resumed:\n",
    "            print(f\"  [RESUMED] From Drive: {resumed}\")\n",
    "\n",
    "    if cached_eval.exists() and not FORCE_RETRAIN:\n",
    "        print(f\"  [CACHED] Eval exists: {cached_eval}\")\n",
    "        from tick2.finetuning.base import FineTuneResult\n",
    "\n",
    "        stub = FineTuneResult(\n",
    "            model_name=f\"chronos2-ft-{exp_name}\",\n",
    "            machine=TRAINING_MODE,\n",
    "            checkpoint_path=str(ckpt_local),\n",
    "            config=exp,\n",
    "        )\n",
    "        all_ft_results.append(stub)\n",
    "        experiment_labels[exp_name] = [stub]\n",
    "        continue\n",
    "\n",
    "    if ckpt_local.exists() and not FORCE_RETRAIN:\n",
    "        print(f\"  [CACHED] Checkpoint: {ckpt_local}\")\n",
    "        from tick2.finetuning.base import FineTuneResult\n",
    "\n",
    "        stub = FineTuneResult(\n",
    "            model_name=f\"chronos2-ft-{exp_name}\",\n",
    "            machine=TRAINING_MODE,\n",
    "            checkpoint_path=str(ckpt_local),\n",
    "            config=exp,\n",
    "        )\n",
    "        all_ft_results.append(stub)\n",
    "        experiment_labels[exp_name] = [stub]\n",
    "        continue\n",
    "\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    try:\n",
    "        ft_results = finetune_chronos2(\n",
    "            prepared=prepared,\n",
    "            config=config,\n",
    "            output_dir=str(exp_dir),\n",
    "            training_mode=TRAINING_MODE,\n",
    "            finetune_mode=ft_mode,\n",
    "            with_covariates=cov,\n",
    "            learning_rate=exp[\"learning_rate\"],\n",
    "            num_steps=exp[\"num_steps\"],\n",
    "            batch_size=bs,\n",
    "            device_map=device,\n",
    "        )\n",
    "\n",
    "        for r in ft_results:\n",
    "            r.model_name = f\"chronos2-ft-{exp_name}\"\n",
    "            print(f\"  {r.machine}: {r.training_time_s:.1f}s, ckpt={r.checkpoint_path}\")\n",
    "\n",
    "        all_ft_results.extend(ft_results)\n",
    "        experiment_labels[exp_name] = ft_results\n",
    "\n",
    "        save_checkpoint_to_drive(\n",
    "            local_path=ckpt_parent,\n",
    "            model_name=(f\"chronos2_ft/{TRAINING_MODE}/{exp_name}\"),\n",
    "        )\n",
    "        checkpoint_push(exp_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] {exp_name}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        clear_gpu_memory()\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"  Completed: {list(experiment_labels.keys())}\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate Fine-Tuned Models ===\n",
    "from tick2.finetuning.data_prep import combine_training_data\n",
    "from tick2.models.chronos2 import Chronos2Wrapper\n",
    "\n",
    "# Compute shared feature intersection (same as training used)\n",
    "_, shared_features_all = combine_training_data(prepared)\n",
    "eval_features = shared_features_all[: config.max_covariates]\n",
    "print(\n",
    "    f\"Shared eval features: {len(eval_features)}\"\n",
    "    f\" (capped from {len(shared_features_all)})\"\n",
    ")\n",
    "\n",
    "eval_dfs = []\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    exp_name = exp[\"name\"]\n",
    "    cov = exp[\"with_covariates\"]\n",
    "    print(f\"\\n--- Evaluating {exp_name} ---\")\n",
    "\n",
    "    cached_eval = device_results_dir / f\"chronos2-ft-{exp_name}_{TRAINING_MODE}.csv\"\n",
    "    if cached_eval.exists() and not FORCE_RETRAIN:\n",
    "        print(f\"  [CACHED] {cached_eval}\")\n",
    "        eval_dfs.append(pd.read_csv(cached_eval))\n",
    "        continue\n",
    "\n",
    "    # Find checkpoint\n",
    "    exp_dir = ft_output_dir / exp_name\n",
    "    ckpt_path = exp_dir / \"combined\" / \"combined_best\"\n",
    "    if not ckpt_path.exists():\n",
    "        ckpt_path = exp_dir / \"combined\"\n",
    "    if not ckpt_path.exists():\n",
    "        print(f\"  [SKIP] No checkpoint for {exp_name}\")\n",
    "        continue\n",
    "\n",
    "    clear_gpu_memory()\n",
    "\n",
    "    try:\n",
    "        ft_pipeline = load_finetuned_chronos2(\n",
    "            str(ckpt_path),\n",
    "            device_map=device,\n",
    "        )\n",
    "\n",
    "        ft_wrapper = Chronos2Wrapper(\n",
    "            model_id=str(ckpt_path),\n",
    "            model_name=f\"chronos2-ft-{exp_name}\",\n",
    "        )\n",
    "        ft_wrapper._pipeline = ft_pipeline\n",
    "        ft_wrapper._device = device\n",
    "\n",
    "        # Use covariates only if this experiment trained with them\n",
    "        shared_cols = eval_features if cov else None\n",
    "\n",
    "        results_for_exp = experiment_labels.get(exp_name, [])\n",
    "        ft_epochs = results_for_exp[0].best_epoch if results_for_exp else None\n",
    "        ft_time = results_for_exp[0].training_time_s if results_for_exp else None\n",
    "        ft_machines = results_for_exp[0].machine if results_for_exp else \"\"\n",
    "\n",
    "        eval_df = evaluate_finetuned(\n",
    "            model=ft_wrapper,\n",
    "            prepared=prepared,\n",
    "            config=config,\n",
    "            training_mode=f\"ft_{TRAINING_MODE}\",\n",
    "            ft_epochs=ft_epochs,\n",
    "            ft_time_s=ft_time,\n",
    "            ft_train_machines=ft_machines,\n",
    "            shared_feature_cols=shared_cols,\n",
    "        )\n",
    "\n",
    "        if not eval_df.empty:\n",
    "            eval_df[\"experiment\"] = exp_name\n",
    "            eval_df.to_csv(cached_eval, index=False)\n",
    "            eval_dfs.append(eval_df)\n",
    "            print(f\"  MAE: {eval_df['mae'].mean():.4f}\")\n",
    "            print(f\"  Saved: {cached_eval}\")\n",
    "        else:\n",
    "            print(f\"  [WARN] No eval results for {exp_name}\")\n",
    "\n",
    "        checkpoint_push(f\"eval-{exp_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] Eval {exp_name}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        clear_gpu_memory()\n",
    "\n",
    "# Combine all evaluation results\n",
    "if eval_dfs:\n",
    "    ft_eval_df = pd.concat(eval_dfs, ignore_index=True)\n",
    "    print(f\"\\nTotal FT eval rows: {len(ft_eval_df)}\")\n",
    "    print(f\"Mean MAE:  {ft_eval_df['mae'].mean():.4f}\")\n",
    "    print(f\"Mean RMSE: {ft_eval_df['rmse'].mean():.4f}\")\n",
    "    if ft_eval_df[\"coverage\"].notna().any():\n",
    "        print(f\"Mean Coverage: {ft_eval_df['coverage'].mean():.1%}\")\n",
    "    display(ft_eval_df)\n",
    "else:\n",
    "    ft_eval_df = pd.DataFrame()\n",
    "    print(\"No evaluation results collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Zero-Shot Baselines ===\n",
    "zs_dir = output_base.parent / \"output\" / \"02\"\n",
    "zs_results = load_zero_shot_baselines(\n",
    "    zs_dir,\n",
    "    model_name=\"chronos2-small\",\n",
    ")\n",
    "print(f\"Zero-shot baselines: {len(zs_results)} rows\")\n",
    "if not zs_results.empty:\n",
    "    print(f\"  Mean MAE: {zs_results['mae'].mean():.4f}\")\n",
    "    machines = zs_results[\"machine\"].unique().tolist()\n",
    "    print(f\"  Machines: {machines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comparison: Fine-Tuned vs Zero-Shot ===\n",
    "if not ft_eval_df.empty and not zs_results.empty:\n",
    "    combined = compare_ft_vs_zero_shot(ft_eval_df, zs_results)\n",
    "\n",
    "    # --- Per-experiment improvement ---\n",
    "    best_zs = (\n",
    "        zs_results.groupby(\"machine\")[\"mae\"]\n",
    "        .agg([\"min\", \"idxmin\"])\n",
    "        .rename(columns={\"min\": \"best_zs_mae\"})\n",
    "    )\n",
    "    best_zs[\"best_zs_ctx\"] = zs_results.loc[best_zs[\"idxmin\"], \"context_length\"].values\n",
    "    best_zs = best_zs.drop(columns=[\"idxmin\"])\n",
    "\n",
    "    summary_rows = []\n",
    "    for machine in ft_eval_df[\"machine\"].unique():\n",
    "        if machine not in best_zs.index:\n",
    "            continue\n",
    "        bzs_mae = best_zs.loc[machine, \"best_zs_mae\"]\n",
    "        bzs_ctx = int(best_zs.loc[machine, \"best_zs_ctx\"])\n",
    "\n",
    "        for exp in EXPERIMENTS:\n",
    "            exp_name = exp[\"name\"]\n",
    "            ft_mask = ft_eval_df[\"model\"].str.contains(exp_name, na=False) & (\n",
    "                ft_eval_df[\"machine\"] == machine\n",
    "            )\n",
    "            if not ft_mask.any():\n",
    "                continue\n",
    "            ft_mae = ft_eval_df.loc[ft_mask, \"mae\"].mean()\n",
    "\n",
    "            if bzs_mae > 0:\n",
    "                imp = (bzs_mae - ft_mae) / bzs_mae * 100\n",
    "                summary_rows.append(\n",
    "                    {\n",
    "                        \"machine\": machine,\n",
    "                        \"experiment\": exp_name,\n",
    "                        \"ft_mae\": ft_mae,\n",
    "                        \"best_zs_ctx\": bzs_ctx,\n",
    "                        \"best_zs_mae\": bzs_mae,\n",
    "                        \"vs_best_zs_pct\": imp,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows)\n",
    "        print(\"=== FT vs Best Zero-Shot ===\")\n",
    "        display(summary_df.round(4))\n",
    "\n",
    "        print(\"\\n=== Per-Experiment Summary ===\")\n",
    "        for exp in EXPERIMENTS:\n",
    "            exp_name = exp[\"name\"]\n",
    "            ed = summary_df[summary_df[\"experiment\"] == exp_name]\n",
    "            if not ed.empty:\n",
    "                ft_m = ed[\"ft_mae\"].mean()\n",
    "                zs_m = ed[\"best_zs_mae\"].mean()\n",
    "                imp_m = ed[\"vs_best_zs_pct\"].mean()\n",
    "                print(\n",
    "                    f\"  {exp_name}: FT={ft_m:.4f},\"\n",
    "                    f\" ZS={zs_m:.4f},\"\n",
    "                    f\" improvement={imp_m:+.1f}%\"\n",
    "                )\n",
    "    else:\n",
    "        print(\"Could not compute improvement.\")\n",
    "\n",
    "    print(f\"\\nCombined results: {len(combined)} rows\")\n",
    "    display(combined)\n",
    "elif ft_eval_df.empty:\n",
    "    combined = pd.DataFrame()\n",
    "    print(\"No FT results to compare.\")\n",
    "else:\n",
    "    combined = ft_eval_df.copy()\n",
    "    print(\"No zero-shot baselines to compare against.\")\n",
    "    display(ft_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualizations ===\n",
    "results_dir = Path(RESULTS_DIR)\n",
    "fig_dir = results_dir / \"figures\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not ft_eval_df.empty:\n",
    "    # --- 1. MAE Comparison Bar Chart ---\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "    plot_rows = []\n",
    "\n",
    "    # Add ZS baseline\n",
    "    if not zs_results.empty:\n",
    "        for machine in zs_results[\"machine\"].unique():\n",
    "            m_zs = zs_results[zs_results[\"machine\"] == machine]\n",
    "            plot_rows.append(\n",
    "                {\n",
    "                    \"machine\": machine,\n",
    "                    \"variant\": \"Zero-Shot\",\n",
    "                    \"mae\": m_zs[\"mae\"].mean(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Add FT experiments\n",
    "    for exp in EXPERIMENTS:\n",
    "        exp_name = exp[\"name\"]\n",
    "        exp_data = ft_eval_df[ft_eval_df[\"model\"].str.contains(exp_name, na=False)]\n",
    "        for machine in exp_data[\"machine\"].unique():\n",
    "            m_ft = exp_data[exp_data[\"machine\"] == machine]\n",
    "            plot_rows.append(\n",
    "                {\n",
    "                    \"machine\": machine,\n",
    "                    \"variant\": exp_name,\n",
    "                    \"mae\": m_ft[\"mae\"].mean(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    if plot_rows:\n",
    "        plot_df = pd.DataFrame(plot_rows)\n",
    "        sns.barplot(\n",
    "            data=plot_df,\n",
    "            x=\"machine\",\n",
    "            y=\"mae\",\n",
    "            hue=\"variant\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_ylabel(\"MAE (ppm)\")\n",
    "        ax.set_title(\"Chronos-2: FT vs Zero-Shot MAE by Machine\")\n",
    "        ax.legend(\n",
    "            title=\"Variant\",\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\n",
    "            fig_dir / \"chronos2_ft_vs_zs_mae.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- 2. Coverage Comparison (if available) ---\n",
    "    if ft_eval_df[\"coverage\"].notna().any():\n",
    "        cov_data = ft_eval_df[ft_eval_df[\"coverage\"].notna()]\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        sns.barplot(\n",
    "            data=cov_data,\n",
    "            x=\"machine\",\n",
    "            y=\"coverage\",\n",
    "            hue=\"model\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.axhline(\n",
    "            0.8,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.5,\n",
    "            label=\"80% target\",\n",
    "        )\n",
    "        ax.set_ylabel(\"Coverage\")\n",
    "        ax.set_title(\"Prediction Interval Coverage\")\n",
    "        ax.legend(\n",
    "            title=\"Model\",\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\n",
    "            fig_dir / \"chronos2_ft_coverage.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Saved figures to: {fig_dir}\")\n",
    "else:\n",
    "    print(\"No results to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export Results ===\n",
    "from tick2.benchmark.reporting import results_to_latex, save_results\n",
    "\n",
    "if not ft_eval_df.empty:\n",
    "    # Save combined FT results\n",
    "    ft_csv = device_results_dir / f\"chronos2-ft-all_{TRAINING_MODE}.csv\"\n",
    "    ft_eval_df.to_csv(ft_csv, index=False)\n",
    "    print(f\"FT results CSV: {ft_csv}\")\n",
    "\n",
    "if not combined.empty:\n",
    "    csv_path, latex_path = save_results(\n",
    "        combined,\n",
    "        results_dir,\n",
    "        prefix=f\"chronos2_ft_{TRAINING_MODE}\",\n",
    "    )\n",
    "    print(f\"Comparison CSV:   {csv_path}\")\n",
    "    print(f\"Comparison LaTeX: {latex_path}\")\n",
    "    latex = results_to_latex(\n",
    "        combined,\n",
    "        caption=(f\"Chronos-2 fine-tuning vs zero-shot ({TRAINING_MODE})\"),\n",
    "        label=\"tab:chronos2-ft\",\n",
    "    )\n",
    "    print(f\"\\n{latex}\")\n",
    "else:\n",
    "    print(\"No results to export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Push ===\n",
    "if IN_COLAB:\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"git\", \"add\", \"tick2/notebooks/output/03/\"],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "    status = subprocess.run(\n",
    "        [\"git\", \"status\", \"--porcelain\", \"tick2/notebooks/output/03/\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "    )\n",
    "    if status.stdout.strip():\n",
    "        msg = f\"results: notebook 03b chronos2-ft figures and combined ({device_label})\"\n",
    "        subprocess.run(\n",
    "            [\"git\", \"commit\", \"-m\", msg],\n",
    "            check=True,\n",
    "        )\n",
    "        if GITHUB_TOKEN:\n",
    "            subprocess.run(\n",
    "                [\"git\", \"fetch\", \"-q\", \"origin\"],\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run(\n",
    "                [\"git\", \"rebase\", \"origin/main\"],\n",
    "                capture_output=True,\n",
    "                timeout=30,\n",
    "            )\n",
    "            subprocess.run([\"git\", \"push\"], check=True)\n",
    "            print(\"Pushed final outputs to GitHub.\")\n",
    "        else:\n",
    "            print(\"Committed locally (no token for push).\")\n",
    "    else:\n",
    "        print(\"No new outputs to commit.\")\n",
    "else:\n",
    "    print(f\"Local run. Outputs saved to: {results_dir}\")\n",
    "    print(\n",
    "        \"Run 'git add tick2/notebooks/output/03/ && git commit && git push' to share.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}