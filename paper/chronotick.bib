@inproceedings{shap_nips2017,
  author = {Scott M. Lundberg and Su-In Lee},
  title = {{A Unified Approach to Interpreting Model Predictions}},
  booktitle = {Advances in Neural Information Processing Systems 30 (NeurIPS)},
  year = {2017},
  pages = {4765--4774}
}

@techreport{ntp,
  author = {D. Mills and J. Martin and J. Burbank and W. Kasch},
  title = {{Network Time Protocol Version 4: Protocol and Algorithms Specification}},
  institution = {Internet Engineering Task Force},
  type = {RFC},
  number = {5905},
  year = {2010},
  month = jun,
  url = {https://datatracker.ietf.org/doc/html/rfc5905},
  doi = {10.17487/RFC5905}
}

@inproceedings{ptp_hardware_costs_survey,
  author={Byagowi, Ahmad and Meier, Sven and Schaub, Thomas and Sotiropoulos, Ioannis},
  booktitle={2022 IEEE International Symposium on Precision Clock Synchronization for Measurement, Control, and Communication (ISPCS)},
  title={Time Card and Open Time Server},
  year={2022},
  volume={},
  number={},
  pages={1-6},
  keywords={Global navigation satellite system;Data centers;Protocols;Time measurement;Servers;Synchronization;Network interfaces;Time Card;Open Time Server;GNSS;MAC;FPGA;PTP;NTP;time synchronization;data center},
  doi={10.1109/ISPCS55791.2022.9918379}
}

@techreport{meta_ptp_time_appliances,
  author = {Ahmad Byagowi and Oleg Obleukhov},
  title = {Open-sourcing a more precise time appliance},
  institution = {Meta (Facebook) Engineering},
  year = {2021},
  month = aug,
  url = {https://engineering.fb.com/2021/08/11/open-source/time-appliance/},
  note = {Meta Engineering Blog}
}

@INPROCEEDINGS{whiterabbit,
  author={Lipiński, Maciej and Włostowski, Tomasz and Serrano, Javier and Alvarez, Pablo},
  booktitle={2011 IEEE International Symposium on Precision Clock Synchronization for Measurement, Control and Communication},
  title={White rabbit: a PTP application for robust sub-nanosecond synchronization},
  year={2011},
  volume={},
  number={},
  pages={25-30},
  keywords={Synchronization;Delay;Clocks;Rabbits;Accuracy;Phase measurement},
  doi={10.1109/ISPCS.2011.6070148}}

@inproceedings{spanner_osdi2012_truetime_gps_atomic,
  author = {James C. Corbett and Jeffrey Dean and Michael Epstein and Andrew Fikes and Christopher Frost and JJ Furman and Sanjay Ghemawat and Andrey Gubarev and Christopher Heiser and Peter Hochschild and Wilson Hsieh and Sebastian Kanthak and Eugene Kogan and Hongyi Li and Alexander Lloyd and Sergey Melnik and David Mwaura and David Nagle and Sean Quinlan and Rajesh Rao and Lindsay Rolig and Yasushi Saito and Michal Szymaniak and Christopher Taylor and Ruth Wang and Dale Woodford},
  title = {Spanner: {Google's} Globally-Distributed Database},
  booktitle = {10th USENIX Symposium on Operating Systems Design and Implementation (OSDI '12)},
  year = {2012},
  pages = {251--264},
  publisher = {USENIX Association},
  address = {Hollywood, CA, USA},
  month = oct,
  url = {https://www.usenix.org/conference/osdi12/technical-sessions/presentation/corbett}
}

@inproceedings{cockroachdb_hlc_implementation,
  author = {Rebecca Taft and Irfan Sharif and Andrei Matei and Nathan VanBenschoten and Jordan Lewis and Tobias Grieger and Kai Niemi and Andy Woods and Anne Birzin and Raphael Poss and Paul Bardea and Amruta Ranade and Ben Darnell and Bram Gruneir and Justin Jaffray and Lucy Zhang and Peter Mattis},
  title = {CockroachDB: The Resilient Geo-Distributed {SQL} Database},
  booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
  series = {SIGMOD '20},
  year = {2020},
  pages = {1493--1509},
  publisher = {ACM},
  address = {Portland, OR, USA},
  month = jun,
  doi = {10.1145/3318464.3386134}
}

@misc{yugabytedb_hlc_distributed,
  author = {{YugabyteDB Team}},
  title = {Fundamentals of Distributed Transactions},
  year = {2024},
  url = {https://docs.yugabyte.com/preview/architecture/transactions/transactions-overview/},
  note = {YugabyteDB Documentation}
}

@misc{ntp_performance_chrony_ntpd,
  author = {{Chrony Project}},
  title = {Comparison of {NTP} Implementations},
  year = {2024},
  url = {https://chrony-project.org/comparison.html},
  note = {Chrony Project Documentation}
}

@inproceedings{huygens_nsdi2018_geng_svm_nanosec,
  author = {Yilong Geng and Shiyu Liu and Zi Yin and Ashish Naik and Balaji Prabhakar and Mendel Rosenblum and Amin Vahdat},
  title = {Exploiting a Natural Network Effect for Scalable, Fine-grained Clock Synchronization},
  booktitle = {15th USENIX Symposium on Networked Systems Design and Implementation (NSDI '18)},
  year = {2018},
  pages = {81--94},
  publisher = {USENIX Association},
  address = {Renton, WA, USA},
  month = apr,
  url = {https://www.usenix.org/conference/nsdi18/presentation/geng}
}

@article{su_lstm_tcxo_transfer_learning,
  author = {Bo-Chen Su and Duc Huy Nguyen and Paul C.-P. Chao},
  title = {Predicting Frequency Deviation of a Crystal Oscillator Based on Long Short-Term Memory Network and Transfer Learning Technique},
  journal = {Microsystem Technologies},
  year = {2024},
  month = may,
  publisher = {Springer},
  doi = {10.1007/s00542-024-05691-2},
  url = {https://link.springer.com/article/10.1007/s00542-024-05691-2},
  note = {51\% improvement through LSTM and transfer learning for TCXO prediction}
}

@article{he_bds3_lstm_72pct_arima,
  author = {Shaofeng He and Jiulong Liu and Xiangwei Zhu and Zhiqiang Dai and Du Li},
  title = {Research on Modeling and Predicting of {BDS-3} Satellite Clock Bias Using the {LSTM} Neural Network Model},
  journal = {GPS Solutions},
  volume = {27},
  number = {3},
  articleno = {108},
  year = {2023},
  month = apr,
  publisher = {Springer},
  doi = {10.1007/s10291-023-01451-3},
  url = {https://link.springer.com/article/10.1007/s10291-023-01451-3},
  note = {72\% improvement over ARIMA; sub-nanosecond accuracy for BDS-3}
}

@incollection{chamelon_citation,
  title={Lessons Learned from the Chameleon Testbed},
  author={Kate Keahey and Jason Anderson and Zhuo Zhen and Pierre Riteau and Paul Ruth and Dan Stanzione and Mert Cevik and Jacob Colleran and Haryadi S. Gunawi and Cody Hammock and Joe Mambretti and Alexander Barnes and Fran\c{c}ois Halbach and Alex Rocha and Joe Stubbs},
  booktitle={Proceedings of the 2020 USENIX Annual Technical Conference (USENIX ATC '20)},
  publisher={USENIX Association},
  month={July},
  year={2020}
}

@ARTICLE{ptp,
  author={},
  journal={IEEE Std 1588-2008 (Revision of IEEE Std 1588-2002)},
  title={IEEE Standard for a Precision Clock Synchronization Protocol for Networked Measurement and Control Systems},
  year={2008},
  volume={},
  number={},
  pages={1-269},
  keywords={IEEE Standards;Standards;Clocks;Trademarks;Synchronization;Protocols;Patents;1588-2008;boundary clock;clock;distributed system;master clock;measurement and control system;real-time clock;synchronized clock;transparent clock},
  doi={10.1109/IEEESTD.2008.4579760}}

@misc{TEMPO,
  title={TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting},
  author={Defu Cao and Furong Jia and Sercan O Arik and Tomas Pfister and Yixiang Zheng and Wen Ye and Yan Liu},
  year={2024},
  eprint={2310.04948},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2310.04948},
}

@misc{TIME-LLM,
  title={Time-LLM: Time Series Forecasting by Reprogramming Large Language Models},
  author={Ming Jin and Shiyu Wang and Lintao Ma and Zhixuan Chu and James Y. Zhang and Xiaoming Shi and Pin-Yu Chen and Yuxuan Liang and Yuan-Fang Li and Shirui Pan and Qingsong Wen},
  year={2024},
  eprint={2310.01728},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2310.01728},
}

@inproceedings{AutoTimes,
 author = {Liu, Yong and Qin, Guo and Huang, Xiangdong and Wang, Jianmin and Long, Mingsheng},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {122154--122184},
 publisher = {Curran Associates, Inc.},
 title = {AutoTimes: Autoregressive Time Series Forecasters via Large Language Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/dcf88cbc8d01ce7309b83d0ebaeb9d29-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}

@misc{TimeGPT-1,
  title={TimeGPT-1},
  author={Azul Garza and Cristian Challu and Max Mergenthaler-Canseco},
  year={2024},
  eprint={2310.03589},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2310.03589},
}

@inproceedings{Crossformer,
title={Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting},
author={Yunhao Zhang and Junchi Yan},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=vSVLM2j9eie}
}

@misc{PatchTST,
  title={A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  author={Yuqi Nie and Nam H. Nguyen and Phanwadee Sinthong and Jayant Kalagnanam},
  year={2023},
  eprint={2211.14730},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2211.14730},
}

@misc{MOIRAI,
  title={Unified Training of Universal Time Series Forecasting Transformers},
  author={Gerald Woo and Chenghao Liu and Akshat Kumar and Caiming Xiong and Silvio Savarese and Doyen Sahoo},
  year={2024},
  eprint={2402.02592},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2402.02592},
}

@misc{Time-MoE,
  title={Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts},
  author={Xiaoming Shi and Shiyu Wang and Yuqi Nie and Dianqi Li and Zhou Ye and Qingsong Wen and Ming Jin},
  year={2025},
  eprint={2409.16040},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2409.16040},
}

@inproceedings{TimesFM,
title={A decoder-only foundation model for time-series forecasting},
author={Abhimanyu Das and Weihao Kong and Rajat Sen and Yichen Zhou},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=jn2iTJas6h}
}

@inproceedings{TTMs,
 author = {Ekambaram, Vijay and Jati, Arindam and Dayama, Pankaj and Mukherjee, Sumanta and Nguyen, Nam H. and Gifford, Wesley M. and Reddy, Chandra and Kalagnanam, Jayant},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {74147--74181},
 publisher = {Curran Associates, Inc.},
 title = {Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/874a4d89f2d04b4bcf9a2c19545cf040-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}

@misc{TimeXer,
  title={TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables},
  author={Yuxuan Wang and Haixu Wu and Jiaxiang Dong and Guo Qin and Haoran Zhang and Yong Liu and Yunzhong Qiu and Jianmin Wang and Mingsheng Long},
  year={2024},
  eprint={2402.19072},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2402.19072},
}

@misc{MOMENT,
  title={MOMENT: A Family of Open Time-series Foundation Models},
  author={Mononito Goswami and Konrad Szafer and Arjun Choudhry and Yifu Cai and Shuo Li and Artur Dubrawski},
  year={2024},
  eprint={2402.03885},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2402.03885},
}

@misc{Chronos,
  title={Chronos: Learning the Language of Time Series},
  author={Abdul Fatir Ansari and Lorenzo Stella and Caner Turkmen and Xiyuan Zhang and Pedro Mercado and Huibin Shen and Oleksandr Shchur and Syama Sundar Rangapuram and Sebastian Pineda Arango and Shubham Kapoor and Jasper Zschiegner and Danielle C. Maddix and Hao Wang and Michael W. Mahoney and Kari Torkkola and Andrew Gordon Wilson and Michael Bohlke-Schneider and Yuyang Wang},
  year={2024},
  eprint={2403.07815},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2403.07815},
}

@inproceedings{graham_nsdi22,
  author = {Najafi, Ali and Wei, Michael},
  title = {Graham: Synchronizing Clocks by Leveraging Local Clock Properties},
  booktitle = {19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)},
  year = {2022},
  publisher = {USENIX Association},
  pages = {81--96},
}

@article{tirado_andres_clock_sources_2019,
  author = {Tirado-Andres, Fernando and Araujo, Alvaro},
  title = {Performance of clock sources and their influence on time synchronization in wireless sensor networks},
  journal = {International Journal of Distributed Sensor Networks},
  volume = {15},
  number = {9},
  year = {2019},
  month = sep,
  doi = {10.1177/1550147719879372},
  url = {https://doi.org/10.1177/1550147719879372},
  publisher = {SAGE Publications}
}

@article{wang_lstm_attention_bds_2024,
  author = {Wang, Shuai and Li, Guoqiang and Fang, Yong},
  title = {Enhancing Satellite Clock Bias Prediction in {BDS} with {LSTM}-Attention Model},
  journal = {GPS Solutions},
  volume = {28},
  number = {2},
  year = {2024},
  publisher = {Springer},
  doi = {10.1007/s10291-024-01622-4}
}

@article{gnss_clock_prediction_review_2025,
  author = {Zhang, Xin and others},
  title = {Review of Research on Satellite Clock Bias Prediction Models in {GNSS}},
  journal = {Remote Sensing},
  volume = {17},
  number = {18},
  pages = {3177},
  year = {2025},
  publisher = {MDPI}
}

@article{li_multivariate_cnn_lstm_gps_2024,
  author = {Li, Na and Zhao, Lin and Li, Liang and Feng, Guorui},
  title = {{BDS} Multiple Satellite Clock Offset Parallel Prediction Based on Multivariate {CNN-LSTM} Model},
  journal = {GPS Solutions},
  volume = {28},
  number = {4},
  articleno = {189},
  year = {2024},
  publisher = {Springer},
  doi = {10.1007/s10291-024-01735-w}
}

@inproceedings{jung_ml_rco_isscc_2022,
  author = {Jung, Jaeho and others},
  title = {A Single-Crystal-Oscillator-Based Clock-Management {IC} with {ML}-Based {RCO} Calibration Achieving 0.68\,ppm/\textdegree{C} Stability},
  booktitle = {2022 IEEE International Solid-State Circuits Conference (ISSCC)},
  year = {2022},
  publisher = {IEEE},
  doi = {10.1109/ISSCC42614.2022.9731670}
}

@article{xplog_tsc2026,
  author = {Satapathy, Utkalika and Borse, Harshal R. and Bachhawat, Rajat and Dalmia, Neha and Chattopadhyay, Subhrendu and Chakraborty, Sandip},
  title = {{XPLOG}: A Dynamic Observability Framework for Distributed Sandboxed Microservices},
  journal = {IEEE Transactions on Services Computing},
  year = {2026},
  note = {Causally-consistent logging for microservices},
}

@inproceedings{sundial_osdi2020,
  author = {Li, Yuliang and Kumar, Gautam and Hariharan, Hrishikesh and Wassel, Hassan M. G. and Hochschild, Peter H. and Platt, Dave and Sabato, Simon L. and Yu, Minlan and Dukkipati, Nandita and Chandra, Prashant and Vahdat, Amin},
  title = {Sundial: Fault-tolerant Clock Synchronization for Datacenters},
  booktitle = {USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  year = {2020},
  note = {Google datacenter clock sync, assumes 200ppm commodity drift},
}

@techreport{dapper_google2010,
  author = {Sigelman, Benjamin H. and Barroso, Luiz Andr\'{e} and Burrows, Mike and Stephenson, Pat and Plakal, Manoj and Beaver, Donald and Jaspan, Saul and Shanbhag, Chandan},
  title = {Dapper, a Large-Scale Distributed Systems Tracing Infrastructure},
  institution = {Google},
  year = {2010},
  note = {Google's distributed tracing at scale},
}

@inproceedings{najafi_hotos2021_time,
  author = {Najafi, Ali and Tai, Amy and Wei, Michael},
  title = {Systems research is running out of time},
  booktitle = {Workshop on Hot Topics in Operating Systems (HotOS)},
  year = {2021},
  publisher = {ACM},
}

@inproceedings{chronolog_msst2020,
  author = {Kougkas, Anthony and Devarajan, Hariharan and Bateman, Keith and Cernuda, Jaime and Rajesh, Neeraj and Sun, Xian-He},
  title = {{ChronoLog}: A Distributed Shared Tiered Log Store with Time-based Data Ordering},
  booktitle = {Proceedings of the 36th International Conference on Massive Storage Systems and Technology (MSST)},
  year = {2020},
}

@inproceedings{agentsight_pacmi2025,
  author = {Zheng, Yusheng and Hu, Yanpeng and Yu, Tong and Quinn, Andi},
  title = {{AgentSight}: System-Level Observability for {AI} Agents Using {eBPF}},
  booktitle = {Proceedings of the ACM on Programming Languages (PACMI), co-located with SOSP 2025},
  year = {2025},
  doi = {10.1145/3766882.3767169},
}

@article{denis_starpu_tracing2023,
  author = {Denis, Alexandre and Jeannot, Emmanuel and Swartvagher, Philippe and Thibault, Samuel},
  title = {Tracing task-based runtime systems: Feedbacks from the {StarPU} case},
  journal = {Concurrency and Computation: Practice and Experience},
  year = {2023},
  doi = {10.1002/cpe.7920},
}

% ============================================================================
% UNCITED ENTRIES — kept for reference, not currently referenced in the paper.
% Review before submission: cite or remove.
% ============================================================================

@inproceedings{hlc_podc2014_kulkarni_causality,
  author = {Kulkarni, Sandeep S. and Demirbas, Murat and Madappa, Deepak and Avva, Bharadwaj and Leone, Marcelo},
  title = {Logical Physical Clocks},
  booktitle = {Principles of Distributed Systems: 18th International Conference, {OPODIS} 2014, Cortina d'Ampezzo, Italy, December 16-19, 2014. Proceedings},
  year = {2014},
  series = {Lecture Notes in Computer Science},
  volume = {8878},
  pages = {17--32},
  publisher = {Springer},
  address = {Cham},
  doi = {10.1007/978-3-319-14472-6_2},
  url = {https://doi.org/10.1007/978-3-319-14472-6_2}
}

@techreport{nvidia_dlss3_frame_generation_neural,
  author = {{NVIDIA Corporation}},
  title = {{NVIDIA Ada GPU Science: How Ada Advances the Science of Graphics with DLSS 3}},
  institution = {NVIDIA Corporation},
  year = {2022},
  type = {White Paper},
  url = {https://images.nvidia.com/aem-dam/Solutions/geforce/ada/ada-lovelace-architecture/nvidia-ada-gpu-science.pdf}
}

@article{sdn_openflow_mckeown_sigcomm,
  author = {McKeown, Nick and Anderson, Tom and Balakrishnan, Hari and Parulkar, Guru and Peterson, Larry and Rexford, Jennifer and Shenker, Scott and Turner, Jonathan},
  title = {OpenFlow: Enabling Innovation in Campus Networks},
  journal = {ACM SIGCOMM Computer Communication Review},
  volume = {38},
  number = {2},
  year = {2008},
  month = apr,
  pages = {69--74},
  doi = {10.1145/1355734.1355746},
  url = {https://doi.org/10.1145/1355734.1355746},
  publisher = {ACM}
}

@inproceedings{autopilot_google_48pct_fleet_lstm,
  author = {Krzysztof Rzadca and Pawel Findeisen and Jacek Swiderski and Przemyslaw Zych and Przemyslaw Broniek and Jarek Kusmierek and Pawel Nowak and Beata Strack and Piotr Witusowski and Steven Hand and John Wilkes},
  title = {Autopilot: Workload Autoscaling at {Google}},
  booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems (EuroSys '20)},
  year = {2020},
  pages = {16:1--16:16},
  articleno = {16},
  numpages = {16},
  publisher = {ACM},
  address = {New York, NY, USA},
  month = apr,
  doi = {10.1145/3342195.3387524},
  url = {https://dl.acm.org/doi/10.1145/3342195.3387524},
  note = {Autopiloted jobs account for over 48\% of Google's fleet-wide resource usage}
}

@inproceedings{deepscaling_alibaba_30k_cores_gnn,
  author = {Chunyang Meng and Shijie Song and Haogang Tong and Maolin Pan and Yang Yu},
  title = {{DeepScaler}: Holistic Autoscaling for Microservices Based on Spatiotemporal {GNN} with Adaptive Graph Learning},
  booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE '23)},
  year = {2023},
  pages = {53--65},
  publisher = {IEEE/ACM},
  month = sep,
  doi = {10.1109/ASE56229.2023.00038},
  url = {https://ieeexplore.ieee.org/document/10298341},
  note = {Alibaba Cloud system with GNN; 41\% SLA violation reduction}
}

@INPROCEEDINGS{slog,
  author={Matri, Pierre and Carns, Philip and Ross, Robert and Costan, Alexandru and Pérez, María S. and Antoniu, Gabriel},
  booktitle={2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)},
  title={SLoG: Large-Scale Logging Middleware for HPC and Big Data Convergence},
  year={2018},
  volume={},
  number={},
  pages={1507-1512},
  keywords={Computational modeling;Middleware;Telemetry;Parallel processing;Supercomputers;Concurrent computing;Data structures;hpc;big data;convergence;storage;file systems;i/o;small files;throughput;latency;replication},
  doi={10.1109/ICDCS.2018.00156}}

@article{SeqFusion,
  title={SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting},
  author={Huang, Ting-Ji and Chen, Xu-Yang and Ye, Han-Jia},
  journal={arXiv preprint arXiv:2503.02836},
  year={2025}
}

@inproceedings{ExplotingLPTS,
title={Exploiting Language Power for Time Series Forecasting with Exogenous Variables},
author={Qihe Huang and Zhengyang Zhou and Kuo Yang and Yang Wang},
booktitle={THE WEB CONFERENCE 2025},
year={2025},
url={https://openreview.net/forum?id=dFapOK8Rhb}
}

@misc{MPTS,
  title={Using Pre-trained LLMs for Multivariate Time Series Forecasting},
  author={Malcolm L. Wolff and Shenghao Yang and Kari Torkkola and Michael W. Mahoney},
  year={2025},
  eprint={2501.06386},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2501.06386},
}

@misc{TimePFN,
  title={TimePFN: Effective Multivariate Time Series Forecasting with Synthetic Data},
  author={Ege Onur Taga and M. Emrullah Ildiz and Samet Oymak},
  year={2025},
  eprint={2502.16294},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2502.16294},
}

@misc{AdaPTS,
  title={AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting},
  author={Abdelhakim Benechehab and Vasilii Feofanov and Giuseppe Paolo and Albert Thomas and Maurizio Filippone and Balázs Kégl},
  year={2025},
  eprint={2502.10235},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/2502.10235},
}

@misc{ReFocus,
  title={ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for Multivariate Time Series Forecasting},
  author={Guoqi Yu and Yaoming Li and Juncheng Wang and Xiaoyu Guo and Angelica I. Aviles-Rivero and Tong Yang and Shujun Wang},
  year={2025},
  eprint={2502.16890},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2502.16890},
}

@misc{SmallButMighty,
  title={Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs},
  author={Haoran Fan and Bin Li and Yixuan Weng and Shoujun Zhou},
  year={2025},
  eprint={2503.03594},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2503.03594},
}

@misc{Time-MMD,
  title={Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis},
  author={Haoxin Liu and Shangqing Xu and Zhiyuan Zhao and Lingkai Kong and Harshavardhan Kamarthi and Aditya B. Sasanur and Megha Sharma and Jiaming Cui and Qingsong Wen and Chao Zhang and B. Aditya Prakash},
  year={2025},
  eprint={2406.08627},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2406.08627},
}

@INPROCEEDINGS{PPDformer,
  author={Wan, Meng and Su, Qi and Hao, Huan and Wang, Jue and Cui, Yuexiu and Bi, Yuxuan and Cao, Rongqiang and Shi, Peng and Wang, Yangang and Qiu, Zonghua and Zhang, Zongshan},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={PPDformer: Channel-Specific Periodic Patch Division for Time Series Forecasting},
  year={2025},
  volume={},
  number={},
  pages={1-5},
  keywords={Attention mechanisms;Fourier transforms;Codes;Time series analysis;Noise reduction;Noise;Predictive models;Transformers;Forecasting;Speech processing;Multivariate time series forecasting;Period;Patch segmentation;Channel-wise denoising;Dual attention mechanism},
  doi={10.1109/ICASSP49660.2025.10890581}}

@misc{UnifyAndAnchor,
  title={Unify and Anchor: A Context-Aware Transformer for Cross-Domain Time Series Forecasting},
  author={Xiaobin Hong and Jiawen Zhang and Wenzhong Li and Sanglu Lu and Jia Li},
  year={2025},
  eprint={2503.01157},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2503.01157},
}

@misc{LAST_SToP,
  title={LAST SToP For Modeling Asynchronous Time Series},
  author={Shubham Gupta and Thibaut Durand and Graham Taylor and Lilian W. Białokozowicz},
  year={2025},
  eprint={2502.01922},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2502.01922},
}

@misc{Time-FFM,
  title={Time-FFM: Towards LM-Empowered Federated Foundation Model for Time Series Forecasting},
  author={Qingxiang Liu and Xu Liu and Chenghao Liu and Qingsong Wen and Yuxuan Liang},
  year={2024},
  eprint={2405.14252},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2405.14252},
}

@misc{TimeCAP,
  title={TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents},
  author={Geon Lee and Wenchao Yu and Kijung Shin and Wei Cheng and Haifeng Chen},
  year={2025},
  eprint={2502.11418},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2502.11418},
}

@misc{TimeCMA,
  title={TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment},
  author={Chenxi Liu and Qianxiong Xu and Hao Miao and Sun Yang and Lingzheng Zhang and Cheng Long and Ziyue Li and Rui Zhao},
  year={2025},
  eprint={2406.01638},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2406.01638},
}

@misc{S^2IP-LLM,
  title={$\textbf{S}^2$IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting},
  author={Zijie Pan and Yushan Jiang and Sahil Garg and Anderson Schneider and Yuriy Nevmyvaka and Dongjin Song},
  year={2024},
  eprint={2403.05798},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2403.05798},
}

@misc{TimeRAG,
  title={TimeRAG: BOOSTING LLM Time Series Forecasting via Retrieval-Augmented Generation},
  author={Silin Yang and Dong Wang and Haoqi Zheng and Ruochun Jin},
  year={2024},
  eprint={2412.16643},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2412.16643},
}

@misc{MSGNet,
  title={MSGNet: Learning Multi-Scale Inter-Series Correlations for Multivariate Time Series Forecasting},
  author={Wanlin Cai and Yuxuan Liang and Xianggen Liu and Jianshuai Feng and Yuankai Wu},
  year={2023},
  eprint={2401.00423},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2401.00423},
}

@inproceedings{SOFTS,
title={{SOFTS}: Efficient Multivariate Time Series Forecasting with Series-Core Fusion},
author={Lu Han and Xu-Yang Chen and Han-Jia Ye and De-Chuan Zhan},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=89AUi5L1uA}
}

@misc{ChatTime,
  title={ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data},
  author={Chengsen Wang and Qi Qi and Jingyu Wang and Haifeng Sun and Zirui Zhuang and Jinming Wu and Lei Zhang and Jianxin Liao},
  year={2024},
  eprint={2412.11376},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2412.11376},
}

@article{GPT4MTS, title={GPT4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting}, volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/30383}, DOI={10.1609/aaai.v38i21.30383}, abstractNote={Time series forecasting is an essential area of machine learning with a wide range of real-world applications. Most of the previous forecasting models aim to capture dynamic characteristics from uni-modal numerical historical data. Although extra knowledge can boost the time series forecasting performance, it is hard to collect such information. In addition, how to fuse the multimodal information is non-trivial. In this paper, we first propose a general principle of collecting the corresponding textual information from different data sources with the help of modern large language models (LLM). Then, we propose a prompt-based LLM framework to utilize both the numerical data and the textual information simultaneously, named GPT4MTS. In practice, we propose a GDELT-based multimodal time series dataset for news impact forecasting, which provides a concise and well-structured version of time series dataset with textual information for further research in communication. Through extensive experiments, we demonstrate the effectiveness of our proposed method on forecasting tasks with extra-textual information.}, number={21}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Jia, Furong and Wang, Kevin and Zheng, Yixiang and Cao, Defu and Liu, Yan}, year={2024}, month={Mar.}, pages={23343-23351} }

@misc{LLM-Mixer,
  title={LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting},
  author={Md Kowsher and Md. Shohanur Islam Sobuj and Nusrat Jahan Prottasha and E. Alejandro Alanis and Ozlem Ozmen Garibay and Niloofar Yousefi},
  year={2024},
  eprint={2410.11674},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2410.11674},
}

@misc{LeMoLE,
  title={LeMoLE: LLM-Enhanced Mixture of Linear Experts for Time Series Forecasting},
  author={Lingzheng Zhang and Lifeng Shen and Yimin Zheng and Shiyuan Piao and Ziyue Li and Fugee Tsung},
  year={2024},
  eprint={2412.00053},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2412.00053},
}
